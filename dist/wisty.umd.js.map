{"version":3,"file":"wisty.umd.js","sources":["../src/utils/initialize_variable.ts","../src/lstm.ts","../node_modules/babel-plugin-transform-async-to-promises/helpers.js","../src/hcn.ts","../src/featurizer.ts","../src/use.ts","../src/utils/hashcode.ts","../src/bow.ts","../src/utils/levenshtein_distance.ts","../src/word_embedding.ts","../src/utils/fuzzy_match.ts","../src/categorical_slot.ts","../src/action_featurizer.ts","../src/utils/parse_stories.ts","../src/utils/train_test_split.ts"],"sourcesContent":["import * as tf from '@tensorflow/tfjs';\n\n/**\n * Initialize a variable of a given shape.\n */\nexport function initializeVariable(shape: number[], scalar: boolean = false,\n    init: 'he'|'zeros'|'normal' = 'he'): tf.Variable {\n    return tf.tidy(() => {\n        let initializer;\n\n        switch (init) {\n        case 'he':\n            initializer = tf.initializers.heNormal({});\n            break;\n\n        case 'zeros':\n            initializer = tf.initializers.zeros();\n            break;\n\n        case 'normal':\n            initializer = tf.initializers.randomNormal({});\n            break;\n\n        default:\n            throw new Error(\n                `Expected parameter init to take value 'he', 'zeros' or 'normal' not '${init}'.`\n            );\n        }\n\n        let randomTensor = initializer.apply(shape);\n        if (scalar) randomTensor = randomTensor.asScalar();\n\n        return randomTensor.variable();\n    });\n}\n","import * as tf from '@tensorflow/tfjs';\nimport { initializeVariable } from './utils/initialize_variable';\n\ntype LSTMPrediction = {y: tf.Tensor1D, nc: tf.Tensor2D, nh: tf.Tensor2D};\n\n/**\n * An LSTM cell with a dense layer on its top.\n */\nexport class LSTM {\n    // LSTM parameters :\n    private lstmKernel: tf.Tensor;\n    private lstmBias: tf.Tensor;\n    private lstmForgetBias: tf.Tensor;\n    private lstmInitH: tf.Tensor;\n    private lstmInitC: tf.Tensor;\n\n    // Dense layer parameters :\n    private denseWeights: tf.Tensor;\n    private denseBias: tf.Tensor;\n\n    // Let dropout be public to allow to change its value when training/inference.\n    public dropout: number;\n\n    /**\n     * @param inputSize The dimension of the input data.\n     * @param hiddenSize The dimension of the output of the LSTM, passed to the dense layer.\n     * @param outputSize The dimension of the output data.\n     * @param dropout The dropout rate between the LSTM cell and the dense layer.\n     */\n    constructor(inputSize: number, hiddenSize: number, outputSize: number, dropout: number = 0.2) {\n        this.lstmKernel = initializeVariable([inputSize + hiddenSize, hiddenSize * 4]);\n        this.lstmBias = initializeVariable([hiddenSize * 4], false, 'zeros');\n        this.lstmForgetBias = initializeVariable([1], true, 'zeros'); // (scalar)\n        this.lstmInitH = initializeVariable([1, hiddenSize]);\n        this.lstmInitC = initializeVariable([1, hiddenSize]);\n\n        this.denseWeights = initializeVariable([hiddenSize, outputSize]);\n        this.denseBias = initializeVariable([outputSize], false, 'zeros');\n\n        this.dropout = dropout;\n    }\n\n    /**\n     * Gives the initial state values of the LSTM (c and h).\n     *\n     * @param clone If it is necessary to clone states variable or no.\n     */\n    initLSTM(clone: boolean = true): {c: tf.Tensor2D, h: tf.Tensor2D} {\n        return {\n            c: <tf.Tensor2D> (clone ? this.lstmInitC.clone() : this.lstmInitC),\n            h: <tf.Tensor2D> (clone ? this.lstmInitH.clone() : this.lstmInitH)\n        };\n    }\n\n    /**\n     * Make a prediction given an input and state values (c and h).\n     * @param x A vector of shape [inputSize].\n     * @param c LSTM's state value.\n     * @param h LSTM's last output value.\n     * @param mask A vector of ones and zeros of shape [outputSize].\n     */\n    predict(x: tf.Tensor1D, c: tf.Tensor2D, h: tf.Tensor2D, mask?: tf.Tensor1D,\n        temperature: number = 1): LSTMPrediction {\n        return tf.tidy(() => {\n            // Execute the LSTM cell.\n            const [nc, nh] = tf.basicLSTMCell(\n                <tf.Scalar> this.lstmForgetBias,\n                <tf.Tensor2D> this.lstmKernel,\n                <tf.Tensor1D> this.lstmBias,\n                <tf.Tensor2D> tf.stack([x]),\n                h, c\n            );\n\n            // Execute the dense layer on top of the LSTM cell.\n            let y = <tf.Tensor1D> tf\n                .dropout(nh, this.dropout)\n                .matMul(this.denseWeights)\n                .add(this.denseBias)\n                .squeeze()\n                .div(temperature)\n                .softmax()\n                .mul(mask ?? 1);\n\n            // Apply normalization after the mask to get probabilities.\n            y = y.div(tf.sum(y));\n\n            return { y, nc, nh };\n        });\n    }\n\n    /**\n     * Update the given model parameters.\n     */\n    load(weights: {[key: string]: any}) {\n        tf.tidy(() => {\n            // Convert every parameter to a tf variable tensor.\n            this.lstmKernel = tf.tensor(weights.lstmKernel).variable();\n            this.lstmBias = tf.tensor(weights.lstmBias).variable();\n            this.lstmForgetBias = tf.tensor(weights.lstmForgetBias).variable();\n            this.lstmInitH = tf.tensor(weights.lstmInitH).variable();\n            this.lstmInitC = tf.tensor(weights.lstmInitC).variable();\n            this.denseWeights = tf.tensor(weights.denseWeights).variable();\n            this.denseBias = tf.tensor(weights.denseBias).variable();\n        });\n    }\n\n    /**\n     * Return all the LSTM model parameters.\n     */\n    async export(): Promise<{[key: string]: any}> {\n        const exports = {\n            lstmKernel: await this.lstmKernel.array(),\n            lstmBias: await this.lstmBias.array(),\n            lstmForgetBias: await this.lstmForgetBias.array(),\n            lstmInitH: await this.lstmInitH.array(),\n            lstmInitC: await this.lstmInitC.array(),\n            denseWeights: await this.denseWeights.array(),\n            denseBias: await this.denseBias.array()\n        };\n\n        return exports;\n    }\n}\n","// A type of promise-like that resolves synchronously and supports only one observer\nexport const _Pact = /*#__PURE__*/(function() {\n\tfunction _Pact() {}\n\t_Pact.prototype.then = function(onFulfilled, onRejected) {\n\t\tconst result = new _Pact();\n\t\tconst state = this.s;\n\t\tif (state) {\n\t\t\tconst callback = state & 1 ? onFulfilled : onRejected;\n\t\t\tif (callback) {\n\t\t\t\ttry {\n\t\t\t\t\t_settle(result, 1, callback(this.v));\n\t\t\t\t} catch (e) {\n\t\t\t\t\t_settle(result, 2, e);\n\t\t\t\t}\n\t\t\t\treturn result;\n\t\t\t} else {\n\t\t\t\treturn this;\n\t\t\t}\n\t\t}\n\t\tthis.o = function(_this) {\n\t\t\ttry {\n\t\t\t\tconst value = _this.v;\n\t\t\t\tif (_this.s & 1) {\n\t\t\t\t\t_settle(result, 1, onFulfilled ? onFulfilled(value) : value);\n\t\t\t\t} else if (onRejected) {\n\t\t\t\t\t_settle(result, 1, onRejected(value));\n\t\t\t\t} else {\n\t\t\t\t\t_settle(result, 2, value);\n\t\t\t\t}\n\t\t\t} catch (e) {\n\t\t\t\t_settle(result, 2, e);\n\t\t\t}\n\t\t};\n\t\treturn result;\n\t}\n\treturn _Pact;\n})();\n\n// Settles a pact synchronously\nexport function _settle(pact, state, value) {\n\tif (!pact.s) {\n\t\tif (value instanceof _Pact) {\n\t\t\tif (value.s) {\n\t\t\t\tif (state & 1) {\n\t\t\t\t\tstate = value.s;\n\t\t\t\t}\n\t\t\t\tvalue = value.v;\n\t\t\t} else {\n\t\t\t\tvalue.o = _settle.bind(null, pact, state);\n\t\t\t\treturn;\n\t\t\t}\n\t\t}\n\t\tif (value && value.then) {\n\t\t\tvalue.then(_settle.bind(null, pact, state), _settle.bind(null, pact, 2));\n\t\t\treturn;\n\t\t}\n\t\tpact.s = state;\n\t\tpact.v = value;\n\t\tconst observer = pact.o;\n\t\tif (observer) {\n\t\t\tobserver(pact);\n\t\t}\n\t}\n}\n\nexport function _isSettledPact(thenable) {\n\treturn thenable instanceof _Pact && thenable.s & 1;\n}\n\n// Converts argument to a function that always returns a Promise\nexport function _async(f) {\n\treturn function() {\n\t\tfor (var args = [], i = 0; i < arguments.length; i++) {\n\t\t\targs[i] = arguments[i];\n\t\t}\n\t\ttry {\n\t\t\treturn Promise.resolve(f.apply(this, args));\n\t\t} catch(e) {\n\t\t\treturn Promise.reject(e);\n\t\t}\n\t}\n}\n\n// Awaits on a value that may or may not be a Promise (equivalent to the await keyword in ES2015, with continuations passed explicitly)\nexport function _await(value, then, direct) {\n\tif (direct) {\n\t\treturn then ? then(value) : value;\n\t}\n\tif (!value || !value.then) {\n\t\tvalue = Promise.resolve(value);\n\t}\n\treturn then ? value.then(then) : value;\n}\n\n// Awaits on a value that may or may not be a Promise, then ignores it\nexport function _awaitIgnored(value, direct) {\n\tif (!direct) {\n\t\treturn value && value.then ? value.then(_empty) : Promise.resolve();\n\t}\n}\n\n// Proceeds after a value has resolved, or proceeds immediately if the value is not thenable\nexport function _continue(value, then) {\n\treturn value && value.then ? value.then(then) : then(value);\n}\n\n// Proceeds after a value has resolved, or proceeds immediately if the value is not thenable\nexport function _continueIgnored(value) {\n\tif (value && value.then) {\n\t\treturn value.then(_empty);\n\t}\n}\n\n// Asynchronously iterate through an object that has a length property, passing the index as the first argument to the callback (even as the length property changes)\nexport function _forTo(array, body, check) {\n\tvar i = -1, pact, reject;\n\tfunction _cycle(result) {\n\t\ttry {\n\t\t\twhile (++i < array.length && (!check || !check())) {\n\t\t\t\tresult = body(i);\n\t\t\t\tif (result && result.then) {\n\t\t\t\t\tif (_isSettledPact(result)) {\n\t\t\t\t\t\tresult = result.v;\n\t\t\t\t\t} else {\n\t\t\t\t\t\tresult.then(_cycle, reject || (reject = _settle.bind(null, pact = new _Pact(), 2)));\n\t\t\t\t\t\treturn;\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t\tif (pact) {\n\t\t\t\t_settle(pact, 1, result);\n\t\t\t} else {\n\t\t\t\tpact = result;\n\t\t\t}\n\t\t} catch (e) {\n\t\t\t_settle(pact || (pact = new _Pact()), 2, e);\n\t\t}\n\t}\n\t_cycle();\n\treturn pact;\n}\n\n// Asynchronously iterate through an object's properties (including properties inherited from the prototype)\n// Uses a snapshot of the object's properties\nexport function _forIn(target, body, check) {\n\tvar keys = [];\n\tfor (var key in target) {\n\t\tkeys.push(key);\n\t}\n\treturn _forTo(keys, function(i) { return body(keys[i]); }, check);\n}\n\n// Asynchronously iterate through an object's own properties (excluding properties inherited from the prototype)\n// Uses a snapshot of the object's properties\nexport function _forOwn(target, body, check) {\n\tvar keys = [];\n\tfor (var key in target) {\n\t\tif (Object.prototype.hasOwnProperty.call(target, key)) {\n\t\t\tkeys.push(key);\n\t\t}\n\t}\n\treturn _forTo(keys, function(i) { return body(keys[i]); }, check);\n}\n\nexport const _iteratorSymbol = /*#__PURE__*/ typeof Symbol !== \"undefined\" ? (Symbol.iterator || (Symbol.iterator = Symbol(\"Symbol.iterator\"))) : \"@@iterator\";\n\n// Asynchronously iterate through an object's values\n// Uses for...of if the runtime supports it, otherwise iterates until length on a copy\nexport function _forOf(target, body, check) {\n\tif (typeof target[_iteratorSymbol] === \"function\") {\n\t\tvar iterator = target[_iteratorSymbol](), step, pact, reject;\n\t\tfunction _cycle(result) {\n\t\t\ttry {\n\t\t\t\twhile (!(step = iterator.next()).done && (!check || !check())) {\n\t\t\t\t\tresult = body(step.value);\n\t\t\t\t\tif (result && result.then) {\n\t\t\t\t\t\tif (_isSettledPact(result)) {\n\t\t\t\t\t\t\tresult = result.v;\n\t\t\t\t\t\t} else {\n\t\t\t\t\t\t\tresult.then(_cycle, reject || (reject = _settle.bind(null, pact = new _Pact(), 2)));\n\t\t\t\t\t\t\treturn;\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tif (pact) {\n\t\t\t\t\t_settle(pact, 1, result);\n\t\t\t\t} else {\n\t\t\t\t\tpact = result;\n\t\t\t\t}\n\t\t\t} catch (e) {\n\t\t\t\t_settle(pact || (pact = new _Pact()), 2, e);\n\t\t\t}\n\t\t}\n\t\t_cycle();\n\t\tif (iterator.return) {\n\t\t\tvar _fixup = function(value) {\n\t\t\t\ttry {\n\t\t\t\t\tif (!step.done) {\n\t\t\t\t\t\titerator.return();\n\t\t\t\t\t}\n\t\t\t\t} catch(e) {\n\t\t\t\t}\n\t\t\t\treturn value;\n\t\t\t}\n\t\t\tif (pact && pact.then) {\n\t\t\t\treturn pact.then(_fixup, function(e) {\n\t\t\t\t\tthrow _fixup(e);\n\t\t\t\t});\n\t\t\t}\n\t\t\t_fixup();\n\t\t}\n\t\treturn pact;\n\t}\n\t// No support for Symbol.iterator\n\tif (!(\"length\" in target)) {\n\t\tthrow new TypeError(\"Object is not iterable\");\n\t}\n\t// Handle live collections properly\n\tvar values = [];\n\tfor (var i = 0; i < target.length; i++) {\n\t\tvalues.push(target[i]);\n\t}\n\treturn _forTo(values, function(i) { return body(values[i]); }, check);\n}\n\nexport const _asyncIteratorSymbol = /*#__PURE__*/ typeof Symbol !== \"undefined\" ? (Symbol.asyncIterator || (Symbol.asyncIterator = Symbol(\"Symbol.asyncIterator\"))) : \"@@asyncIterator\";\n\n// Asynchronously iterate on a value using it's async iterator if present, or its synchronous iterator if missing\nexport function _forAwaitOf(target, body, check) {\n\tif (typeof target[_asyncIteratorSymbol] === \"function\") {\n\t\tvar pact = new _Pact();\n\t\tvar iterator = target[_asyncIteratorSymbol]();\n\t\titerator.next().then(_resumeAfterNext).then(void 0, _reject);\n\t\treturn pact;\n\t\tfunction _resumeAfterBody(result) {\n\t\t\tif (check && check()) {\n\t\t\t\treturn _settle(pact, 1, iterator.return ? iterator.return().then(function() { return result; }) : result);\n\t\t\t}\n\t\t\titerator.next().then(_resumeAfterNext).then(void 0, _reject);\n\t\t}\n\t\tfunction _resumeAfterNext(step) {\n\t\t\tif (step.done) {\n\t\t\t\t_settle(pact, 1);\n\t\t\t} else {\n\t\t\t\tPromise.resolve(body(step.value)).then(_resumeAfterBody).then(void 0, _reject);\n\t\t\t}\n\t\t}\n\t\tfunction _reject(error) {\n\t\t\t_settle(pact, 2, iterator.return ? iterator.return().then(function() { return error; }) : error);\n\t\t}\n\t}\n\treturn Promise.resolve(_forOf(target, function(value) { return Promise.resolve(value).then(body); }, check));\n}\n\n// Asynchronously implement a generic for loop\nexport function _for(test, update, body) {\n\tvar stage;\n\tfor (;;) {\n\t\tvar shouldContinue = test();\n\t\tif (_isSettledPact(shouldContinue)) {\n\t\t\tshouldContinue = shouldContinue.v;\n\t\t}\n\t\tif (!shouldContinue) {\n\t\t\treturn result;\n\t\t}\n\t\tif (shouldContinue.then) {\n\t\t\tstage = 0;\n\t\t\tbreak;\n\t\t}\n\t\tvar result = body();\n\t\tif (result && result.then) {\n\t\t\tif (_isSettledPact(result)) {\n\t\t\t\tresult = result.s;\n\t\t\t} else {\n\t\t\t\tstage = 1;\n\t\t\t\tbreak;\n\t\t\t}\n\t\t}\n\t\tif (update) {\n\t\t\tvar updateValue = update();\n\t\t\tif (updateValue && updateValue.then && !_isSettledPact(updateValue)) {\n\t\t\t\tstage = 2;\n\t\t\t\tbreak;\n\t\t\t}\n\t\t}\n\t}\n\tvar pact = new _Pact();\n\tvar reject = _settle.bind(null, pact, 2);\n\t(stage === 0 ? shouldContinue.then(_resumeAfterTest) : stage === 1 ? result.then(_resumeAfterBody) : updateValue.then(_resumeAfterUpdate)).then(void 0, reject);\n\treturn pact;\n\tfunction _resumeAfterBody(value) {\n\t\tresult = value;\n\t\tdo {\n\t\t\tif (update) {\n\t\t\t\tupdateValue = update();\n\t\t\t\tif (updateValue && updateValue.then && !_isSettledPact(updateValue)) {\n\t\t\t\t\tupdateValue.then(_resumeAfterUpdate).then(void 0, reject);\n\t\t\t\t\treturn;\n\t\t\t\t}\n\t\t\t}\n\t\t\tshouldContinue = test();\n\t\t\tif (!shouldContinue || (_isSettledPact(shouldContinue) && !shouldContinue.v)) {\n\t\t\t\t_settle(pact, 1, result);\n\t\t\t\treturn;\n\t\t\t}\n\t\t\tif (shouldContinue.then) {\n\t\t\t\tshouldContinue.then(_resumeAfterTest).then(void 0, reject);\n\t\t\t\treturn;\n\t\t\t}\n\t\t\tresult = body();\n\t\t\tif (_isSettledPact(result)) {\n\t\t\t\tresult = result.v;\n\t\t\t}\n\t\t} while (!result || !result.then);\n\t\tresult.then(_resumeAfterBody).then(void 0, reject);\n\t}\n\tfunction _resumeAfterTest(shouldContinue) {\n\t\tif (shouldContinue) {\n\t\t\tresult = body();\n\t\t\tif (result && result.then) {\n\t\t\t\tresult.then(_resumeAfterBody).then(void 0, reject);\n\t\t\t} else {\n\t\t\t\t_resumeAfterBody(result);\n\t\t\t}\n\t\t} else {\n\t\t\t_settle(pact, 1, result);\n\t\t}\n\t}\n\tfunction _resumeAfterUpdate() {\n\t\tif (shouldContinue = test()) {\n\t\t\tif (shouldContinue.then) {\n\t\t\t\tshouldContinue.then(_resumeAfterTest).then(void 0, reject);\n\t\t\t} else {\n\t\t\t\t_resumeAfterTest(shouldContinue);\n\t\t\t}\n\t\t} else {\n\t\t\t_settle(pact, 1, result);\n\t\t}\n\t}\n}\n\n// Asynchronously implement a do ... while loop\nexport function _do(body, test) {\n\tvar awaitBody;\n\tdo {\n\t\tvar result = body();\n\t\tif (result && result.then) {\n\t\t\tif (_isSettledPact(result)) {\n\t\t\t\tresult = result.v;\n\t\t\t} else {\n\t\t\t\tawaitBody = true;\n\t\t\t\tbreak;\n\t\t\t}\n\t\t}\n\t\tvar shouldContinue = test();\n\t\tif (_isSettledPact(shouldContinue)) {\n\t\t\tshouldContinue = shouldContinue.v;\n\t\t}\n\t\tif (!shouldContinue) {\n\t\t\treturn result;\n\t\t}\n\t} while (!shouldContinue.then);\n\tconst pact = new _Pact();\n\tconst reject = _settle.bind(null, pact, 2);\n\t(awaitBody ? result.then(_resumeAfterBody) : shouldContinue.then(_resumeAfterTest)).then(void 0, reject);\n\treturn pact;\n\tfunction _resumeAfterBody(value) {\n\t\tresult = value;\n\t\tfor (;;) {\n\t\t\tshouldContinue = test();\n\t\t\tif (_isSettledPact(shouldContinue)) {\n\t\t\t\tshouldContinue = shouldContinue.v;\n\t\t\t}\n\t\t\tif (!shouldContinue) {\n\t\t\t\tbreak;\n\t\t\t}\n\t\t\tif (shouldContinue.then) {\n\t\t\t\tshouldContinue.then(_resumeAfterTest).then(void 0, reject);\n\t\t\t\treturn;\n\t\t\t}\n\t\t\tresult = body();\n\t\t\tif (result && result.then) {\n\t\t\t\tif (_isSettledPact(result)) {\n\t\t\t\t\tresult = result.v;\n\t\t\t\t} else {\n\t\t\t\t\tresult.then(_resumeAfterBody).then(void 0, reject);\n\t\t\t\t\treturn;\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t\t_settle(pact, 1, result);\n\t}\n\tfunction _resumeAfterTest(shouldContinue) {\n\t\tif (shouldContinue) {\n\t\t\tdo {\n\t\t\t\tresult = body();\n\t\t\t\tif (result && result.then) {\n\t\t\t\t\tif (_isSettledPact(result)) {\n\t\t\t\t\t\tresult = result.v;\n\t\t\t\t\t} else {\n\t\t\t\t\t\tresult.then(_resumeAfterBody).then(void 0, reject);\n\t\t\t\t\t\treturn;\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tshouldContinue = test();\n\t\t\t\tif (_isSettledPact(shouldContinue)) {\n\t\t\t\t\tshouldContinue = shouldContinue.v;\n\t\t\t\t}\n\t\t\t\tif (!shouldContinue) {\n\t\t\t\t\t_settle(pact, 1, result);\n\t\t\t\t\treturn;\n\t\t\t\t}\n\t\t\t} while (!shouldContinue.then);\n\t\t\tshouldContinue.then(_resumeAfterTest).then(void 0, reject);\n\t\t} else {\n\t\t\t_settle(pact, 1, result);\n\t\t}\n\t}\n}\n\n// Asynchronously implement a switch statement\nexport function _switch(discriminant, cases) {\n\tvar dispatchIndex = -1;\n\tvar awaitBody;\n\touter: {\n\t\tfor (var i = 0; i < cases.length; i++) {\n\t\t\tvar test = cases[i][0];\n\t\t\tif (test) {\n\t\t\t\tvar testValue = test();\n\t\t\t\tif (testValue && testValue.then) {\n\t\t\t\t\tbreak outer;\n\t\t\t\t}\n\t\t\t\tif (testValue === discriminant) {\n\t\t\t\t\tdispatchIndex = i;\n\t\t\t\t\tbreak;\n\t\t\t\t}\n\t\t\t} else {\n\t\t\t\t// Found the default case, set it as the pending dispatch case\n\t\t\t\tdispatchIndex = i;\n\t\t\t}\n\t\t}\n\t\tif (dispatchIndex !== -1) {\n\t\t\tdo {\n\t\t\t\tvar body = cases[dispatchIndex][1];\n\t\t\t\twhile (!body) {\n\t\t\t\t\tdispatchIndex++;\n\t\t\t\t\tbody = cases[dispatchIndex][1];\n\t\t\t\t}\n\t\t\t\tvar result = body();\n\t\t\t\tif (result && result.then) {\n\t\t\t\t\tawaitBody = true;\n\t\t\t\t\tbreak outer;\n\t\t\t\t}\n\t\t\t\tvar fallthroughCheck = cases[dispatchIndex][2];\n\t\t\t\tdispatchIndex++;\n\t\t\t} while (fallthroughCheck && !fallthroughCheck());\n\t\t\treturn result;\n\t\t}\n\t}\n\tconst pact = new _Pact();\n\tconst reject = _settle.bind(null, pact, 2);\n\t(awaitBody ? result.then(_resumeAfterBody) : testValue.then(_resumeAfterTest)).then(void 0, reject);\n\treturn pact;\n\tfunction _resumeAfterTest(value) {\n\t\tfor (;;) {\n\t\t\tif (value === discriminant) {\n\t\t\t\tdispatchIndex = i;\n\t\t\t\tbreak;\n\t\t\t}\n\t\t\tif (++i === cases.length) {\n\t\t\t\tif (dispatchIndex !== -1) {\n\t\t\t\t\tbreak;\n\t\t\t\t} else {\n\t\t\t\t\t_settle(pact, 1, result);\n\t\t\t\t\treturn;\n\t\t\t\t}\n\t\t\t}\n\t\t\ttest = cases[i][0];\n\t\t\tif (test) {\n\t\t\t\tvalue = test();\n\t\t\t\tif (value && value.then) {\n\t\t\t\t\tvalue.then(_resumeAfterTest).then(void 0, reject);\n\t\t\t\t\treturn;\n\t\t\t\t}\n\t\t\t} else {\n\t\t\t\tdispatchIndex = i;\n\t\t\t}\n\t\t}\n\t\tdo {\n\t\t\tvar body = cases[dispatchIndex][1];\n\t\t\twhile (!body) {\n\t\t\t\tdispatchIndex++;\n\t\t\t\tbody = cases[dispatchIndex][1];\n\t\t\t}\n\t\t\tvar result = body();\n\t\t\tif (result && result.then) {\n\t\t\t\tresult.then(_resumeAfterBody).then(void 0, reject);\n\t\t\t\treturn;\n\t\t\t}\n\t\t\tvar fallthroughCheck = cases[dispatchIndex][2];\n\t\t\tdispatchIndex++;\n\t\t} while (fallthroughCheck && !fallthroughCheck());\n\t\t_settle(pact, 1, result);\n\t}\n\tfunction _resumeAfterBody(result) {\n\t\tfor (;;) {\n\t\t\tvar fallthroughCheck = cases[dispatchIndex][2];\n\t\t\tif (!fallthroughCheck || fallthroughCheck()) {\n\t\t\t\tbreak;\n\t\t\t}\n\t\t\tdispatchIndex++;\n\t\t\tvar body = cases[dispatchIndex][1];\n\t\t\twhile (!body) {\n\t\t\t\tdispatchIndex++;\n\t\t\t\tbody = cases[dispatchIndex][1];\n\t\t\t}\n\t\t\tresult = body();\n\t\t\tif (result && result.then) {\n\t\t\t\tresult.then(_resumeAfterBody).then(void 0, reject);\n\t\t\t\treturn;\n\t\t\t}\n\t\t}\n\t\t_settle(pact, 1, result);\n\t}\n}\n\n// Asynchronously call a function and pass the result to explicitly passed continuations\nexport function _call(body, then, direct) {\n\tif (direct) {\n\t\treturn then ? then(body()) : body();\n\t}\n\ttry {\n\t\tvar result = Promise.resolve(body());\n\t\treturn then ? result.then(then) : result;\n\t} catch (e) {\n\t\treturn Promise.reject(e);\n\t}\n}\n\n// Asynchronously call a function and swallow the result\nexport function _callIgnored(body, direct) {\n\treturn _call(body, _empty, direct);\n}\n\n// Asynchronously call a function and pass the result to explicitly passed continuations\nexport function _invoke(body, then) {\n\tvar result = body();\n\tif (result && result.then) {\n\t\treturn result.then(then);\n\t}\n\treturn then(result);\n}\n\n// Asynchronously call a function and swallow the result\nexport function _invokeIgnored(body) {\n\tvar result = body();\n\tif (result && result.then) {\n\t\treturn result.then(_empty);\n\t}\n}\n\n// Asynchronously call a function and send errors to recovery continuation\nexport function _catch(body, recover) {\n\ttry {\n\t\tvar result = body();\n\t} catch(e) {\n\t\treturn recover(e);\n\t}\n\tif (result && result.then) {\n\t\treturn result.then(void 0, recover);\n\t}\n\treturn result;\n}\n\n// Asynchronously await a promise and pass the result to a finally continuation\nexport function _finallyRethrows(body, finalizer) {\n\ttry {\n\t\tvar result = body();\n\t} catch (e) {\n\t\treturn finalizer(true, e);\n\t}\n\tif (result && result.then) {\n\t\treturn result.then(finalizer.bind(null, false), finalizer.bind(null, true));\n\t}\n\treturn finalizer(false, result);\n}\n\n// Asynchronously await a promise and invoke a finally continuation that always overrides the result\nexport function _finally(body, finalizer) {\n\ttry {\n\t\tvar result = body();\n\t} catch (e) {\n\t\treturn finalizer();\n\t}\n\tif (result && result.then) {\n\t\treturn result.then(finalizer, finalizer);\n\t}\n\treturn finalizer();\n}\n\n// Rethrow or return a value from a finally continuation\nexport function _rethrow(thrown, value) {\n\tif (thrown)\n\t\tthrow value;\n\treturn value;\n}\n\n// Empty function to implement break and other control flow that ignores asynchronous results\nexport function _empty() {\n}\n\n// Sentinel value for early returns in generators \nexport const _earlyReturn = /*#__PURE__*/ {};\n\n// Asynchronously call a function and send errors to recovery continuation, skipping early returns\nexport function _catchInGenerator(body, recover) {\n\treturn _catch(body, function(e) {\n\t\tif (e === _earlyReturn) {\n\t\t\tthrow e;\n\t\t}\n\t\treturn recover(e);\n\t});\n}\n\n// Asynchronous generator class; accepts the entrypoint of the generator, to which it passes itself when the generator should start\nexport const _AsyncGenerator = /*#__PURE__*/(function() {\n\tfunction _AsyncGenerator(entry) {\n\t\tthis._entry = entry;\n\t\tthis._pact = null;\n\t\tthis._resolve = null;\n\t\tthis._return = null;\n\t\tthis._promise = null;\n\t}\n\n\tfunction _wrapReturnedValue(value) {\n\t\treturn { value: value, done: true };\n\t}\n\tfunction _wrapYieldedValue(value) {\n\t\treturn { value: value, done: false };\n\t}\n\n\t_AsyncGenerator.prototype._yield = function(value) {\n\t\t// Yield the value to the pending next call\n\t\tthis._resolve(value && value.then ? value.then(_wrapYieldedValue) : _wrapYieldedValue(value));\n\t\t// Return a pact for an upcoming next/return/throw call\n\t\treturn this._pact = new _Pact();\n\t};\n\t_AsyncGenerator.prototype.next = function(value) {\n\t\t// Advance the generator, starting it if it has yet to be started\n\t\tconst _this = this;\n\t\treturn _this._promise = new Promise(function (resolve) {\n\t\t\tconst _pact = _this._pact;\n\t\t\tif (_pact === null) {\n\t\t\t\tconst _entry = _this._entry;\n\t\t\t\tif (_entry === null) {\n\t\t\t\t\t// Generator is started, but not awaiting a yield expression\n\t\t\t\t\t// Abandon the next call!\n\t\t\t\t\treturn resolve(_this._promise);\n\t\t\t\t}\n\t\t\t\t// Start the generator\n\t\t\t\t_this._entry = null;\n\t\t\t\t_this._resolve = resolve;\n\t\t\t\tfunction returnValue(value) {\n\t\t\t\t\t_this._resolve(value && value.then ? value.then(_wrapReturnedValue) : _wrapReturnedValue(value));\n\t\t\t\t\t_this._pact = null;\n\t\t\t\t\t_this._resolve = null;\n\t\t\t\t}\n\t\t\t\tvar result = _entry(_this);\n\t\t\t\tif (result && result.then) {\n\t\t\t\t\tresult.then(returnValue, function(error) {\n\t\t\t\t\t\tif (error === _earlyReturn) {\n\t\t\t\t\t\t\treturnValue(_this._return);\n\t\t\t\t\t\t} else {\n\t\t\t\t\t\t\tconst pact = new _Pact();\n\t\t\t\t\t\t\t_this._resolve(pact);\n\t\t\t\t\t\t\t_this._pact = null;\n\t\t\t\t\t\t\t_this._resolve = null;\n\t\t\t\t\t\t\t_resolve(pact, 2, error);\n\t\t\t\t\t\t}\n\t\t\t\t\t});\n\t\t\t\t} else {\n\t\t\t\t\treturnValue(result);\n\t\t\t\t}\n\t\t\t} else {\n\t\t\t\t// Generator is started and a yield expression is pending, settle it\n\t\t\t\t_this._pact = null;\n\t\t\t\t_this._resolve = resolve;\n\t\t\t\t_settle(_pact, 1, value);\n\t\t\t}\n\t\t});\n\t};\n\t_AsyncGenerator.prototype.return = function(value) {\n\t\t// Early return from the generator if started, otherwise abandons the generator\n\t\tconst _this = this;\n\t\treturn _this._promise = new Promise(function (resolve) {\n\t\t\tconst _pact = _this._pact;\n\t\t\tif (_pact === null) {\n\t\t\t\tif (_this._entry === null) {\n\t\t\t\t\t// Generator is started, but not awaiting a yield expression\n\t\t\t\t\t// Abandon the return call!\n\t\t\t\t\treturn resolve(_this._promise);\n\t\t\t\t}\n\t\t\t\t// Generator is not started, abandon it and return the specified value\n\t\t\t\t_this._entry = null;\n\t\t\t\treturn resolve(value && value.then ? value.then(_wrapReturnedValue) : _wrapReturnedValue(value));\n\t\t\t}\n\t\t\t// Settle the yield expression with a rejected \"early return\" value\n\t\t\t_this._return = value;\n\t\t\t_this._resolve = resolve;\n\t\t\t_this._pact = null;\n\t\t\t_settle(_pact, 2, _earlyReturn);\n\t\t});\n\t};\n\t_AsyncGenerator.prototype.throw = function(error) {\n\t\t// Inject an exception into the pending yield expression\n\t\tconst _this = this;\n\t\treturn _this._promise = new Promise(function (resolve, reject) {\n\t\t\tconst _pact = _this._pact;\n\t\t\tif (_pact === null) {\n\t\t\t\tif (_this._entry === null) {\n\t\t\t\t\t// Generator is started, but not awaiting a yield expression\n\t\t\t\t\t// Abandon the throw call!\n\t\t\t\t\treturn resolve(_this._promise);\n\t\t\t\t}\n\t\t\t\t// Generator is not started, abandon it and return a rejected Promise containing the error\n\t\t\t\t_this._entry = null;\n\t\t\t\treturn reject(error);\n\t\t\t}\n\t\t\t// Settle the yield expression with the value as a rejection\n\t\t\t_this._resolve = resolve;\n\t\t\t_this._pact = null;\n\t\t\t_settle(_pact, 2, error);\n\t\t});\n\t};\n\n\t_AsyncGenerator.prototype[_asyncIteratorSymbol] = function() {\n\t\treturn this;\n\t};\n\t\n\treturn _AsyncGenerator;\n})();\n","import * as tf from '@tensorflow/tfjs';\nimport { Featurizer } from './featurizer';\nimport { LSTM } from './lstm';\nimport { Story } from './state';\n\ninterface Metrics {\n    /**\n     * Epoch of the training.\n     *\n     * Not defined for validation metrics.\n     */\n    epoch?: number;\n\n    /**\n     * Model's average loss.\n     *\n     * Only defined on training metrics.\n     */\n    loss?: number;\n\n    /**\n     * Accuracy of the model over the samples.\n     *\n     * Accuracy = proportion of correctly predicted samples.\n     */\n    accuracy: number;\n\n    /**\n     * Recall of the model over the samples.\n     *\n     * Recall = (number of correctly assigned samples to a label) / (number of samples that belong\n     * to a label)\n     */\n    recall: number;\n\n    /**\n     * Precision of the model over the samples.\n     *\n     * Precision = (number of correctly assigned samples to a label) / (number of samples assigned\n     * to a label)\n     */\n    precision: number;\n\n    /**\n     * Average confidence of the model in its prediction.\n     * Ideally, this value should be approximatively equal to the model's accuracy.\n     *\n     * Only defined for validation metrics.\n     */\n    averageConfidence?: number;\n\n    /**\n     * The array of the indexes of failling samples (< 0.999 accuracy).\n     */\n    failingSamples: number[];\n}\n\ninterface SampleData {\n    targets: tf.Tensor1D,\n    predictions: tf.Tensor1D,\n    loss: number,\n    isFailing: boolean\n}\n\ntype TrainingCallback = (metrics: Metrics) => any;\n\n/**\n * An implementation of Hybrid Code Networks(*) dialog manager.\n *\n * (*): Williams, Asadi, Zweig - 2017.\n *      Hybrid Code Networks: practical and efÔ¨Åcient end-to-end dialog control with supervised\n *      and reinforcement learning.\n */\nexport class HCN<Action> {\n    private actions: Action[];\n    private featurizers: Featurizer[];\n    private optimizer: tf.Optimizer;\n\n    private inputSize: number;\n    private hiddenSize: number;\n    private outputSize: number;\n\n    private lstm: LSTM;\n    private lstmH: tf.Tensor2D;\n    private lstmC: tf.Tensor2D;\n    private lstmDropout: number;\n\n    constructor(actions: Action[], featurizers: Featurizer[], hiddenSize: number = 128,\n        optimizer: tf.Optimizer = tf.train.adam(0.01), dropout: number = 0.2) {\n        this.actions = actions;\n        this.featurizers = featurizers;\n        this.optimizer = optimizer;\n\n        this.hiddenSize = hiddenSize;\n        this.outputSize = actions.length;\n\n        this.lstmDropout = dropout;\n    }\n\n    /**\n     * Initialize the model and it's featurizers.\n     */\n    async init() {\n        // Initialize asynchronously all featurizers.\n        await Promise.all(\n            this.featurizers.map((featurizer) => featurizer.init(this.actions))\n        );\n\n        // The model input size is the sum of the sizes of features vectors.\n        this.inputSize = this.featurizers\n            .map((featurizer) => featurizer.size)\n            .reduce((acc, size) => acc + size, 1);\n\n        this.lstm = new LSTM(this.inputSize, this.hiddenSize, this.outputSize, this.lstmDropout);\n\n        this.resetDialog();\n    }\n\n    /**\n     * Resets the state of the featurizers\n     */\n    resetDialog() {\n        this.featurizers.forEach((featurizer) => featurizer.resetDialog());\n        ({ c: this.lstmC, h: this.lstmH } = this.lstm.initLSTM());\n    }\n\n    /**\n     * Get the data returned from every featurizer's handleQuery method.\n     */\n    private async handleQuery(query: string): Promise<any[]> {\n        return Promise.all(\n            this.featurizers.map((featurizer) => featurizer.handleQuery(query))\n        );\n    }\n\n    /**\n     * Get the embedding vector resulted from every featurizers.\n     */\n    private getOptimizableFeatures(features: tf.Tensor[]): tf.Tensor1D {\n        return tf.tidy(() => {\n            const embeddings = this.featurizers.map(\n                (featurizer, idx) => featurizer.getOptimizableFeatures(features[idx])\n            );\n\n            // Add a zero to make tf.concat work consistently even with only one featurizer.\n            embeddings.push(tf.zeros([1]));\n\n            return <tf.Tensor1D> tf.concat(embeddings);\n        });\n    }\n\n    /**\n     * Inform every featurizers of the taken action.\n     */\n    private handleAction(action: Action) {\n        this.featurizers.map((featurizer) => featurizer.handleAction(action));\n    }\n\n    /**\n     * Get the final action mask resulted from every featurizers.\n     */\n    private getActionMask(): tf.Tensor1D {\n        return tf.tidy(() => this.featurizers\n            // Get action mask and convert them to tensors.\n            .map((featurizer) => <tf.Tensor1D> tf.tensor(\n                featurizer.getActionMask(),\n                undefined, 'float32'\n            ))\n            // Compute the product of every masks.\n            .reduce((acc, mask) => tf.mul(acc, mask), tf.ones([this.actions.length])));\n    }\n\n    /**\n     * Trains the model on a single training story.\n     */\n    private async fitStory(story: Story): Promise<SampleData> {\n        this.resetDialog();\n\n        // Prepare the input data.\n\n        const inputs: any[][] = [];\n        const masks: tf.Tensor1D[] = [];\n        const targets: tf.Tensor1D[] = [];\n\n        // For each story's state...\n        for (let stateIdx = 0; stateIdx < story.length; stateIdx += 1) {\n            const state = story[stateIdx];\n\n            // The query must be featurized before moving to the next state.\n            // eslint-disable-next-line no-await-in-loop\n            inputs.push(await this.handleQuery(state.query));\n\n            masks.push(this.getActionMask());\n\n            targets.push(\n                <tf.Tensor1D> tf.oneHot(\n                    this.actions.indexOf(state.action),\n                    this.outputSize\n                )\n            );\n\n            this.handleAction(state.action);\n        }\n\n        // Fit the sequence.\n        let data: SampleData;\n\n        this.optimizer.minimize(() => {\n            let { c, h } = this.lstm.initLSTM(false);\n\n            // Make a prediction for each step of the input sequence.\n            const predictions = inputs.map((features, idx) => {\n                const statePred = this.lstm.predict(\n                    <tf.Tensor1D> this.getOptimizableFeatures(features),\n                    <tf.Tensor2D> c,\n                    <tf.Tensor2D> h,\n                    <tf.Tensor1D> masks[idx]\n                );\n\n                c = statePred.nc;\n                h = statePred.nh;\n\n                return statePred.y;\n            });\n\n            const targetsMatrix = tf.stack(targets);\n            const predictionsMatrix = tf.stack(predictions);\n\n            // Compare the predicted sequence with the target.\n            const lossScalar = <tf.Scalar> tf.metrics.categoricalCrossentropy(\n                targetsMatrix, predictionsMatrix\n            ).mean();\n\n            // Store the necessary data to build metrics.\n            data = {\n                targets: tf.keep(targetsMatrix.argMax(1)),\n                predictions: tf.keep(predictionsMatrix.argMax(1)),\n                loss: <number> lossScalar.arraySync(),\n                isFailing: tf.metrics\n                    .categoricalAccuracy(targetsMatrix, predictionsMatrix)\n                    .mean()\n                    .arraySync() < 0.999\n            };\n\n            // Return the loss to the optimizer to update the model.\n            return lossScalar;\n        });\n\n        // BUG: two tensors leak in the memory at each loop :/\n        tf.dispose([inputs, targets]);\n\n        return data;\n    }\n\n\n    /**\n     * Trains the model using the training stories.\n     */\n    async train(stories: Story[], nEpochs: number = 12,\n        onEpochEnd?: TrainingCallback): Promise<Metrics> {\n        let epochMetrics: Metrics;\n\n        // For each epoch...\n        for (let epoch = 0; epoch < nEpochs; epoch += 1) {\n            const allTargets: tf.Tensor1D[] = [];\n            const allPredictions: tf.Tensor1D[] = [];\n            const allLosses: number[] = [];\n            const failingSamples: number[] = [];\n\n            // For each training story...\n            for (let storyIdx = 0; storyIdx < stories.length; storyIdx += 1) {\n                // (Each story must be fitted sequentially)\n                // eslint-disable-next-line no-await-in-loop\n                const storyData = await this.fitStory(stories[storyIdx]);\n\n                allTargets.push(storyData.targets);\n                allPredictions.push(storyData.predictions);\n                allLosses.push(storyData.loss);\n\n                if (storyData.isFailing) {\n                    failingSamples.push(storyIdx);\n                }\n            }\n\n            // Build the metrics.\n            const confusionMatrix = tf.tidy(() => tf.math.confusionMatrix(\n                tf.concat(allTargets),\n                tf.concat(allPredictions),\n                this.outputSize\n            ));\n\n            const truePredictions = tf.tidy(() => confusionMatrix\n                .mul(tf.eye(...confusionMatrix.shape))\n                .sum(0));\n\n            epochMetrics = {\n                epoch,\n                failingSamples,\n\n                accuracy: <number> tf.tidy(() => (\n                    truePredictions.sum().div(confusionMatrix.sum()).arraySync()\n                )),\n\n                recall: <number> tf.tidy(() => (\n                    truePredictions.div(confusionMatrix.sum(1)).mean().arraySync()\n                )),\n\n                precision: <number> tf.tidy(() => (\n                    truePredictions.div(confusionMatrix.sum(0)).mean().arraySync()\n                )),\n\n                loss: allLosses.reduce((a, b) => a + b) / allLosses.length\n            };\n\n            // Clear the tensors.\n            tf.dispose(allTargets);\n            tf.dispose(allPredictions);\n            tf.dispose([truePredictions, confusionMatrix]);\n\n            if (onEpochEnd !== undefined) {\n                onEpochEnd(epochMetrics);\n            }\n        }\n\n        this.resetDialog();\n        return epochMetrics;\n    }\n\n    /**\n     * Predict an action resulting from the given query.\n     */\n    async predict(query: string, sampleSize: number = 1,\n        temperature: number = 1): Promise<{action: Action, confidence: number}> {\n        // If the prediction is done without sampling, dropout is disabled.\n        if (sampleSize === 1) {\n            this.lstm.dropout = 0;\n        } else {\n            this.lstm.dropout = this.lstmDropout;\n        }\n\n        const features = this.getOptimizableFeatures(await this.handleQuery(query));\n        const masks = this.getActionMask();\n\n        const ys: tf.Tensor1D[] = [];\n        let prediction;\n\n        for (let i = 0; i < sampleSize; i += 1) {\n            tf.dispose(prediction);\n\n            prediction = this.lstm.predict(features, this.lstmC, this.lstmH, masks, temperature);\n            ys.push(prediction.y);\n        }\n\n        tf.dispose([this.lstmC, this.lstmH]);\n        this.lstmC = prediction.nc.clone();\n        this.lstmH = prediction.nh.clone();\n\n        const { mean: y, variance } = tf.tidy(() => tf.moments(tf.stack(ys), 0));\n\n        const actionIdx = <number> tf.tidy(() => y.argMax().arraySync());\n        const confidence = <number> tf.tidy(() => y.sub(variance.sqrt()).arraySync()[actionIdx]);\n\n        tf.dispose([features, masks, y, variance]);\n        tf.dispose(prediction);\n        tf.dispose(ys);\n\n        this.handleAction(this.actions[actionIdx]);\n\n        return { action: this.actions[actionIdx], confidence };\n    }\n\n    /**\n     * Evaluate the model using stories.\n     */\n    async score(stories: Story[], sampleSize: number = 1,\n        temperature: number = 1): Promise<Metrics> {\n        const targets: number[] = [];\n        const predictions: number[] = [];\n        const confidences: number[] = [];\n        const failingSamples: number[] = [];\n\n        /*\n            For each stories and states, make predictions.\n         */\n        for (let storyIdx = 0; storyIdx < stories.length; storyIdx += 1) {\n            this.resetDialog();\n\n            for (let stateIdx = 0; stateIdx < stories[storyIdx].length; stateIdx += 1) {\n                const state = stories[storyIdx][stateIdx];\n\n                // eslint-disable-next-line no-await-in-loop\n                const { action, confidence } = await this.predict(\n                    state.query, sampleSize, temperature\n                );\n\n                targets.push(this.actions.indexOf(state.action));\n                predictions.push(this.actions.indexOf(action));\n                confidences.push(confidence);\n\n                if (action !== state.action && !failingSamples.includes(storyIdx)) {\n                    failingSamples.push(storyIdx);\n                }\n            }\n        }\n\n        // Build a confusion matrix out of the prediction and build the metrics.\n        const confusionMatrix = tf.tidy(() => tf.math.confusionMatrix(\n            tf.tensor(targets), tf.tensor(predictions), this.outputSize\n        ));\n\n        const truePredictions = tf.tidy(() => confusionMatrix\n            .mul(tf.eye(...confusionMatrix.shape))\n            .sum(0));\n\n        const metrics: Metrics = {\n            failingSamples,\n\n            accuracy: <number> tf.tidy(() => (\n                truePredictions.sum().div(confusionMatrix.sum()).arraySync()\n            )),\n\n            recall: <number> tf.tidy(() => (\n                truePredictions.div(confusionMatrix.sum(1)).mean().arraySync()\n            )),\n\n            precision: <number> tf.tidy(() => (\n                truePredictions.div(confusionMatrix.sum(0)).mean().arraySync()\n            )),\n\n            averageConfidence: confidences.reduce((a, b) => a + b) / confidences.length\n        };\n\n        tf.dispose([truePredictions, confusionMatrix]);\n\n        this.resetDialog();\n        return metrics;\n    }\n\n    /**\n     * Load the models parameters from a JSON formatted string.\n     */\n    load(json: string) {\n        const parameters = JSON.parse(json);\n\n        this.featurizers.forEach((featurizer) => {\n            featurizer.load(parameters[featurizer.id]);\n        });\n\n        this.lstm.load(parameters.lstm);\n\n        this.resetDialog();\n    }\n\n    /**\n     * Export the models parameters in a JSON format.\n     */\n    async export(): Promise<string> {\n        const parameters = { lstm: await this.lstm.export() };\n\n        for (let idx = 0; idx < this.featurizers.length; idx += 1) {\n            const featurizer = this.featurizers[idx];\n\n            // eslint-disable-next-line no-await-in-loop\n            parameters[featurizer.id] = await featurizer.export();\n        }\n\n        return JSON.stringify(parameters);\n    }\n}\n","import * as tf from '@tensorflow/tfjs';\n\ntype JSONSerializable = {[key: string]: any};\n\n/**\n * A stateful featurizer that turns queries into numerical representations.\n */\nexport abstract class Featurizer {\n    /**\n     * An ID used by models for exportations.\n     */\n    readonly id: string;\n\n    /**\n     * The list of every action the model can take.\n     */\n    protected actions: any[];\n\n    /**\n     * The size of the vector returned by the featurizer.\n     */\n    readonly size: number;\n\n    /**\n     * Initialize the model, can be asynchronous async code.\n     * This method is executed by the model during it's initialization,\n     * it will also set the actions attribute.\n     */\n    async init(actions: any[]) {\n        this.actions = actions;\n    }\n\n    /**\n     * Featurizes and handle a text query.\n     *\n     * This method can directly return a 1D tensor to provide features to the model.\n     * Alternatively, it can returns data of any type if the Featurizer implement a custom\n     * getOptimizableFeatures method to handle those data.\n     * @async\n     */\n    abstract handleQuery(query: string): Promise<any>;\n\n    /**\n     * Turn the data returned by handleQuery into an embedding vector.\n     * This function is used to expose featurizer variables to the model optimizer for training.\n     *\n     * Reimplementing this method is not necessary if your featurizer is not meant to be optimizable\n     * through gradient descent.\n     * In this case, just return the feature vector directly using the handleQuery method.\n     *\n     * It's important to keep this function stateless, it should only depend of its tensor argument\n     * and of featurizer's variables.\n     */\n    // eslint-disable-next-line class-methods-use-this\n    getOptimizableFeatures(data: any): tf.Tensor1D {\n        return <tf.Tensor1D> data;\n    }\n\n    /**\n     * Let the featurizer know what action the model has taken.\n     */\n    // eslint-disable-next-line no-unused-vars, class-methods-use-this\n    handleAction(action: any): void {}\n\n    /**\n     * Produce an action mask according to featurizer state.\n     * (Generally, this method is reimplemented in stateful featurizers)\n     *\n     * @returns An array of boolean mapping every actions availability.\n     */\n    getActionMask(): boolean[] {\n        return this.actions.map(() => true);\n    }\n\n    /**\n     * Resets the state of the featurizer (if the stateful feature is used).\n     */\n    // eslint-disable-next-line class-methods-use-this\n    resetDialog(): void {}\n\n    /**\n     * Load parameters extracted from a JSON-like document.\n     */\n    // eslint-disable-next-line no-unused-vars, class-methods-use-this\n    load(parameters: JSONSerializable) {}\n\n    /**\n     * Export the featurizer's internal parameters to be serialized along the model.\n     */\n    // eslint-disable-next-line class-methods-use-this\n    async export(): Promise<JSONSerializable> {\n        return {};\n    }\n}\n","import * as tf from '@tensorflow/tfjs';\nimport * as use from '@tensorflow-models/universal-sentence-encoder';\nimport { Featurizer } from './featurizer';\n\n/**\n * Featurizes queries using the Universal Sentence Encoder model.\n */\nexport class USE extends Featurizer {\n    readonly id = 'Universal Sentence Encoder';\n\n    private encoder: use.UniversalSentenceEncoder;\n    private emptyEncoding: tf.Tensor1D;\n\n    readonly size = 512;\n\n    /**\n     * Initializes the Universal Sentence Encoder model.\n     */\n    async init(actions: any[]) {\n        await super.init(actions);\n        this.encoder = await use.load();\n\n        // Cache the empty string embed (for optimization purpose).\n        this.emptyEncoding = await this.encodeQuery('');\n    }\n\n    /**\n     * Encodes a query using the model.\n     */\n    private async encodeQuery(query: string): Promise<tf.Tensor1D> {\n        const embed = await this.encoder.embed([query]);\n        const squeezedEmbed = <tf.Tensor1D> embed.squeeze();\n        tf.dispose(embed);\n\n        return squeezedEmbed;\n    }\n\n    /**\n     * @return A tensor of shape [512].\n     */\n    async handleQuery(query: string): Promise<tf.Tensor1D> {\n        // When the query is empty, return the cached empty query encoding.\n        if (!query) {\n            return this.emptyEncoding.clone();\n        }\n\n        return this.encodeQuery(query);\n    }\n}\n","/* eslint-disable no-bitwise */\n\n/**\n * Hash a string.\n * Based on https://stackoverflow.com/a/7616484\n */\nexport function hashcode(input: string) {\n    let hash = 0;\n\n    for (let i = 0; i < input.length; i += 1) {\n        const chr = input.charCodeAt(i);\n\n        hash = ((hash << 5) - hash) + chr;\n        hash |= 0; // Convert to 32bit integer\n    }\n\n    return hash;\n}\n","import * as tf from '@tensorflow/tfjs';\nimport { Featurizer } from './featurizer';\nimport { hashcode } from './utils/hashcode';\n\n/**\n * Featurizes queries as bag of words.\n * The algorithm use the hashing trick to avoid having to store a vocabulary in the memory.\n */\nexport class BOW extends Featurizer {\n    readonly id = 'Bag-of-Words';\n    readonly size: number;\n\n    constructor(size: number) {\n        super();\n        this.size = size;\n    }\n\n    /**\n     * @return A tensor of shape [size].\n     */\n    async handleQuery(query: string): Promise<tf.Tensor1D> {\n        return tf.tidy(() => {\n            const indexes = query.toLowerCase()\n                .split(/\\W/g)\n                .map((word) => hashcode(word) % this.size);\n\n            return <tf.Tensor1D> tf.oneHot(indexes, this.size).asType('float32').sum(0);\n        });\n    }\n}\n","/**\n * Compute the Levenshtein distance between two strings using the Wagner-Fisher algorithm.\n * (as described at https://en.wikipedia.org/wiki/Wagner%E2%80%93Fischer_algorithm)\n */\nexport function levenshteinDistance(s1: string, s2: string): number {\n    const d = Array.from(\n        Array(s1.length + 1),\n        () => new Array(s2.length + 1).fill(0)\n    );\n\n    for (let i = 1; i <= s1.length; i += 1) {\n        d[i][0] = i;\n    }\n\n    for (let j = 1; j <= s2.length; j += 1) {\n        d[0][j] = j;\n    }\n\n    for (let j = 0; j < s2.length; j += 1) {\n        for (let i = 0; i < s1.length; i += 1) {\n            const substitutionCost = (s1[i] !== s2[j]) ? 1 : 0;\n\n            d[i + 1][j + 1] = Math.min(\n                d[i][j + 1] + 1,\n                d[i + 1][j] + 1,\n                d[i][j] + substitutionCost\n            );\n        }\n    }\n\n    return d[s1.length][s2.length] / Math.max(s1.length, s2.length, 1);\n}\n","import * as tf from '@tensorflow/tfjs';\nimport { Featurizer } from './featurizer';\nimport { levenshteinDistance } from './utils/levenshtein_distance';\n\n/**\n * Featurize queries by pooling words embedding using SWEM-concat(*).\n *\n * (*): Dinghan Shen, Guoyin Wang, Wenlin Wang, Martin Renqiang Min, Qinliang Su, Yizhe Zhang,\n *      Chunyuan Li, Ricardo Henao, Lawrence Carin- 2018.\n *      Baseline Needs More Love: On Simple Word-Embedding-Based Models and\n *      Associated Pooling Mechanisms.\n */\nexport class WordEmbedding extends Featurizer {\n    readonly id = 'Word Embedding';\n    readonly size: number;\n\n    private loaderFunction: () => Promise<string>;\n    private vectors: {[word: string]: number[]};\n\n    /**\n     * @param loaderFunction A function that loads the json string containing the embedding.\n     * @param size The dimension of the word embedding\n     */\n    constructor(loaderFunction: () => Promise<string>, size: number) {\n        super();\n        this.size = 2 * size;\n        this.loaderFunction = loaderFunction;\n    }\n\n    async init(actions: any[]) {\n        await super.init(actions);\n        this.vectors = JSON.parse(await this.loaderFunction());\n    }\n\n    async handleQuery(query: string): Promise<tf.Tensor1D> {\n        return <tf.Tensor1D> tf.tidy(() => {\n            const tokens = query.toLowerCase() // Word embeddings are uncased.\n                .split(/\\W/g) // Tokenize at each non-word character.\n                .filter((token) => token.length > 0);\n\n            const embeddings: tf.Tensor1D[] = [];\n\n            tokens.forEach((token) => {\n                // If the token in in the vocabulary, just use its embedding.\n                if (Object.keys(this.vectors).includes(token)) {\n                    embeddings.push(tf.tensor(this.vectors[token]));\n\n                // If the token is out of vocabulary, use the most similarly spelled token instead.\n                } else {\n                    let bestToken: string;\n                    let lowestDistance: number = Infinity;\n\n                    Object.keys(this.vectors).forEach((vocabToken) => {\n                        const distance = levenshteinDistance(vocabToken, token);\n\n                        if (distance < lowestDistance) {\n                            bestToken = vocabToken;\n                            lowestDistance = distance;\n                        }\n                    });\n\n                    if (lowestDistance < 0.5) {\n                        embeddings.push(tf.tensor(this.vectors[bestToken]));\n                    }\n                }\n            });\n\n            // When there is no embeddable tokens, return a zeros vector.\n            if (embeddings.length === 0) {\n                return tf.zeros([this.size]);\n            }\n\n            const embeddingsMatrix = tf.stack(embeddings);\n\n            return tf.concat([embeddingsMatrix.mean(0), embeddingsMatrix.max(0)]);\n        });\n    }\n}\n","import { levenshteinDistance } from './levenshtein_distance';\n\ntype Match = { extract: string, score: number };\n\nexport function fuzzyMatch(text: string, substring: string): Match {\n    let bestMatch: Match = { extract: undefined, score: 0 };\n\n    for (let i = 0; i < text.length; i += 1) {\n        const extract = text.substring(i, i + substring.length);\n\n        const aMatch = {\n            extract,\n            score: 1 - levenshteinDistance(extract, substring)\n        };\n\n        if (aMatch.score === 1) {\n            return aMatch;\n        }\n\n        if (aMatch.score > bestMatch.score) {\n            bestMatch = aMatch;\n        }\n    }\n\n    return bestMatch;\n}\n","import * as tf from '@tensorflow/tfjs';\nimport { Featurizer } from './featurizer';\nimport { fuzzyMatch } from './utils/fuzzy_match';\nimport { hashcode } from './utils/hashcode';\n\ntype Categories = {[category: string]: string[]};\ntype Value = { category: string, extract: string, score: number };\n\nexport class CategoricalSlot extends Featurizer {\n    readonly id: string;\n    readonly size: number;\n\n    private categoryNames: string[];\n    private categories: Categories;\n\n    private dependantActions: any[];\n    private inverselyDependantActions: any[];\n\n    private threshold: number;\n    private value: Value;\n\n    constructor(categories: Categories, dependantActions: any[] = [],\n        inverselyDependantActions: any[] = [], threshold: number = 0.75) {\n        super();\n\n        this.categoryNames = Object.keys(categories);\n        this.categories = categories;\n\n        this.id = `Categorical Slot (${hashcode(JSON.stringify(this.categoryNames))})`;\n\n        this.dependantActions = dependantActions;\n        this.inverselyDependantActions = inverselyDependantActions;\n\n        this.threshold = threshold;\n\n        this.size = 2 * this.categoryNames.length;\n    }\n\n    async init(actions: any[]) {\n        await super.init(actions);\n        this.resetDialog();\n    }\n\n    private featurizeValue(value: Value): tf.Tensor1D {\n        const categoryNames = Object.keys(this.categories);\n\n        return <tf.Tensor1D> tf.oneHot(\n            categoryNames.indexOf(value.category),\n            categoryNames.length\n        );\n    }\n\n    async handleQuery(query: string): Promise<tf.Tensor1D> {\n        let bestValue: Value = { category: undefined, extract: undefined, score: 0 };\n\n        Object.entries(this.categories).forEach(([category, keywords]) => {\n            // Find the best match of one category.\n            const match = keywords\n                .map((keyword) => fuzzyMatch(query.toLowerCase(), keyword.toLowerCase()))\n                .filter((m) => m.score >= this.threshold)\n                .reduce(\n                    (hm, m) => (hm.score > m.score ? hm : m),\n                    { extract: undefined, score: 0 }\n                );\n\n            // If this match is the best of every categories.\n            if (match.score > bestValue.score) {\n                bestValue = { category, ...match };\n            }\n        });\n\n        const features = tf.tidy(() => (\n            tf.concat([\n                this.featurizeValue(bestValue),\n                this.featurizeValue(this.value)\n            ])\n        ));\n\n        if (bestValue.category !== undefined) {\n            this.value = bestValue;\n        }\n\n        return features;\n    }\n\n    getActionMask(): boolean[] {\n        return this.actions.map((action) => {\n            const u = this.value.extract === undefined;\n            const d = this.dependantActions.includes(action);\n            const i = this.inverselyDependantActions.includes(action);\n\n            return (u && (i || !d)) || (!u && !i);\n        });\n    }\n\n    resetDialog() {\n        this.value = { category: undefined, extract: undefined, score: 0 };\n    }\n\n    getValue(): Value {\n        return this.value;\n    }\n}\n","import * as tf from '@tensorflow/tfjs';\nimport { Featurizer } from './featurizer';\nimport { initializeVariable } from './utils/initialize_variable';\n\n/**\n * Rule-based featurizer improving model robustness.\n *\n * - Featurize the previous action the model has taken.\n * - Mask the LUS action when the user has just talked.\n *   (Force the model to reply at least once)\n * - Mask the previous action.\n *   (Prevent looping : the model can't take two times in a row the same action)\n */\nexport class ActionFeaturizer extends Featurizer {\n    readonly id = 'Action Featurizer';\n    size: number;\n\n    private LUSAction: any;\n    private maskLUS: boolean;\n    private maskPreviousAction: boolean;\n\n    private userTalked: boolean;\n    private previousAction: any;\n\n    private embeddings: tf.Tensor;\n\n    /**\n     * @param maskLUS Enable the masking of LUS when the user has just talked\n     * @param maskPreviousAction Enable the masking of the previous action\n     * @param LUSAction The action the bot takes to let the user talk\n     */\n    constructor(maskLUS: boolean = true,\n        maskPreviousAction: boolean = true, LUSAction: any = 'LUS') {\n        super();\n        this.maskLUS = maskLUS;\n        this.maskPreviousAction = maskPreviousAction;\n        this.LUSAction = LUSAction;\n\n        this.resetDialog();\n    }\n\n    async init(actions: any[]) {\n        await super.init(actions);\n\n        this.size = actions.length;\n        this.embeddings = initializeVariable([this.size, this.size]);\n    }\n\n    async handleQuery(query: string): Promise<tf.Tensor2D> {\n        return tf.tidy(() => {\n            this.userTalked = query !== '';\n\n            // One-hot encode the previous action.\n            return <tf.Tensor2D> tf.oneHot(\n                [this.actions.indexOf(this.previousAction)],\n                this.actions.length\n            );\n        });\n    }\n\n    getOptimizableFeatures(data: tf.Tensor2D): tf.Tensor1D {\n        return <tf.Tensor1D> data.matMul(this.embeddings).squeeze();\n    }\n\n    handleAction(action: any) {\n        // Store the new action if it's not the LUS action.\n        this.previousAction = action !== this.LUSAction ? action : this.previousAction;\n    }\n\n    getActionMask(): boolean[] {\n        const mask = super.getActionMask();\n\n        // Mask LUS when the user talk and the option is enabled.\n        if (this.maskLUS && this.userTalked) {\n            mask[this.actions.indexOf(this.LUSAction)] = false;\n        }\n\n        // Mask the previous action when the option is enabled and if applicable.\n        if (this.maskPreviousAction && this.actions.includes(this.previousAction)) {\n            mask[this.actions.indexOf(this.previousAction)] = false;\n        }\n\n        return mask;\n    }\n\n    resetDialog() {\n        this.userTalked = false;\n        this.previousAction = undefined;\n    }\n\n    load(parameters: {embeddings: number[][]}) {\n        this.embeddings = tf.tidy(() => tf.tensor(parameters.embeddings).variable());\n    }\n\n    async export(): Promise<{embeddings: number[][]}> {\n        return {\n            embeddings: <number[][]> await this.embeddings.array()\n        };\n    }\n}\n","import { Story, State } from '../state';\n\n/**\n * Parse a source string formatted according the Wisty Training Story syntax.\n * Usually, this source string is extracted using fetch or from a file.\n */\nexport function parseStories(source: string): Story[] {\n    const stories: Story[] = [];\n    let story: Story = [];\n    let inputAnswered = true;\n\n    source.split('\\n').forEach((line) => {\n        const newStory = /^## *([^#].*)?$/gm.exec(line);\n        const newInput = /^> *(.*)$/gm.exec(line);\n        const newAction = /^- *(\\w*)$/gm.exec(line);\n\n        /*\n            New story\n            ## Story name\n        */\n        if (newStory != null && story.length > 0) {\n            story.push(<State> { query: '', action: 'LUS' });\n            stories.push(story); // Push previous story.\n            story = [];\n\n        /*\n            New user input\n            > user input\n        */\n        } else if (newInput != null) {\n            // Add a LUS action to mark the end of the previous turn.\n            if (story.length > 0) story.push(<State> { query: '', action: 'LUS' });\n\n            story.push(<State> { query: newInput[1], action: undefined });\n            inputAnswered = false;\n\n        /*\n            New bot action\n            (> user input)\n            (- action_name)\n            - action_name\n        */\n        } else if (newAction != null && inputAnswered) {\n            story.push(<State> { query: '', action: newAction[1] });\n\n        /*\n            New bot action (first answer)\n            (> user input)\n            - action_name\n        */\n        } else if (newAction != null && !inputAnswered) {\n            // eslint-disable-next-line prefer-destructuring\n            story[story.length - 1].action = newAction[1];\n            inputAnswered = true;\n        }\n    });\n\n    // Finalize the last story\n    if (story.length > 0) {\n        story.push(<State> { query: '', action: 'LUS' });\n        stories.push(story);\n    }\n\n    return stories;\n}\n","import { Story } from '../state';\n\n/**\n * Split a list of stories into random train and test subsets.\n *\n * @param stories A list of stories.\n * @param testSize The proportion of stories to put in the test subset.\n */\nexport function trainTestSplit(stories: Story[], testSize: number):\n    {train: Story[], test: Story[]} {\n    const test: Story[] = [];\n\n    for (let i = 0; i / stories.length < testSize; i += 1) {\n        test.push(...stories.splice(\n            Math.floor(Math.random() * stories.length), 1\n        ));\n    }\n\n    return { train: stories, test };\n}\n"],"names":["initializeVariable","shape","scalar","init","tf","initializer","heNormal","zeros","randomNormal","Error","randomTensor","apply","asScalar","variable","LSTM","inputSize","hiddenSize","outputSize","dropout","this","lstmKernel","lstmBias","lstmForgetBias","lstmInitH","lstmInitC","denseWeights","denseBias","initLSTM","clone","c","h","predict","x","mask","temperature","_this","nc","nh","y","matMul","add","squeeze","div","softmax","mul","load","weights","_this2","_this4","array","_Pact","prototype","then","onFulfilled","onRejected","result","state","s","callback","_settle","v","e","o","value","pact","bind","observer","_isSettledPact","thenable","_for","test","update","body","stage","shouldContinue","updateValue","reject","_resumeAfterTest","_resumeAfterBody","_resumeAfterUpdate","Symbol","iterator","asyncIterator","HCN","actions","featurizers","optimizer","adam","length","lstmDropout","Promise","all","map","featurizer","size","reduce","acc","lstm","resetDialog","forEach","lstmC","lstmH","handleQuery","query","getOptimizableFeatures","features","embeddings","_this5","idx","push","handleAction","action","getActionMask","_this6","undefined","fitStory","story","data","_this8","minimize","predictions","inputs","statePred","masks","targetsMatrix","targets","predictionsMatrix","lossScalar","categoricalCrossentropy","mean","argMax","loss","arraySync","isFailing","categoricalAccuracy","stateIdx","_push","indexOf","train","stories","nEpochs","onEpochEnd","epochMetrics","_this10","epoch","confusionMatrix","allTargets","allPredictions","truePredictions","sum","failingSamples","accuracy","recall","precision","allLosses","a","b","storyIdx","storyData","sampleSize","_this12","prediction","ys","i","variance","actionIdx","confidence","sub","sqrt","score","_this14","metrics","averageConfidence","confidences","includes","json","parameters","JSON","parse","id","_this16","stringify","Featurizer","USE","use","_this3","encoder","encodeQuery","emptyEncoding","embed","squeezedEmbed","hashcode","input","hash","charCodeAt","BOW","indexes","toLowerCase","split","word","asType","levenshteinDistance","s1","s2","d","Array","from","fill","j","Math","min","max","WordEmbedding","loaderFunction","vectors","tokens","filter","token","Object","keys","bestToken","lowestDistance","Infinity","vocabToken","distance","embeddingsMatrix","fuzzyMatch","text","substring","bestMatch","extract","aMatch","CategoricalSlot","categories","dependantActions","inverselyDependantActions","threshold","categoryNames","featurizeValue","category","bestValue","entries","match","keyword","m","hm","u","getValue","maskLUS","maskPreviousAction","LUSAction","userTalked","previousAction","source","inputAnswered","line","newStory","exec","newInput","newAction","testSize","splice","floor","random"],"mappings":"qWAKgBA,EAAmBC,EAAiBC,EAChDC,GACA,gBAFgDD,IAAAA,GAAkB,YAClEC,IAAAA,EAA8B,MACvBC,OAAQ,WACX,IAAIC,EAEJ,OAAQF,GACR,IAAK,KACDE,EAAcD,eAAgBE,SAAS,IACvC,MAEJ,IAAK,QACDD,EAAcD,eAAgBG,QAC9B,MAEJ,IAAK,SACDF,EAAcD,eAAgBI,aAAa,IAC3C,MAEJ,QACI,UAAUC,8EACkEN,QAIhF,IAAIO,EAAeL,EAAYM,MAAMV,GAGrC,OAFIC,IAAQQ,EAAeA,EAAaE,YAEjCF,EAAaG,iBCxBfC,aAqBT,WAAYC,EAAmBC,EAAoBC,EAAoBC,YAAAA,IAAAA,EAAkB,IACrFC,KAAKC,WAAapB,EAAmB,CAACe,EAAYC,EAAyB,EAAbA,IAC9DG,KAAKE,SAAWrB,EAAmB,CAAc,EAAbgB,IAAiB,EAAO,SAC5DG,KAAKG,eAAiBtB,EAAmB,CAAC,IAAI,EAAM,SACpDmB,KAAKI,UAAYvB,EAAmB,CAAC,EAAGgB,IACxCG,KAAKK,UAAYxB,EAAmB,CAAC,EAAGgB,IAExCG,KAAKM,aAAezB,EAAmB,CAACgB,EAAYC,IACpDE,KAAKO,UAAY1B,EAAmB,CAACiB,IAAa,EAAO,SAEzDE,KAAKD,QAAUA,EA/BvB,2BAuCIS,SAAA,SAASC,GACL,gBADKA,IAAAA,GAAiB,GACf,CACHC,EAAkBD,EAAQT,KAAKK,UAAUI,QAAUT,KAAKK,UACxDM,EAAkBF,EAAQT,KAAKI,UAAUK,QAAUT,KAAKI,cAWhEQ,QAAA,SAAQC,EAAgBH,EAAgBC,EAAgBG,EACpDC,cACA,gBADAA,IAAAA,EAAsB,GACf9B,OAAQ,iBAEMA,gBACD+B,EAAKb,eACHa,EAAKf,WACLe,EAAKd,SACLjB,QAAS,CAAC4B,IACxBF,EAAGD,GALAO,OAAIC,OASPC,EAAkBlC,UACTiC,EAAIF,EAAKjB,SACjBqB,OAAOJ,EAAKV,cACZe,IAAIL,EAAKT,WACTe,UACAC,IAAIR,GACJS,UACAC,UAAIX,EAAAA,EAAQ,GAKjB,MAAO,CAAEK,EAFTA,EAAIA,EAAEI,IAAItC,MAAOkC,IAELF,GAAAA,EAAIC,GAAAA,QAOxBQ,KAAA,SAAKC,cACD1C,OAAQ,WAEJ2C,EAAK3B,WAAahB,SAAU0C,EAAQ1B,YAAYP,WAChDkC,EAAK1B,SAAWjB,SAAU0C,EAAQzB,UAAUR,WAC5CkC,EAAKzB,eAAiBlB,SAAU0C,EAAQxB,gBAAgBT,WACxDkC,EAAKxB,UAAYnB,SAAU0C,EAAQvB,WAAWV,WAC9CkC,EAAKvB,UAAYpB,SAAU0C,EAAQtB,WAAWX,WAC9CkC,EAAKtB,aAAerB,SAAU0C,EAAQrB,cAAcZ,WACpDkC,EAAKrB,UAAYtB,SAAU0C,EAAQpB,WAAWb,4CAS5BM,4BAAA6B,EAAK5B,WAAW6B,iDAClBD,EAAK3B,SAAS4B,iDACRD,EAAK1B,eAAe2B,iDACzBD,EAAKzB,UAAU0B,iDACfD,EAAKxB,UAAUyB,iDACZD,EAAKvB,aAAawB,iDACrBD,EAAKtB,UAAUuB,0BAGpC,MAVgB,CACZ7B,aACAC,WACAC,iBACAC,YACAC,YACAC,eACAC,2BA7GZ,yCCPO,MAAMwB,EAAqB,WACjC,SAASA,KAiCT,OAhCAA,EAAMC,UAAUC,KAAO,SAASC,EAAaC,GAC5C,MAAMC,EAAS,IAAIL,EACbM,EAAQrC,KAAKsC,EACnB,GAAID,EAAO,CACV,MAAME,EAAmB,EAARF,EAAYH,EAAcC,EAC3C,GAAII,EAAU,CACb,IACCC,EAAQJ,EAAQ,EAAGG,EAASvC,KAAKyC,IAChC,MAAOC,GACRF,EAAQJ,EAAQ,EAAGM,GAEpB,OAAON,EAEP,OAAOpC,KAiBT,OAdAA,KAAK2C,EAAI,SAAS3B,GACjB,IACC,MAAM4B,EAAQ5B,EAAMyB,EACN,EAAVzB,EAAMsB,EACTE,EAAQJ,EAAQ,EAAGF,EAAcA,EAAYU,GAASA,GAC5CT,EACVK,EAAQJ,EAAQ,EAAGD,EAAWS,IAE9BJ,EAAQJ,EAAQ,EAAGQ,GAEnB,MAAOF,GACRF,EAAQJ,EAAQ,EAAGM,KAGdN,GAEDL,EAlC0B,GAsC3B,SAASS,EAAQK,EAAMR,EAAOO,GACpC,IAAKC,EAAKP,EAAG,CACZ,GAAIM,aAAiBb,EAAO,CAC3B,IAAIa,EAAMN,EAOT,YADAM,EAAMD,EAAIH,EAAQM,KAAK,KAAMD,EAAMR,IALvB,EAARA,IACHA,EAAQO,EAAMN,GAEfM,EAAQA,EAAMH,EAMhB,GAAIG,GAASA,EAAMX,KAElB,YADAW,EAAMX,KAAKO,EAAQM,KAAK,KAAMD,EAAMR,GAAQG,EAAQM,KAAK,KAAMD,EAAM,IAGtEA,EAAKP,EAAID,EACTQ,EAAKJ,EAAIG,EACT,MAAMG,EAAWF,EAAKF,EAClBI,GACHA,EAASF,IAKL,SAASG,EAAeC,GAC9B,OAAOA,aAAoBlB,GAAsB,EAAbkB,EAASX,EA6LvC,SAASY,EAAKC,EAAMC,EAAQC,GAElC,IADA,IAAIC,IACK,CACR,IAAIC,EAAiBJ,IAIrB,GAHIH,EAAeO,KAClBA,EAAiBA,EAAed,IAE5Bc,EACJ,OAAOnB,EAER,GAAImB,EAAetB,KAAM,CACxBqB,EAAQ,EACR,MAED,IAAIlB,EAASiB,IACb,GAAIjB,GAAUA,EAAOH,KAAM,CAC1B,IAAIe,EAAeZ,GAEZ,CACNkB,EAAQ,EACR,MAHAlB,EAASA,EAAOE,EAMlB,GAAIc,EAAQ,CACX,IAAII,EAAcJ,IAClB,GAAII,GAAeA,EAAYvB,OAASe,EAAeQ,GAAc,CACpEF,EAAQ,EACR,QAIH,IAAIT,EAAO,IAAId,EACX0B,EAASjB,EAAQM,KAAK,KAAMD,EAAM,GAEtC,OADW,IAAVS,EAAcC,EAAetB,KAAKyB,GAA8B,IAAVJ,EAAclB,EAAOH,KAAK0B,GAAoBH,EAAYvB,KAAK2B,IAAqB3B,UAAK,EAAQwB,GACjJZ,EACP,SAASc,EAAiBf,GACzBR,EAASQ,EACT,EAAG,CACF,GAAIQ,IACHI,EAAcJ,MACKI,EAAYvB,OAASe,EAAeQ,GAEtD,YADAA,EAAYvB,KAAK2B,GAAoB3B,UAAK,EAAQwB,GAKpD,KADAF,EAAiBJ,MACOH,EAAeO,KAAoBA,EAAed,EAEzE,YADAD,EAAQK,EAAM,EAAGT,GAGlB,GAAImB,EAAetB,KAElB,YADAsB,EAAetB,KAAKyB,GAAkBzB,UAAK,EAAQwB,GAIhDT,EADJZ,EAASiB,OAERjB,EAASA,EAAOK,UAERL,IAAWA,EAAOH,MAC5BG,EAAOH,KAAK0B,GAAkB1B,UAAK,EAAQwB,GAE5C,SAASC,EAAiBH,GACrBA,GACHnB,EAASiB,MACKjB,EAAOH,KACpBG,EAAOH,KAAK0B,GAAkB1B,UAAK,EAAQwB,GAE3CE,EAAiBvB,GAGlBI,EAAQK,EAAM,EAAGT,GAGnB,SAASwB,KACJL,EAAiBJ,KAChBI,EAAetB,KAClBsB,EAAetB,KAAKyB,GAAkBzB,UAAK,EAAQwB,GAEnDC,EAAiBH,GAGlBf,EAAQK,EAAM,EAAGT,IA5K2C,oBAAXyB,SAA0BA,OAAOC,WAAaD,OAAOC,SAAWD,OAAO,qBA6DvD,oBAAXA,SAA0BA,OAAOE,gBAAkBF,OAAOE,cAAgBF,OAAO,8BCxJ7HG,aAcT,WAAYC,EAAmBC,EAA2BrE,EACtDsE,EAA+CpE,YADOF,IAAAA,EAAqB,cAC3EsE,IAAAA,EAA0BlF,QAASmF,KAAK,eAAOrE,IAAAA,EAAkB,IACjEC,KAAKiE,QAAUA,EACfjE,KAAKkE,YAAcA,EACnBlE,KAAKmE,UAAYA,EAEjBnE,KAAKH,WAAaA,EAClBG,KAAKF,WAAamE,EAAQI,OAE1BrE,KAAKsE,YAAcvE,EAvB3B,2BA6BUf,0BAGEgB,4BADEuE,QAAQC,IACV5C,EAAKsC,YAAYO,IAAI,SAACC,UAAeA,EAAW1F,KAAK4C,EAAKqC,6BAI9DrC,EAAKhC,UAAYgC,EAAKsC,YACjBO,IAAI,SAACC,UAAeA,EAAWC,OAC/BC,OAAO,SAACC,EAAKF,UAASE,EAAMF,GAAM,GAEvC/C,EAAKkD,KAAO,IAAInF,EAAKiC,EAAKhC,UAAWgC,EAAK/B,WAAY+B,EAAK9B,WAAY8B,EAAK0C,aAE5E1C,EAAKmD,gBA1Cb,sCAgDIA,YAAA,WACI/E,KAAKkE,YAAYc,QAAQ,SAACN,UAAeA,EAAWK,sBAChB/E,KAAK8E,KAAKtE,WAAxCR,KAAKiF,QAARvE,EAAkBV,KAAKkF,QAARvE,KAMRwE,qBAAYC,OACtB,OAAOb,QAAQC,IACXxE,KAAKkE,YAAYO,IAAI,SAACC,UAAeA,EAAWS,YAAYC,MA1DxE,sCAiEYC,uBAAA,SAAuBC,cAC3B,OAAOrG,OAAQ,WACX,IAAMsG,EAAaC,EAAKtB,YAAYO,IAChC,SAACC,EAAYe,UAAQf,EAAWW,uBAAuBC,EAASG,MAMpE,OAFAF,EAAWG,KAAKzG,QAAS,CAAC,KAELA,SAAUsG,QAO/BI,aAAA,SAAaC,GACjB5F,KAAKkE,YAAYO,IAAI,SAACC,UAAeA,EAAWiB,aAAaC,QAMzDC,cAAA,sBACJ,OAAO5G,OAAQ,kBAAM6G,EAAK5B,YAErBO,IAAI,SAACC,UAA6BzF,SAC/ByF,EAAWmB,qBACXE,EAAW,aAGdnB,OAAO,SAACC,EAAK/D,UAAS7B,MAAO4F,EAAK/D,IAAO7B,OAAQ,CAAC6G,EAAK7B,QAAQI,eAM1D2B,kBAASC,wBA8BnB,IAAIC,EA8CJ,OA5CAC,EAAKhC,UAAUiC,SAAS,iBACLD,EAAKrB,KAAKtE,UAAS,GAA5BE,IAAAA,EAAGC,IAAAA,EAGH0F,EAAcC,EAAO7B,IAAI,SAACa,EAAUG,GACtC,IAAMc,EAAYJ,EAAKrB,KAAKlE,QACVuF,EAAKd,uBAAuBC,GAC5B5E,EACAC,EACA6F,EAAMf,IAMxB,OAHA/E,EAAI6F,EAAUtF,GACdN,EAAI4F,EAAUrF,GAEPqF,EAAUpF,IAGfsF,EAAgBxH,QAASyH,GACzBC,EAAoB1H,QAASoH,GAG7BO,EAAyB3H,UAAW4H,wBACtCJ,EAAeE,GACjBG,OAcF,OAXAZ,EAAO,CACHQ,QAASzH,OAAQwH,EAAcM,OAAO,IACtCV,YAAapH,OAAQ0H,EAAkBI,OAAO,IAC9CC,KAAeJ,EAAWK,YAC1BC,UAAWjI,UACNkI,oBAAoBV,EAAeE,GACnCG,OACAG,YAAc,MAIhBL,IAIX3H,UAAW,CAACqH,EAAQI,IAEbR,KA3EPlG,KAAAmG,EAAKpB,cAIL,IAAMuB,EAAkB,GAClBE,EAAuB,GACvBE,EAAyB,GAGtBU,EAAW,wBAAGA,EAAWnB,EAAM5B,4BAAQ+C,GAAY,eACxD,IAAM/E,EAAQ4D,EAAMmB,KAIpBd,EAAOZ,4BAAWS,EAAKhB,YAAY9C,EAAM+C,yBAAzCiC,OAAAf,KAEAE,EAAMd,KAAKS,EAAKN,iBAEhBa,EAAQhB,KACUzG,SACVkH,EAAKlC,QAAQqD,QAAQjF,EAAMuD,QAC3BO,EAAKrG,aAIbqG,EAAKR,aAAatD,EAAMuD,4DAhIpC,sCAyLU2B,eAAMC,EAAkBC,EAC1BC,YAD0BD,IAAAA,EAAkB,YAExCE,eAiEJ,OADAC,EAAK7C,cACE4C,KApDyB3H,KAVvB6H,EAAQ,wBAAGA,EAAQJ,uBAASI,GAAS,4BAsB1C,IAAMC,EAAkB7I,OAAQ,kBAAMA,OAAQ6I,gBAC1C7I,SAAU8I,GACV9I,SAAU+I,GACVJ,EAAK9H,cAGHmI,EAAkBhJ,OAAQ,kBAAM6I,EACjCrG,IAAIxC,YAAAA,EAAU6I,EAAgBhJ,QAC9BoJ,IAAI,KAETP,EAAe,CACXE,MAAAA,EACAM,eAAAA,EAEAC,SAAmBnJ,OAAQ,kBACvBgJ,EAAgBC,MAAM3G,IAAIuG,EAAgBI,OAAOjB,cAGrDoB,OAAiBpJ,OAAQ,kBACrBgJ,EAAgB1G,IAAIuG,EAAgBI,IAAI,IAAIpB,OAAOG,cAGvDqB,UAAoBrJ,OAAQ,kBACxBgJ,EAAgB1G,IAAIuG,EAAgBI,IAAI,IAAIpB,OAAOG,cAGvDD,KAAMuB,EAAU3D,OAAO,SAAC4D,EAAGC,UAAMD,EAAIC,IAAKF,EAAUlE,QAIxDpF,UAAW8I,GACX9I,UAAW+I,GACX/I,UAAW,CAACgJ,EAAiBH,SAEV/B,IAAf2B,GACAA,EAAWC,GAxDf,IAAMI,EAA4B,GAC5BC,EAAgC,GAChCO,EAAsB,GACtBJ,EAA2B,GAGxBO,EAAW,wBAAGA,EAAWlB,EAAQnD,4BAAQqE,GAAY,sCAGlCd,EAAK5B,SAASwB,EAAQkB,mBAAxCC,GAENZ,EAAWrC,KAAKiD,EAAUjC,SAC1BsB,EAAetC,KAAKiD,EAAUtC,aAC9BkC,EAAU7C,KAAKiD,EAAU3B,MAErB2B,EAAUzB,WACViB,EAAezC,KAAKgD,wFA/MxC,sCAkQU9H,iBAAQwE,EAAewD,EACzB7H,YADyB6H,IAAAA,EAAqB,YAC9C7H,IAAAA,EAAsB,aAGlBf,KAAA6I,EAAK/D,KAAK/E,QADK,IAAf6I,EACoB,EAEAC,EAAKvE,kBAGZuE,EAAKxD,8CAA6BwD,EAAK1D,YAAYC,qBAMpE,IANA,IAII0D,EAJExD,cACAkB,EAAQqC,EAAKhD,gBAEbkD,EAAoB,GAGjBC,EAAI,EAAGA,EAAIJ,EAAYI,GAAK,EACjC/J,UAAW6J,GAEXA,EAAaD,EAAK/D,KAAKlE,QAAQ0E,EAAUuD,EAAK5D,MAAO4D,EAAK3D,MAAOsB,EAAOzF,GACxEgI,EAAGrD,KAAKoD,EAAW3H,GAGvBlC,UAAW,CAAC4J,EAAK5D,MAAO4D,EAAK3D,QAC7B2D,EAAK5D,MAAQ6D,EAAW7H,GAAGR,QAC3BoI,EAAK3D,MAAQ4D,EAAW5H,GAAGT,cAEGxB,OAAQ,kBAAMA,UAAWA,QAAS8J,GAAK,KAAvD5H,IAAN2F,KAASmC,IAAAA,SAEXC,EAAqBjK,OAAQ,kBAAMkC,EAAE4F,SAASE,cAC9CkC,EAAsBlK,OAAQ,kBAAMkC,EAAEiI,IAAIH,EAASI,QAAQpC,YAAYiC,KAQ7E,OANAjK,UAAW,CAACqG,EAAUkB,EAAOrF,EAAG8H,IAChChK,UAAW6J,GACX7J,UAAW8J,GAEXF,EAAKlD,aAAakD,EAAK5E,QAAQiF,IAExB,CAAEtD,OAAQiD,EAAK5E,QAAQiF,GAAYC,WAAAA,KAvSlD,sCA6SUG,eAAM9B,EAAkBoB,EAC1B7H,YAD0B6H,IAAAA,EAAqB,YAC/C7H,IAAAA,EAAsB,wBA+BtB,IAAM+G,EAAkB7I,OAAQ,kBAAMA,OAAQ6I,gBAC1C7I,SAAUyH,GAAUzH,SAAUoH,GAAckD,EAAKzJ,cAG/CmI,EAAkBhJ,OAAQ,kBAAM6I,EACjCrG,IAAIxC,YAAAA,EAAU6I,EAAgBhJ,QAC9BoJ,IAAI,KAEHsB,EAAmB,CACrBrB,eAAAA,EAEAC,SAAmBnJ,OAAQ,kBACvBgJ,EAAgBC,MAAM3G,IAAIuG,EAAgBI,OAAOjB,cAGrDoB,OAAiBpJ,OAAQ,kBACrBgJ,EAAgB1G,IAAIuG,EAAgBI,IAAI,IAAIpB,OAAOG,cAGvDqB,UAAoBrJ,OAAQ,kBACxBgJ,EAAgB1G,IAAIuG,EAAgBI,IAAI,IAAIpB,OAAOG,cAGvDwC,kBAAmBC,EAAY9E,OAAO,SAAC4D,EAAGC,UAAMD,EAAIC,IAAKiB,EAAYrF,QAMzE,OAHApF,UAAW,CAACgJ,EAAiBH,IAE7ByB,EAAKxE,cACEyE,KAlDHxJ,KATE0G,EAAoB,GACpBL,EAAwB,GACxBqD,EAAwB,GACxBvB,EAA2B,GAKxBO,EAAW,wBAAGA,EAAWlB,EAAQnD,4BAAQqE,GAAY,eAC1Da,EAAKxE,cAEA,IAAIqC,EAAW,wBAAGA,EAAWI,EAAQkB,GAAUrE,4BAAQ+C,GAAY,eACpE,IAAM/E,EAAQmF,EAAQkB,GAAUtB,GADuC,uBAIlCmC,EAAK3I,QACtCyB,EAAM+C,MAAOwD,EAAY7H,yBADrB6E,IAAAA,OAAQuD,IAAAA,WAIhBzC,EAAQhB,KAAK6D,EAAKtF,QAAQqD,QAAQjF,EAAMuD,SACxCS,EAAYX,KAAK6D,EAAKtF,QAAQqD,QAAQ1B,IACtC8D,EAAYhE,KAAKyD,GAEbvD,IAAWvD,EAAMuD,QAAWuC,EAAewB,SAASjB,IACpDP,EAAezC,KAAKgD,kGAvUxC,sCAgXIhH,KAAA,SAAKkI,GACD,IAAMC,EAAaC,KAAKC,MAAMH,GAE9B5J,KAAKkE,YAAYc,QAAQ,SAACN,GACtBA,EAAWhD,KAAKmI,EAAWnF,EAAWsF,OAG1ChK,KAAK8E,KAAKpD,KAAKmI,EAAW/E,MAE1B9E,KAAK+E,6CAO4B/E,4BAAAiK,EAAKnF,6CAStC,OAAOgF,KAAKI,UAAUL,GATtB,IAAMA,EAAa,CAAE/E,QAEZW,EAAM,wBAAGA,EAAMwE,EAAK/F,YAAYG,4BAAQoB,GAAO,eACpD,IAAMf,EAAauF,EAAK/F,YAAYuB,GADmB,uBAIrBf,6BAAlCmF,EAAWnF,EAAWsF,2CAtYlC,2VClEsBG,sDAqBZnL,cAAKiF,cACPjE,KAAKiE,QAAUA,oBAtBvB,sCA+CIoB,uBAAA,SAAuBa,GACnB,OAAqBA,KAOzBP,aAAA,SAAaC,OAQbC,cAAA,WACI,YAAY5B,QAAQQ,IAAI,yBAO5BM,YAAA,eAMArD,KAAA,SAAKmI,yBAOD,uBAAO,UCpFFO,cAAb,8DACkB,6BAKLpJ,OAAO,aANpB,2BAWUhC,cAAKiF,qDACKjF,YAAKiF,2CACIoG,kCAArBC,EAAKC,0BAGsBD,EAAKE,YAAY,sBAA5CF,EAAKG,sBAhBb,sCAsBkBD,qBAAYpF,8BACFpF,KAAKuK,QAAQG,MAAM,CAACtF,mBAAlCsF,GACN,IAAMC,EAA8BD,EAAMpJ,UAG1C,OAFArC,UAAWyL,GAEJC,IA3Bf,sCAiCUxF,qBAAYC,OAEd,uBAAKA,EACMpF,KAGCwK,YAAYpF,GAHbpF,KAAKyK,cAAchK,SApCtC,uCAAyB0J,YCDTS,EAASC,GAGrB,IAFA,IAAIC,EAAO,EAEF9B,EAAI,EAAGA,EAAI6B,EAAMxG,OAAQ2E,GAAK,EAGnC8B,GAASA,GAAQ,GAAKA,EAFVD,EAAME,WAAW/B,GAG7B8B,GAAQ,EAGZ,OAAOA,MCREE,cAIT,WAAYrG,gBACR3D,yBAJU,eAKVA,EAAK2D,KAAOA,8BAMVQ,qBAAYC,aAI0BpF,KAHxC,uBAAOf,OAAQ,WACX,IAAMgM,EAAU7F,EAAM8F,cACjBC,MAAM,OACN1G,IAAI,SAAC2G,UAASR,EAASQ,GAAQd,EAAK3F,OAEzC,OAAqB1F,SAAUgM,EAASX,EAAK3F,MAAM0G,OAAO,WAAWnD,IAAI,MAlBrF,uCAAyBiC,YCJTmB,EAAoBC,EAAYC,GAM5C,IALA,IAAMC,EAAIC,MAAMC,KACZD,MAAMH,EAAGlH,OAAS,GAClB,sBAAUqH,MAAMF,EAAGnH,OAAS,GAAGuH,KAAK,KAG/B5C,EAAI,EAAGA,GAAKuC,EAAGlH,OAAQ2E,GAAK,EACjCyC,EAAEzC,GAAG,GAAKA,EAGd,IAAK,IAAI6C,EAAI,EAAGA,GAAKL,EAAGnH,OAAQwH,GAAK,EACjCJ,EAAE,GAAGI,GAAKA,EAGd,IAAK,IAAIA,EAAI,EAAGA,EAAIL,EAAGnH,OAAQwH,GAAK,EAChC,IAAK,IAAI7C,EAAI,EAAGA,EAAIuC,EAAGlH,OAAQ2E,GAAK,EAGhCyC,EAAEzC,EAAI,GAAG6C,EAAI,GAAKC,KAAKC,IACnBN,EAAEzC,GAAG6C,EAAI,GAAK,EACdJ,EAAEzC,EAAI,GAAG6C,GAAK,EACdJ,EAAEzC,GAAG6C,IALiBN,EAAGvC,KAAOwC,EAAGK,GAAM,EAAI,IAUzD,OAAOJ,EAAEF,EAAGlH,QAAQmH,EAAGnH,QAAUyH,KAAKE,IAAIT,EAAGlH,OAAQmH,EAAGnH,OAAQ,OClBvD4H,cAWT,WAAYC,EAAuCvH,gBAC/C3D,yBAXU,iBAYVA,EAAK2D,KAAO,EAAIA,EAChB3D,EAAKkL,eAAiBA,WAd9B,2BAiBUlN,cAAKiF,qDACKjF,YAAKiF,2CACeqG,EAAK4B,mCAArC5B,EAAK6B,QAAUrC,KAAKC,aAnB5B,sCAsBU5E,qBAAYC,aAUUpF,KATxB,uBAAqBf,OAAQ,WACzB,IAAMmN,EAAShH,EAAM8F,cAChBC,MAAM,OACNkB,OAAO,SAACC,UAAUA,EAAMjI,OAAS,IAEhCkB,EAA4B,GA4BlC,GA1BA6G,EAAOpH,QAAQ,SAACsH,GAEZ,GAAIC,OAAOC,KAAKhH,EAAK2G,SAASxC,SAAS2C,GACnC/G,EAAWG,KAAKzG,SAAUuG,EAAK2G,QAAQG,SAGpC,CACH,IAAIG,EACAC,EAAyBC,SAE7BJ,OAAOC,KAAKhH,EAAK2G,SAASnH,QAAQ,SAAC4H,GAC/B,IAAMC,EAAWvB,EAAoBsB,EAAYN,GAE7CO,EAAWH,IACXD,EAAYG,EACZF,EAAiBG,KAIrBH,EAAiB,IACjBnH,EAAWG,KAAKzG,SAAUuG,EAAK2G,QAAQM,QAMzB,IAAtBlH,EAAWlB,OACX,OAAOpF,QAAS,CAACuG,EAAKb,OAG1B,IAAMmI,EAAmB7N,QAASsG,GAElC,OAAOtG,SAAU,CAAC6N,EAAiBhG,KAAK,GAAIgG,EAAiBd,IAAI,QA9D7E,uCAAmC7B,YCRnB4C,EAAWC,EAAcC,GAGrC,IAFA,IAAIC,EAAmB,CAAEC,aAASpH,EAAWuD,MAAO,GAE3CN,EAAI,EAAGA,EAAIgE,EAAK3I,OAAQ2E,GAAK,EAAG,CACrC,IAAMmE,EAAUH,EAAKC,UAAUjE,EAAGA,EAAIiE,EAAU5I,QAE1C+I,EAAS,CACXD,QAAAA,EACA7D,MAAO,EAAIgC,EAAoB6B,EAASF,IAG5C,GAAqB,IAAjBG,EAAO9D,MACP,OAAO8D,EAGPA,EAAO9D,MAAQ4D,EAAU5D,QACzB4D,EAAYE,GAIpB,OAAOF,MChBEG,cAaT,WAAYC,EAAwBC,EAChCC,EAAuCC,yBADPF,IAAAA,EAA0B,aAC1DC,IAAAA,EAAmC,aAAIC,IAAAA,EAAoB,MAC3DzM,sBAEK0M,cAAgBnB,OAAOC,KAAKc,GACjCtM,EAAKsM,WAAaA,EAElBtM,EAAKgJ,wBAA0BY,EAASd,KAAKI,UAAUlJ,EAAK0M,oBAE5D1M,EAAKuM,iBAAmBA,EACxBvM,EAAKwM,0BAA4BA,EAEjCxM,EAAKyM,UAAYA,EAEjBzM,EAAK2D,KAAO,EAAI3D,EAAK0M,cAAcrJ,gBA3B3C,2BA8BUrF,cAAKiF,qDACKjF,YAAKiF,oBACjBqG,EAAKvF,gBAhCb,sCAmCY4I,eAAA,SAAe/K,GACnB,IAAM8K,EAAgBnB,OAAOC,KAAKxM,KAAKsN,YAEvC,OAAqBrO,SACjByO,EAAcpG,QAAQ1E,EAAMgL,UAC5BF,EAAcrJ,WAIhBc,qBAAYC,aAGCpF,KAFX6N,EAAmB,CAAED,cAAU7H,EAAWoH,aAASpH,EAAWuD,MAAO,GAEzEiD,OAAOuB,QAAQtI,EAAK8H,YAAYtI,QAAQ,gBAAE4I,OAEhCG,OACDtJ,IAAI,SAACuJ,UAAYjB,EAAW3H,EAAM8F,cAAe8C,EAAQ9C,iBACzDmB,OAAO,SAAC4B,UAAMA,EAAE3E,OAAS9D,EAAKiI,YAC9B7I,OACG,SAACsJ,EAAID,UAAOC,EAAG5E,MAAQ2E,EAAE3E,MAAQ4E,EAAKD,GACtC,CAAEd,aAASpH,EAAWuD,MAAO,IAIjCyE,EAAMzE,MAAQuE,EAAUvE,QACxBuE,KAAcD,SAAAA,GAAaG,MAInC,IAAMzI,EAAWrG,OAAQ,kBACrBA,SAAU,CACNuG,EAAKmI,eAAeE,GACpBrI,EAAKmI,eAAenI,EAAK5C,WAQjC,YAJ2BmD,IAAvB8H,EAAUD,WACVpI,EAAK5C,MAAQiL,mBAGVvI,GA1Ef,sCA6EIO,cAAA,sBACI,YAAY5B,QAAQQ,IAAI,SAACmB,GACrB,IAAMuI,OAA2BpI,IAAvBD,EAAKlD,MAAMuK,QACf1B,EAAI3F,EAAKyH,iBAAiB5D,SAAS/D,GACnCoD,EAAIlD,EAAK0H,0BAA0B7D,SAAS/D,GAElD,OAAQuI,IAAMnF,IAAMyC,KAAS0C,IAAMnF,OAI3CjE,YAAA,WACI/E,KAAK4C,MAAQ,CAAEgL,cAAU7H,EAAWoH,aAASpH,EAAWuD,MAAO,MAGnE8E,SAAA,WACI,YAAYxL,UA5FiBuH,kCCuBjC,WAAYkE,EACRC,EAAoCC,yBAD5BF,IAAAA,GAAmB,YAC3BC,IAAAA,GAA8B,YAAMC,IAAAA,EAAiB,QACrDvN,yBAnBU,oBAoBVA,EAAKqN,QAAUA,EACfrN,EAAKsN,mBAAqBA,EAC1BtN,EAAKuN,UAAYA,EAEjBvN,EAAK+D,uBAzBb,2BA4BU/F,cAAKiF,qDACKjF,YAAKiF,oBAEjBqG,EAAK3F,KAAOV,EAAQI,OACpBiG,EAAK/E,WAAa1G,EAAmB,CAACyL,EAAK3F,KAAM2F,EAAK3F,SAhC9D,sCAmCUQ,qBAAYC,aAEVpF,KADJ,uBAAOf,OAAQ,WAIX,OAHAuG,EAAKgJ,WAAuB,KAAVpJ,EAGGnG,SACjB,CAACuG,EAAKvB,QAAQqD,QAAQ9B,EAAKiJ,iBAC3BjJ,EAAKvB,QAAQI,WA1C7B,sCA+CIgB,uBAAA,SAAuBa,GACnB,OAAqBA,EAAK9E,OAAOpB,KAAKuF,YAAYjE,aAGtDqE,aAAA,SAAaC,GAET5F,KAAKyO,eAAiB7I,IAAW5F,KAAKuO,UAAY3I,EAAS5F,KAAKyO,kBAGpE5I,cAAA,WACI,IAAM/E,cAAa+E,yBAYnB,OATI7F,KAAKqO,SAAWrO,KAAKwO,aACrB1N,EAAKd,KAAKiE,QAAQqD,QAAQtH,KAAKuO,aAAc,GAI7CvO,KAAKsO,oBAAsBtO,KAAKiE,QAAQ0F,SAAS3J,KAAKyO,kBACtD3N,EAAKd,KAAKiE,QAAQqD,QAAQtH,KAAKyO,kBAAmB,GAG/C3N,KAGXiE,YAAA,WACI/E,KAAKwO,YAAa,EAClBxO,KAAKyO,oBAAiB1I,KAG1BrE,KAAA,SAAKmI,GACD7J,KAAKuF,WAAatG,OAAQ,kBAAMA,SAAU4K,EAAWtE,YAAY7F,6DAK9BM,KAAKuF,WAAWzD,0BADnD,MAAO,CACHyD,gBAnFZ,uCAAsC4E,oKCPTuE,GACzB,IAAMlH,EAAmB,GACrBvB,EAAe,GACf0I,GAAgB,EAsDpB,OApDAD,EAAOvD,MAAM,MAAMnG,QAAQ,SAAC4J,GACxB,IAAMC,EAAW,oBAAoBC,KAAKF,GACpCG,EAAW,cAAcD,KAAKF,GAC9BI,EAAY,eAAeF,KAAKF,GAMtB,MAAZC,GAAoB5I,EAAM5B,OAAS,GACnC4B,EAAMP,KAAa,CAAEN,MAAO,GAAIQ,OAAQ,QACxC4B,EAAQ9B,KAAKO,GACbA,EAAQ,IAMW,MAAZ8I,GAEH9I,EAAM5B,OAAS,GAAG4B,EAAMP,KAAa,CAAEN,MAAO,GAAIQ,OAAQ,QAE9DK,EAAMP,KAAa,CAAEN,MAAO2J,EAAS,GAAInJ,YAAQG,IACjD4I,GAAgB,GAQI,MAAbK,GAAqBL,EAC5B1I,EAAMP,KAAa,CAAEN,MAAO,GAAIQ,OAAQoJ,EAAU,KAO9B,MAAbA,GAAsBL,IAE7B1I,EAAMA,EAAM5B,OAAS,GAAGuB,OAASoJ,EAAU,GAC3CL,GAAgB,KAKpB1I,EAAM5B,OAAS,IACf4B,EAAMP,KAAa,CAAEN,MAAO,GAAIQ,OAAQ,QACxC4B,EAAQ9B,KAAKO,IAGVuB,6BCvDoBA,EAAkByH,GAI7C,IAFA,IAAM9L,EAAgB,GAEb6F,EAAI,EAAGA,EAAIxB,EAAQnD,OAAS4K,EAAUjG,GAAK,EAChD7F,EAAKuC,WAALvC,EAAaqE,EAAQ0H,OACjBpD,KAAKqD,MAAMrD,KAAKsD,SAAW5H,EAAQnD,QAAS,IAIpD,MAAO,CAAEkD,MAAOC,EAASrE,KAAAA"}