{"version":3,"file":"index.esm.js","sources":["../src/featurizers/featurizer.ts","../src/utils/levenshtein_distance.ts","../src/utils/fuzzy_match.ts","../src/utils/hashcode.ts","../src/utils/initialize_variable.ts","../src/utils/lstm.ts","../src/utils/trie.ts","../src/featurizers/action_featurizer.ts","../src/featurizers/bow.ts","../src/featurizers/use.ts","../src/featurizers/word_embedding.ts","../src/models/hcn.ts","../src/tools/parse_wistyml.ts","../src/slots/slot.ts","../src/slots/categorical_slot.ts","../src/tools/nlu_formatter.ts","../src/tools/train_test_split.ts","../src/tools/keyed_vectors.ts"],"sourcesContent":["import * as tf from '@tensorflow/tfjs';\n\ntype JSONSerializable = {[key: string]: any};\n\n/**\n * A stateful featurizer that turns queries into numerical representations.\n *\n * @abstract\n */\nexport class Featurizer {\n    /**\n     * An ID used by models for exportations.\n     */\n    readonly id: string;\n\n    /**\n     * The list of every action the model can take.\n     */\n    protected actions: any[];\n\n    /**\n     * The size of the vector returned by the featurizer.\n     * By default it's set to 1 which is the default for a featurizer that returns no features.\n     */\n    readonly size: number = 1;\n\n    /**\n     * Initialize the model, can be asynchronous async code.\n     *\n     * This method is executed by the model during it's initialization,\n     * it will also set the actions attribute.\n     */\n    async init(actions: any[]) {\n        this.actions = actions;\n    }\n\n    /**\n     * Featurizes and handle a text query.\n     *\n     * @remarks\n     * This method can directly return a 1D tensor to provide features to the model.\n     * Alternatively, it can returns data of any type if the Featurizer implement a custom\n     * getOptimizableFeatures method to handle those data.\n     * If this method doesn't return something, no features will be passed to the model.\n     */\n    // eslint-disable-next-line no-unused-vars, class-methods-use-this, no-empty-function\n    async handleQuery(query: string): Promise<any> {}\n\n    /**\n     * Turn the data returned by handleQuery into an embedding vector.\n     * This function is used to expose featurizer variables to the model optimizer for training.\n     *\n     * Reimplementing this method is not necessary if your featurizer is not meant to be optimizable\n     * through gradient descent.\n     * In this case, just return the feature vector directly using the handleQuery method.\n     *\n     * @remarks\n     * It's important to keep this function stateless, it should only depend of its tensor argument\n     * and of featurizer's variables.\n     */\n    // eslint-disable-next-line class-methods-use-this\n    getOptimizableFeatures(data: any): tf.Tensor1D {\n        if (data === undefined) {\n            return tf.zeros([1]);\n        }\n\n        return <tf.Tensor1D> data;\n    }\n\n    /**\n     * Let the featurizer know what action the model has taken.\n     */\n    // eslint-disable-next-line no-unused-vars, class-methods-use-this\n    handleAction(action: any): void {}\n\n    /**\n     * Produce an action mask according to featurizer state.\n     * (Generally, this method is reimplemented in stateful featurizers)\n     *\n     * @returns An array of boolean mapping every actions availability.\n     */\n    getActionMask(): boolean[] {\n        return this.actions.map(() => true);\n    }\n\n    /**\n     * Resets the state of the featurizer (if the stateful feature is used).\n     */\n    // eslint-disable-next-line class-methods-use-this\n    resetDialog(): void {}\n\n    /**\n     * Load parameters extracted from a JSON-like document.\n     */\n    // eslint-disable-next-line no-unused-vars, class-methods-use-this\n    load(parameters: JSONSerializable) {}\n\n    /**\n     * Export the featurizer's internal parameters to be serialized along the model.\n     */\n    // eslint-disable-next-line class-methods-use-this\n    async export(): Promise<JSONSerializable> {\n        return {};\n    }\n}\n","/**\n * Compute the Levenshtein distance between two strings using the\n * [Wagner-Fisher algorithm](https://en.wikipedia.org/wiki/Wagner%E2%80%93Fischer_algorithm).\n */\nexport function levenshteinDistance(s1: string, s2: string): number {\n    const d = Array.from(\n        Array(s1.length + 1),\n        () => new Array(s2.length + 1).fill(0)\n    );\n\n    for (let i = 1; i <= s1.length; i += 1) {\n        d[i][0] = i;\n    }\n\n    for (let j = 1; j <= s2.length; j += 1) {\n        d[0][j] = j;\n    }\n\n    for (let j = 0; j < s2.length; j += 1) {\n        for (let i = 0; i < s1.length; i += 1) {\n            const substitutionCost = (s1[i] !== s2[j]) ? 1 : 0;\n\n            d[i + 1][j + 1] = Math.min(\n                d[i][j + 1] + 1,\n                d[i + 1][j] + 1,\n                d[i][j] + substitutionCost\n            );\n        }\n    }\n\n    return d[s1.length][s2.length] / Math.max(s1.length, s2.length, 1);\n}\n","import { levenshteinDistance } from './levenshtein_distance';\n\ntype Match = { extract: string, score: number };\n\nexport function fuzzyMatch(text: string, substring: string): Match {\n    let bestMatch: Match = { extract: undefined, score: 0 };\n\n    for (let i = 0; i < text.length; i += 1) {\n        const extract = text.substring(i, i + substring.length);\n\n        const aMatch = {\n            extract,\n            score: 1 - levenshteinDistance(extract, substring)\n        };\n\n        if (aMatch.score === 1) {\n            return aMatch;\n        }\n\n        if (aMatch.score > bestMatch.score) {\n            bestMatch = aMatch;\n        }\n    }\n\n    return bestMatch;\n}\n","/* eslint-disable no-bitwise */\n\n/**\n * Hash a string.\n * Based on https://stackoverflow.com/a/7616484\n */\nexport function hashcode(input: string) {\n    let hash = 0;\n\n    for (let i = 0; i < input.length; i += 1) {\n        const chr = input.charCodeAt(i);\n\n        hash = ((hash << 5) - hash) + chr;\n        hash |= 0; // Convert to 32bit integer\n    }\n\n    return hash;\n}\n","import * as tf from '@tensorflow/tfjs';\n\n/**\n * Initialize a variable of a given shape.\n */\nexport function initializeVariable(shape: number[], scalar: boolean = false,\n    init: 'he'|'zeros'|'normal' = 'he'): tf.Variable {\n    return tf.tidy(() => {\n        let initializer;\n\n        switch (init) {\n        case 'he':\n            initializer = tf.initializers.heNormal({});\n            break;\n\n        case 'zeros':\n            initializer = tf.initializers.zeros();\n            break;\n\n        case 'normal':\n            initializer = tf.initializers.randomNormal({});\n            break;\n\n        default:\n            throw new Error(\n                `Expected parameter init to take value 'he', 'zeros' or 'normal' not '${init}'.`\n            );\n        }\n\n        let randomTensor = initializer.apply(shape);\n        if (scalar) randomTensor = randomTensor.asScalar();\n\n        return randomTensor.variable();\n    });\n}\n","import * as tf from '@tensorflow/tfjs';\nimport { initializeVariable } from './initialize_variable';\n\ntype LSTMPrediction = {y: tf.Tensor1D, nc: tf.Tensor2D, nh: tf.Tensor2D};\n\n/**\n * An LSTM cell with a dense layer on its top.\n */\nexport class LSTM {\n    // LSTM parameters :\n    private lstmKernel: tf.Tensor;\n    private lstmBias: tf.Tensor;\n    private lstmForgetBias: tf.Tensor;\n    private lstmInitH: tf.Tensor;\n    private lstmInitC: tf.Tensor;\n\n    // Dense layer parameters :\n    private denseWeights: tf.Tensor;\n    private denseBias: tf.Tensor;\n\n    // Let dropout be public to allow to change its value when training/inference.\n    public dropout: number;\n\n    /**\n     * @param inputSize The dimension of the input data.\n     * @param hiddenSize The dimension of the output of the LSTM, passed to the dense layer.\n     * @param outputSize The dimension of the output data.\n     * @param dropout The dropout rate between the LSTM cell and the dense layer.\n     */\n    constructor(inputSize: number, hiddenSize: number, outputSize: number, dropout: number = 0.2) {\n        this.lstmKernel = initializeVariable([inputSize + hiddenSize, hiddenSize * 4]);\n        this.lstmBias = initializeVariable([hiddenSize * 4], false, 'zeros');\n        this.lstmForgetBias = initializeVariable([1], true, 'zeros'); // (scalar)\n        this.lstmInitH = initializeVariable([1, hiddenSize]);\n        this.lstmInitC = initializeVariable([1, hiddenSize]);\n\n        this.denseWeights = initializeVariable([hiddenSize, outputSize]);\n        this.denseBias = initializeVariable([outputSize], false, 'zeros');\n\n        this.dropout = dropout;\n    }\n\n    /**\n     * Gives the initial state values of the LSTM (c and h).\n     *\n     * @param clone If it is necessary to clone states variable or no.\n     */\n    initLSTM(clone: boolean = true): {c: tf.Tensor2D, h: tf.Tensor2D} {\n        return {\n            c: <tf.Tensor2D> (clone ? this.lstmInitC.clone() : this.lstmInitC),\n            h: <tf.Tensor2D> (clone ? this.lstmInitH.clone() : this.lstmInitH)\n        };\n    }\n\n    /**\n     * Make a prediction given an input and state values (c and h).\n     * @param x A vector of shape [inputSize].\n     * @param c LSTM's state value.\n     * @param h LSTM's last output value.\n     * @param mask A vector of ones and zeros of shape [outputSize].\n     */\n    predict(x: tf.Tensor1D, c: tf.Tensor2D, h: tf.Tensor2D, mask?: tf.Tensor1D,\n        temperature: number = 1): LSTMPrediction {\n        return tf.tidy(() => {\n            // Execute the LSTM cell.\n            const [nc, nh] = tf.basicLSTMCell(\n                <tf.Scalar> this.lstmForgetBias,\n                <tf.Tensor2D> this.lstmKernel,\n                <tf.Tensor1D> this.lstmBias,\n                <tf.Tensor2D> tf.stack([x]),\n                h, c\n            );\n\n            // Execute the dense layer on top of the LSTM cell.\n            let y = <tf.Tensor1D> tf\n                .dropout(nh, this.dropout)\n                .matMul(this.denseWeights)\n                .add(this.denseBias)\n                .squeeze()\n                .div(temperature)\n                .softmax()\n                .mul(mask ?? 1);\n\n            // Apply normalization after the mask to get probabilities.\n            y = y.div(tf.sum(y));\n\n            return { y, nc, nh };\n        });\n    }\n\n    /**\n     * Update the given model parameters.\n     */\n    load(weights: {[key: string]: any}) {\n        tf.tidy(() => {\n            // Convert every parameter to a tf variable tensor.\n            this.lstmKernel = tf.tensor(weights.lstmKernel).variable();\n            this.lstmBias = tf.tensor(weights.lstmBias).variable();\n            this.lstmForgetBias = tf.tensor(weights.lstmForgetBias).variable();\n            this.lstmInitH = tf.tensor(weights.lstmInitH).variable();\n            this.lstmInitC = tf.tensor(weights.lstmInitC).variable();\n            this.denseWeights = tf.tensor(weights.denseWeights).variable();\n            this.denseBias = tf.tensor(weights.denseBias).variable();\n        });\n    }\n\n    /**\n     * Return all the LSTM model parameters.\n     */\n    async export(): Promise<{[key: string]: any}> {\n        const exports = {\n            lstmKernel: await this.lstmKernel.array(),\n            lstmBias: await this.lstmBias.array(),\n            lstmForgetBias: await this.lstmForgetBias.array(),\n            lstmInitH: await this.lstmInitH.array(),\n            lstmInitC: await this.lstmInitC.array(),\n            denseWeights: await this.denseWeights.array(),\n            denseBias: await this.denseBias.array()\n        };\n\n        return exports;\n    }\n}\n","/**\n * Inspired by Trie.js\n * https://gist.github.com/tpae/72e1c54471e88b689f85ad2b3940a8f0\n */\n\n/**\n * A node holding a character and having a parent node and several children.\n */\nexport class TrieNode {\n    readonly parent: TrieNode;\n    readonly key: string;\n    readonly childs: {[key: string]: TrieNode};\n    ending: boolean;\n\n    constructor(key: string, parent: TrieNode) {\n        this.key = key;\n        this.parent = parent;\n\n        this.childs = {};\n        this.ending = false;\n    }\n\n    addChild(child: TrieNode) {\n        this.childs[child.key] = child;\n    }\n\n    setEnding() {\n        this.ending = true;\n    }\n}\n\n/**\n * A trie data structure.\n */\nexport class Trie {\n    root: TrieNode;\n\n    constructor() {\n        this.root = new TrieNode('', null);\n    }\n\n    /**\n     * Add a word to the trie.\n     */\n    add(word: string) {\n        let actualNode = this.root;\n\n        for (let i = 0; i < word.length; i += 1) {\n            if (actualNode.childs[word[i]] === undefined) {\n                actualNode.addChild(new TrieNode(word[i], actualNode));\n            }\n\n            actualNode = actualNode.childs[word[i]];\n\n            if (i === word.length - 1) {\n                actualNode.setEnding();\n            }\n        }\n    }\n\n    /**\n     * Split a text into a sequence of words based on the trie vocabulary.\n     *\n     * @param text A text to split into words\n     * @param unknownKey The word used when the word is not found in the trie\n     * @param ignoreTokens Words, not in the trie, to not replace by the unknown key.\n     */\n    split(text: string, unknownKey: string = undefined, ignoreTokens: string[] = []): string[] {\n        const splittedText = [];\n\n        function pushUnknown(word: string) {\n            if (splittedText[splittedText.length - 1] !== unknownKey\n                && !ignoreTokens.includes(word)) {\n                splittedText.push(unknownKey);\n            }\n        }\n\n        let node = this.root;\n        let word = '';\n\n        for (let i = 0; i < text.length; i += 1) {\n            const character = text[i];\n\n            if (node.childs[character] !== undefined) {\n                word += character;\n                node = node.childs[character];\n            } else {\n                if (node.ending) splittedText.push(word);\n                else pushUnknown(word);\n\n                if (this.root.childs[character] !== undefined) {\n                    word = character;\n                    node = this.root.childs[character];\n                } else {\n                    pushUnknown(word);\n                    word = '';\n                    node = this.root;\n                }\n            }\n        }\n\n        if (node.ending) splittedText.push(word);\n        else pushUnknown(word);\n\n        return splittedText;\n    }\n}\n","import * as tf from '@tensorflow/tfjs';\nimport { Featurizer } from './featurizer';\nimport { initializeVariable } from '../utils';\n\n/**\n * Parameters for ActionFeaturizer constructor.\n */\ninterface ActionFeaturizerArgs {\n    /**\n     * Enable the masking of LUS when the user has just talked.\n     * Enabled by default.\n     */\n    maskLUS?: boolean;\n\n    /**\n     * Enable the masking of the previous action.\n     * Enabled by default.\n     */\n    maskPreviousAction?: boolean;\n\n    /**\n     * The action the bot takes to let the user talk.\n     * Default to 'LUS' (acronym for Let User Speak).\n     */\n    LUSAction?: string;\n}\n\n/**\n * Rule-based featurizer improving model robustness.\n *\n * - Featurize the previous action the model has taken.\n * - Mask the LUS action when the user has just talked.\n *   (Force the model to reply at least once)\n * - Mask the previous action.\n *   (Prevent looping : the model can't take two times in a row the same action)\n */\nexport class ActionFeaturizer extends Featurizer {\n    readonly id = 'Action Featurizer';\n    size: number;\n\n    private LUSAction: any;\n    private maskLUS: boolean;\n    private maskPreviousAction: boolean;\n\n    private userTalked: boolean;\n    private previousAction: any;\n\n    private embeddings: tf.Tensor;\n\n    constructor({\n        maskLUS = true,\n        maskPreviousAction = true,\n        LUSAction = 'LUS'\n    }: ActionFeaturizerArgs = { maskLUS: true, maskPreviousAction: true, LUSAction: 'LUS' }) {\n        super();\n        this.maskLUS = maskLUS;\n        this.maskPreviousAction = maskPreviousAction;\n        this.LUSAction = LUSAction;\n\n        this.resetDialog();\n    }\n\n    async init(actions: any[]) {\n        await super.init(actions);\n\n        this.size = actions.length;\n        this.embeddings = initializeVariable([this.size, this.size]);\n    }\n\n    async handleQuery(query: string): Promise<tf.Tensor2D> {\n        return tf.tidy(() => {\n            this.userTalked = query !== '';\n\n            // One-hot encode the previous action.\n            return <tf.Tensor2D> tf.oneHot(\n                [this.actions.indexOf(this.previousAction)],\n                this.actions.length\n            );\n        });\n    }\n\n    getOptimizableFeatures(data: tf.Tensor2D): tf.Tensor1D {\n        return <tf.Tensor1D> data.matMul(this.embeddings).squeeze();\n    }\n\n    handleAction(action: any) {\n        // Store the new action if it's not the LUS action.\n        this.previousAction = action !== this.LUSAction ? action : this.previousAction;\n    }\n\n    getActionMask(): boolean[] {\n        const mask = super.getActionMask();\n\n        // Mask LUS when the user talk and the option is enabled.\n        if (this.maskLUS && this.userTalked) {\n            mask[this.actions.indexOf(this.LUSAction)] = false;\n        }\n\n        // Mask the previous action when the option is enabled and if applicable.\n        if (this.maskPreviousAction && this.actions.includes(this.previousAction)) {\n            mask[this.actions.indexOf(this.previousAction)] = false;\n        }\n\n        return mask;\n    }\n\n    resetDialog() {\n        this.userTalked = false;\n        this.previousAction = undefined;\n    }\n\n    load(parameters: {embeddings: number[][]}) {\n        this.embeddings = tf.tidy(() => tf.tensor(parameters.embeddings).variable());\n    }\n\n    async export(): Promise<{embeddings: number[][]}> {\n        return {\n            embeddings: <number[][]> await this.embeddings.array()\n        };\n    }\n}\n","import * as tf from '@tensorflow/tfjs';\nimport { Featurizer } from './featurizer';\nimport { hashcode } from '../utils';\n\n/**\n * Featurizes queries as bag of words.\n *\n * The algorithm uses the [hashing trick](https://en.wikipedia.org/wiki/Feature_hashing) to avoid\n * having to store a vocabulary in the memory.\n */\nexport class BOW extends Featurizer {\n    readonly id = 'Bag-of-Words';\n    readonly size: number;\n\n    /**\n     * @param size The vocabulary size you allow to the featurizer.\n     */\n    constructor(size: number) {\n        super();\n        this.size = size;\n    }\n\n    async handleQuery(query: string): Promise<tf.Tensor1D> {\n        return tf.tidy(() => {\n            const indexes = query.toLowerCase()\n                .split(/\\W/g)\n                .map((word) => hashcode(word) % this.size);\n\n            return <tf.Tensor1D> tf.oneHot(indexes, this.size).asType('float32').sum(0);\n        });\n    }\n}\n","import * as tf from '@tensorflow/tfjs';\nimport * as use from '@tensorflow-models/universal-sentence-encoder';\nimport { Featurizer } from './featurizer';\n\n/**\n * Featurizes queries using the Universal Sentence Encoder model.\n */\nexport class USE extends Featurizer {\n    readonly id = 'Universal Sentence Encoder';\n\n    private encoder: use.UniversalSentenceEncoder;\n    private emptyEncoding: tf.Tensor1D;\n\n    readonly size = 512;\n\n    async init(actions: any[]) {\n        await super.init(actions);\n        this.encoder = await use.load();\n\n        // Cache the empty string embed (for optimization purpose).\n        this.emptyEncoding = await this.encodeQuery('');\n    }\n\n    /**\n     * Encodes a query using the model.\n     */\n    private async encodeQuery(query: string): Promise<tf.Tensor1D> {\n        const embed = await this.encoder.embed([query]);\n        const squeezedEmbed = <tf.Tensor1D> embed.squeeze();\n        tf.dispose(embed);\n\n        return squeezedEmbed;\n    }\n\n    async handleQuery(query: string): Promise<tf.Tensor1D> {\n        // When the query is empty, return the cached empty query encoding.\n        if (!query) {\n            return this.emptyEncoding.clone();\n        }\n\n        return this.encodeQuery(query);\n    }\n}\n","import * as tf from '@tensorflow/tfjs';\nimport { Featurizer } from './featurizer';\nimport { KeyedVectors } from '../tools';\n\n/**\n * Featurize queries by pooling words embedding using SWEM-concat(*).\n *\n * (*): Dinghan Shen, Guoyin Wang, Wenlin Wang, Martin Renqiang Min, Qinliang Su, Yizhe Zhang,\n *      Chunyuan Li, Ricardo Henao, Lawrence Carin- 2018.\n *      Baseline Needs More Love: On Simple Word-Embedding-Based Models and\n *      Associated Pooling Mechanisms.\n */\nexport class WordEmbedding extends Featurizer {\n    readonly id = 'Word Embedding';\n    readonly size: number;\n\n    private vectors: KeyedVectors;\n\n    /**\n     * @param vectors The keyed vectors storing the embeddings.\n     */\n    constructor(vectors: KeyedVectors) {\n        super();\n        this.size = 2 * vectors.size;\n        this.vectors = vectors;\n    }\n\n    async init(actions: any[]) {\n        await super.init(actions);\n\n        if (!this.vectors.isLoaded()) await this.vectors.load();\n    }\n\n    async handleQuery(query: string): Promise<tf.Tensor1D> {\n        return <tf.Tensor1D> tf.tidy(() => {\n            const tokens = this.vectors.tokenize(query);\n            const embeddings = tokens\n                .map((token) => this.vectors.get(token))\n                .filter((v) => v !== undefined);\n\n            // When there is no embeddable tokens, return a zeros vector.\n            if (embeddings.length === 0) {\n                return tf.zeros([this.size]);\n            }\n\n            const embeddingsMatrix = tf.stack(embeddings);\n\n            return tf.concat([embeddingsMatrix.mean(0), embeddingsMatrix.max(0)]);\n        });\n    }\n}\n","import * as tf from '@tensorflow/tfjs';\nimport { Featurizer } from '../featurizers';\nimport {\n    LSTM,\n    Story,\n    Stories,\n    Metrics\n} from '../utils';\n\ninterface SampleData {\n    targets: tf.Tensor1D,\n    predictions: tf.Tensor1D,\n    loss: number,\n    isFailing: boolean\n}\n\n/**\n * @callback\n */\ntype TrainingCallback = (metrics: Metrics) => void;\n\n/**\n * Parameters for HCN constructor.\n */\ninterface HCNConstructorArgs {\n    /**\n     * The list of actions the model can take.\n     * (keeping the order the same is important for pretrained models)\n     */\n    actions: string[];\n\n    /**\n     * The list of featurizers the model uses.\n     * (keeping the order the same is important for pretrained models)\n     */\n    featurizers: Featurizer[];\n\n    /**\n     * The output size of the LSTM cell.\n     * Default is set to 32 units.\n     */\n    hiddenSize?: number;\n\n    /**\n     * The optimization algorithm used for training.\n     * By default, Adam with a learning rate of 0.01 is used.\n     */\n    optimizer?: tf.Optimizer;\n\n    /**\n     * Temperature of the model softmax, used to calibrate confidence estimation.\n     * By default, the temperature is 1 but you usually want it higher to make less overconfident.\n     */\n    temperature?: number;\n\n    /**\n     * The percentage of units to dropout between the LSTM cell layer and the dense.\n     * Useful for regularizing the model. It's disabled by default (value = 0).\n     */\n    dropout?: number;\n}\n\n/**\n * Parameters for HCN train method.\n */\ninterface HCNTrainArgs {\n    /**\n     * Training stories to learn from.\n     */\n    stories: Stories;\n\n    /**\n     * Number of times the model will be passed the whole set of training stories during training.\n     * Default is set to 12 epochs.\n     */\n    nEpochs?: number;\n\n    /**\n     * After each epoch, this callback function will be executed with the metrics collected\n     * during the epoch.\n     */\n    onEpochEnd?: TrainingCallback;\n}\n\n/**\n * An implementation of Hybrid Code Networks(*) dialog manager.\n *\n * (*): Williams, Asadi, Zweig - 2017.\n *      Hybrid Code Networks: practical and efï¬cient end-to-end dialog control with supervised\n *      and reinforcement learning.\n */\nexport class HCN {\n    private actions: string[];\n    private featurizers: Featurizer[];\n    private optimizer: tf.Optimizer;\n\n    private inputSize: number;\n    private hiddenSize: number;\n    private outputSize: number;\n\n    private lstm: LSTM;\n    private lstmH: tf.Tensor2D;\n    private lstmC: tf.Tensor2D;\n    private lstmTemperature: number;\n    private lstmDropout: number;\n\n    /**\n     * Defines the model.\n     *\n     * To fully initialize the model, run the async *init()* method.\n     */\n    constructor({\n        actions,\n        featurizers,\n        hiddenSize = 32,\n        optimizer = tf.train.adam(0.01),\n        temperature = 1,\n        dropout = 0\n    }: HCNConstructorArgs) {\n        this.actions = actions;\n        this.featurizers = featurizers;\n        this.optimizer = optimizer;\n\n        this.hiddenSize = hiddenSize;\n        this.outputSize = actions.length;\n\n        this.lstmTemperature = temperature;\n        this.lstmDropout = dropout;\n    }\n\n    /**\n     * Initialize the model and its featurizers.\n     */\n    async init() {\n        // Initialize asynchronously all featurizers.\n        await Promise.all(\n            this.featurizers.map((featurizer) => featurizer.init(this.actions))\n        );\n\n        // The model input size is the sum of the sizes of features vectors.\n        this.inputSize = this.featurizers\n            .map((featurizer) => featurizer.size)\n            .reduce((acc, size) => acc + size, 1);\n\n        this.lstm = new LSTM(this.inputSize, this.hiddenSize, this.outputSize, this.lstmDropout);\n\n        this.resetDialog();\n    }\n\n    /**\n     * Resets the state of the model and its featurizers.\n     */\n    resetDialog() {\n        this.featurizers.forEach((featurizer) => featurizer.resetDialog());\n        ({ c: this.lstmC, h: this.lstmH } = this.lstm.initLSTM());\n    }\n\n    /**\n     * Get the data returned from every featurizer's handleQuery method.\n     */\n    private async handleQuery(query: string): Promise<any[]> {\n        return Promise.all(\n            this.featurizers.map((featurizer) => featurizer.handleQuery(query))\n        );\n    }\n\n    /**\n     * Get the embedding vector resulted from every featurizers.\n     */\n    private getOptimizableFeatures(features: tf.Tensor[]): tf.Tensor1D {\n        return tf.tidy(() => {\n            const embeddings = this.featurizers.map(\n                (featurizer, idx) => featurizer.getOptimizableFeatures(features[idx])\n            );\n\n            // Add a zero to make tf.concat work consistently even with only one featurizer.\n            embeddings.push(tf.zeros([1]));\n\n            return <tf.Tensor1D> tf.concat(embeddings);\n        });\n    }\n\n    /**\n     * Inform every featurizers of the taken action.\n     */\n    private handleAction(action: string) {\n        this.featurizers.map((featurizer) => featurizer.handleAction(action));\n    }\n\n    /**\n     * Get the final action mask resulted from every featurizers.\n     */\n    private getActionMask(): tf.Tensor1D {\n        return tf.tidy(() => this.featurizers\n            // Get action mask and convert them to tensors.\n            .map((featurizer) => <tf.Tensor1D> tf.tensor(\n                featurizer.getActionMask(),\n                undefined, 'float32'\n            ))\n            // Compute the product of every masks.\n            .reduce((acc, mask) => tf.mul(acc, mask), tf.ones([this.actions.length])));\n    }\n\n    /**\n     * Trains the model on a single training story.\n     */\n    private async fitStory(story: Story): Promise<SampleData> {\n        this.resetDialog();\n\n        // 1. Prepare the input data.\n        const inputs: any[][] = [];\n        const masks: tf.Tensor1D[] = [];\n        const targets: tf.Tensor1D[] = [];\n\n        // For each story's state...\n        for (let stateIdx = 0; stateIdx < story.length; stateIdx += 1) {\n            const state = story[stateIdx];\n\n            // The query must be featurized before moving to the next state.\n            // eslint-disable-next-line no-await-in-loop\n            inputs.push(await this.handleQuery(state.query));\n\n            masks.push(this.getActionMask());\n\n            targets.push(\n                <tf.Tensor1D> tf.oneHot(\n                    this.actions.indexOf(state.action),\n                    this.outputSize\n                )\n            );\n\n            this.handleAction(state.action);\n        }\n\n        // 2. Fit the sequence.\n        let data: SampleData;\n\n        this.optimizer.minimize(() => {\n            let { c, h } = this.lstm.initLSTM(false);\n\n            // Make a prediction for each step of the input sequence.\n            const predictions = inputs.map((features, idx) => {\n                const statePred = this.lstm.predict(\n                    <tf.Tensor1D> this.getOptimizableFeatures(features),\n                    <tf.Tensor2D> c,\n                    <tf.Tensor2D> h,\n                    <tf.Tensor1D> masks[idx]\n                );\n\n                c = statePred.nc;\n                h = statePred.nh;\n\n                return statePred.y;\n            });\n\n            const targetsMatrix = tf.stack(targets);\n            const predictionsMatrix = tf.stack(predictions);\n\n            // Compare the predicted sequence with the target.\n            const lossScalar = <tf.Scalar> tf.metrics.categoricalCrossentropy(\n                targetsMatrix, predictionsMatrix\n            ).mean();\n\n            // Store the necessary data to build metrics.\n            data = {\n                targets: tf.keep(targetsMatrix.argMax(1)),\n                predictions: tf.keep(predictionsMatrix.argMax(1)),\n                loss: <number> lossScalar.arraySync(),\n                isFailing: tf.metrics\n                    .categoricalAccuracy(targetsMatrix, predictionsMatrix)\n                    .mean()\n                    .arraySync() < 0.999\n            };\n\n            // Return the loss to the optimizer to update the model.\n            return lossScalar;\n        });\n\n        // BUG: two tensors leak in the memory at each loop :/\n        tf.dispose([inputs, targets]);\n\n        return data;\n    }\n\n    /**\n     * Trains the model using the training stories.\n     *\n     * @returns Metrics collected from the last epoch (that correspond to the trained model).\n     */\n    async train({ stories, nEpochs = 12, onEpochEnd = undefined }: HCNTrainArgs): Promise<Metrics> {\n        const storiesEntries = Object.entries(stories);\n        let epochMetrics: Metrics;\n\n        // For each epoch...\n        for (let epoch = 0; epoch < nEpochs; epoch += 1) {\n            const allTargets: tf.Tensor1D[] = [];\n            const allPredictions: tf.Tensor1D[] = [];\n            const allLosses: number[] = [];\n            const failingSamples: string[] = [];\n\n            // For each training story...\n            for (let storyIdx = 0; storyIdx < storiesEntries.length; storyIdx += 1) {\n                const [storyTitle, story] = storiesEntries[storyIdx];\n\n                // (Each story must be fitted sequentially)\n                // eslint-disable-next-line no-await-in-loop\n                const storyData = await this.fitStory(story);\n\n                allTargets.push(storyData.targets);\n                allPredictions.push(storyData.predictions);\n                allLosses.push(storyData.loss);\n\n                if (storyData.isFailing) {\n                    failingSamples.push(storyTitle);\n                }\n            }\n\n            // Build the metrics.\n            const confusionMatrix = tf.tidy(() => tf.math.confusionMatrix(\n                tf.concat(allTargets),\n                tf.concat(allPredictions),\n                this.outputSize\n            ));\n\n            const truePredictions = tf.tidy(() => confusionMatrix\n                .mul(tf.eye(...confusionMatrix.shape))\n                .sum(0));\n\n            epochMetrics = {\n                epoch,\n                failingSamples,\n\n                accuracy: <number> tf.tidy(() => (\n                    truePredictions.sum().div(confusionMatrix.sum()).arraySync()\n                )),\n\n                recall: <number> tf.tidy(() => (\n                    truePredictions.div(confusionMatrix.sum(1)).mean().arraySync()\n                )),\n\n                precision: <number> tf.tidy(() => (\n                    truePredictions.div(confusionMatrix.sum(0)).mean().arraySync()\n                )),\n\n                loss: allLosses.reduce((a, b) => a + b) / allLosses.length\n            };\n\n            // Clear the tensors.\n            tf.dispose(allTargets);\n            tf.dispose(allPredictions);\n            tf.dispose([truePredictions, confusionMatrix]);\n\n            if (onEpochEnd !== undefined) {\n                onEpochEnd(epochMetrics);\n            }\n        }\n\n        this.resetDialog();\n        return epochMetrics;\n    }\n\n    /**\n     * Predict an action resulting from the given query.\n     *\n     * @param query The given query from the user.\n     * @returns The predicted action from the model and its confidence.\n     */\n    async predict(query: string):\n        Promise<{action: string, confidence: number}> {\n        // At inference, dropout is disabled\n        this.lstm.dropout = 0;\n\n        const features = this.getOptimizableFeatures(await this.handleQuery(query));\n        const masks = this.getActionMask();\n\n        const prediction = this.lstm.predict(\n            features, this.lstmC, this.lstmH, masks, this.lstmTemperature\n        );\n\n        // Update lstm internal state\n        tf.dispose([this.lstmC, this.lstmH]);\n        this.lstmC = prediction.nc.clone();\n        this.lstmH = prediction.nh.clone();\n\n        const actionIdx = <number> tf.tidy(() => prediction.y.argMax().arraySync());\n        const confidence = <number> tf.tidy(() => prediction.y.arraySync()[actionIdx]);\n\n        // Clear the memory\n        tf.dispose([features, masks]);\n        tf.dispose(prediction);\n\n        // Retablish dropout (just in case)\n        this.lstm.dropout = this.lstmDropout;\n\n        this.handleAction(this.actions[actionIdx]);\n\n        return { action: this.actions[actionIdx], confidence };\n    }\n\n    /**\n     * Evaluate the model using stories.\n     *\n     * @param stories Validation stories to evaluate the model.\n     * @returns Validation metrics based on the results from the stories.\n     */\n    async score(stories: Stories): Promise<Metrics> {\n        const storiesEntries = Object.entries(stories);\n\n        const targets: number[] = [];\n        const predictions: number[] = [];\n        const confidences: number[] = [];\n        const failingSamples: string[] = [];\n\n        // For each stories and states, make predictions.\n        for (let storyIdx = 0; storyIdx < storiesEntries.length; storyIdx += 1) {\n            const [storyTitle, story] = storiesEntries[storyIdx];\n            this.resetDialog();\n\n            for (let stateIdx = 0; stateIdx < story.length; stateIdx += 1) {\n                const state = story[stateIdx];\n\n                // eslint-disable-next-line no-await-in-loop\n                const { action, confidence } = await this.predict(state.query);\n\n                targets.push(this.actions.indexOf(state.action));\n                predictions.push(this.actions.indexOf(action));\n                confidences.push(confidence);\n\n                if (action !== state.action && !failingSamples.includes(storyTitle)) {\n                    failingSamples.push(storyTitle);\n                }\n            }\n        }\n\n        // Build a confusion matrix out of the prediction and build the metrics.\n        const confusionMatrix = tf.tidy(() => tf.math.confusionMatrix(\n            tf.tensor(targets), tf.tensor(predictions), this.outputSize\n        ));\n\n        const truePredictions = tf.tidy(() => confusionMatrix\n            .mul(tf.eye(...confusionMatrix.shape))\n            .sum(0));\n\n        const metrics: Metrics = {\n            failingSamples,\n\n            accuracy: <number> tf.tidy(() => (\n                truePredictions.sum().div(confusionMatrix.sum()).arraySync()\n            )),\n\n            recall: <number> tf.tidy(() => (\n                truePredictions.div(confusionMatrix.sum(1)).mean().arraySync()\n            )),\n\n            precision: <number> tf.tidy(() => (\n                truePredictions.div(confusionMatrix.sum(0)).mean().arraySync()\n            )),\n\n            averageConfidence: confidences.reduce((a, b) => a + b) / confidences.length\n        };\n\n        tf.dispose([truePredictions, confusionMatrix]);\n\n        this.resetDialog();\n        return metrics;\n    }\n\n    /**\n     * Load the models parameters from a JSON formatted string.\n     */\n    load(json: string) {\n        const parameters = JSON.parse(json);\n\n        this.featurizers.forEach((featurizer) => {\n            featurizer.load(parameters[featurizer.id]);\n        });\n\n        this.lstm.load(parameters.lstm);\n\n        this.resetDialog();\n    }\n\n    /**\n     * Export the models parameters in a JSON format.\n     */\n    async export(): Promise<string> {\n        const parameters = { lstm: await this.lstm.export() };\n\n        for (let idx = 0; idx < this.featurizers.length; idx += 1) {\n            const featurizer = this.featurizers[idx];\n\n            // eslint-disable-next-line no-await-in-loop\n            parameters[featurizer.id] = await featurizer.export();\n        }\n\n        return JSON.stringify(parameters);\n    }\n}\n","import * as commonmark from 'commonmark';\nimport { Stories, State, ExtractedValue } from '../utils';\n\nexport interface ParsedWistyML {\n    stories: Stories,\n    extractedValues: {[title: string]: ExtractedValue[]}\n}\n\nenum StateStep {\n    query, data, action, empty\n}\n\n/**\n * Parse a source string formatted according the WistyML syntax.\n * Usually, this source string is extracted using fetch or from a file.\n */\nexport function parseWistyML(source: string): ParsedWistyML {\n    const markdownParser = new commonmark.Parser({ smart: true });\n    const parsedMarkdown = markdownParser.parse(source);\n\n    const walker = parsedMarkdown.walker();\n    let event = walker.next();\n\n    const state = {\n        // General\n        section: undefined,\n        status: undefined,\n        // Slot\n        slot: undefined,\n        sentence: '',\n        extractedValues: [],\n        // Story\n        storyName: undefined,\n        story: [],\n        currentState: undefined,\n        stateStep: StateStep.empty\n    };\n\n    const parsedSource: ParsedWistyML = { stories: {}, extractedValues: {} };\n\n    function endStory() {\n        if (state.storyName !== undefined) {\n            // Push the last step\n            state.story.push(state.currentState);\n            // Add a last LUS state\n            state.story.push({ query: '', action: 'LUS' });\n\n            // Push the story\n            parsedSource.stories[state.storyName] = state.story;\n\n            // Reset the state\n            state.storyName = undefined;\n            state.story = [];\n            state.currentState = undefined;\n            state.stateStep = StateStep.empty;\n        }\n    }\n\n    function pushSlot(sentence: string) {\n        if (parsedSource.extractedValues[state.slot] === undefined) {\n            parsedSource.extractedValues[state.slot] = [];\n        }\n\n        // Push the samples to the parsed digest\n        parsedSource.extractedValues[state.slot].push(\n            // Add the complete sentence to the extracted values.\n            ...state.extractedValues.map((extractedValues) => ({ sentence, ...extractedValues }))\n        );\n\n        state.extractedValues = [];\n        state.sentence = '';\n    }\n\n    while (event !== null) {\n        const { entering, node } = event;\n        const {\n            type,\n            literal,\n            destination,\n            info,\n            level\n        } = node;\n\n        /*\n            Handle section change\n            ## section name\n        */\n        if (entering && type === 'heading' && level === 2) {\n            state.status = 'new-section';\n            endStory();\n\n        /*\n            Get the new section name\n        */\n        } else if (type === 'text' && state.status === 'new-section') {\n            state.section = literal;\n            state.status = `${literal}.entering`;\n\n        /*\n            Slots section parsing :\n            ## wisty.slots\n        */\n        } else if (state.section === 'wisty.slots') {\n            /*\n                Entering a new slot\n\n                ## wisty.slots\n                ...\n                ### slot name\n            */\n            if (entering && type === 'heading' && level === 3) {\n                state.status = 'slots.new-slot';\n\n            /*\n                Get the slot name\n            */\n            } else if (type === 'text' && state.status === 'slots.new-slot') {\n                if (!(literal in parsedSource.extractedValues)) {\n                    parsedSource.extractedValues[literal] = [];\n                }\n\n                state.slot = literal;\n                state.status = 'slots.in-slot';\n\n            /*\n                Entering a sample\n\n                - sample\n            */\n            } else if (entering && type === 'item' && state.status === 'slots.in-slot') {\n                state.status = 'slots.in-sample';\n\n            /*\n                Getting sample text\n            */\n            } else if (type === 'text' && state.status === 'slots.in-sample') {\n                state.sentence += literal;\n\n            /*\n                Getting selected sample text\n\n                `selected text`\n            */\n            } else if (type === 'code' && state.status === 'slots.in-sample') {\n                state.extractedValues.push({\n                    extract: literal,\n                    start: state.sentence.length,\n                    end: state.sentence.length + literal.length - 1\n                });\n\n                state.sentence += literal;\n\n            /*\n                Exiting a sample\n            */\n            } else if (!entering && type === 'item' && state.status === 'slots.in-sample') {\n                pushSlot(state.sentence);\n                state.status = 'slots.in-slot';\n            }\n\n        /*\n            Stories section parsing :\n\n            ## wisty.stories\n        */\n        } else if (state.section === 'wisty.stories') {\n            /*\n                Entering a new story\n\n                ## wisty.stories\n                ...\n                ### story name\n            */\n            if (entering && type === 'heading' && level === 3) {\n                state.status = 'stories.new-story';\n\n                endStory();\n\n            /*\n                Get the new story name\n            */\n            } else if (type === 'text' && state.status === 'stories.new-story') {\n                state.storyName = literal;\n                state.status = 'stories.in-story';\n\n            /*\n                State management code\n            */\n            } else if (\n                entering\n                && ['block_quote', 'item', 'code_block'].includes(type)\n                && state.status === 'stories.in-story') {\n                // Identify the type of data in the state (the \"step\")\n                let newStep: StateStep;\n\n                switch (type) {\n                case 'block_quote':\n                    newStep = StateStep.query;\n                    break;\n\n                case 'item':\n                    newStep = StateStep.action;\n                    break;\n\n                case 'code_block':\n                    newStep = StateStep.data;\n                    break;\n\n                default: break;\n                }\n\n                /*\n                    If the new step is breaking the order of enunciation of the state step,\n                    we begin a new state.\n                */\n                if (newStep <= state.stateStep) {\n                    // Push the previous step\n                    if (state.currentState !== undefined) {\n                        state.story.push(state.currentState);\n\n                        if (newStep === StateStep.query && state.currentState.action !== 'LUS') {\n                            state.story.push(<State> { query: '', action: 'LUS' });\n                        }\n                    }\n\n                    state.currentState = { query: '', action: 'LUS' };\n                }\n\n                switch (newStep) {\n                case StateStep.query:\n                    state.status = 'stories.new-query';\n                    break;\n\n                case StateStep.action:\n                    state.status = 'stories.new-action';\n                    break;\n\n                case StateStep.data:\n                    if (info === 'json') {\n                        state.currentState.data = JSON.parse(literal);\n                    }\n                    break;\n\n                default: break;\n                }\n\n                state.stateStep = newStep;\n\n            /*\n                Get the query\n            */\n            } else if (type === 'text' && state.status === 'stories.new-query') {\n                state.currentState.query += literal;\n\n            /*\n                Slot training in a query\n            */\n            } else if (entering && type === 'link' && state.status === 'stories.new-query') {\n                state.slot = destination;\n                state.status = 'stories.new-slot';\n\n            /*\n                Get the extracted text from the slot\n            */\n            } else if (type === 'text' && state.status === 'stories.new-slot') {\n                state.extractedValues.push({\n                    extract: literal,\n                    start: state.currentState.query.length,\n                    end: state.currentState.query.length + literal.length - 1\n                });\n\n                state.currentState.query += literal;\n                state.status = 'stories.new-query';\n\n            /*\n                End the query block\n            */\n            } else if (!entering && type === 'block_quote' && state.status === 'stories.new-query') {\n                if (state.extractedValues.length > 0) pushSlot(state.currentState.query);\n\n                state.status = 'stories.in-story';\n\n            /*\n                Get the action name\n            */\n            } else if (type === 'text' && state.status === 'stories.new-action') {\n                state.currentState.action = literal;\n                state.status = 'stories.in-story';\n            }\n        }\n\n        event = walker.next();\n    }\n\n    endStory();\n\n    return parsedSource;\n}\n","import { Featurizer } from '../featurizers';\n\n/**\n * An extension of featurizer that holds a value in its state.\n * @abstract\n */\nexport class Slot<Value> extends Featurizer {\n    /**\n     * The list of actions that can be taken by the model only when the slot is defined.\n     */\n    private dependantActions: string[];\n\n    /**\n     * The list of actions that can be taken by the model only when the slot is undefined.\n     */\n    private invDependantActions: string[];\n\n    /**\n     * Stores the value of the slot.\n     */\n    private value: Value;\n\n    /**\n     * @param dependantActions The list of actions that can be taken by the model\n     *                         only when the slot is defined.\n     * @param invDependantActions The list of actions that can be taken by the model\n     *                            only when the slot is undefined.\n     */\n    constructor(dependantActions: string[], invDependantActions: string[]) {\n        super();\n        this.dependantActions = dependantActions;\n        this.invDependantActions = invDependantActions;\n    }\n\n    getActionMask(): boolean[] {\n        return this.actions.map((action) => {\n            const isDefined = this.value !== undefined;\n            const isDependant = this.dependantActions.includes(action);\n            const isInvDependant = this.invDependantActions.includes(action);\n\n            return (!isDefined && (!isDependant || isInvDependant))\n                || (isDefined && !isInvDependant);\n        });\n    }\n\n    resetDialog(): void {\n        this.value = undefined;\n    }\n\n    /**\n     * Retrieves the value of the slot.\n     */\n    getValue(): Value {\n        return this.value;\n    }\n\n    /**\n     * Redefine a new value for the slot.\n     */\n    setValue(value: Value) {\n        this.value = value;\n    }\n}\n","import * as tf from '@tensorflow/tfjs';\nimport { Slot } from './slot';\nimport { fuzzyMatch } from '../utils';\n\ntype Categories = {[category: string]: string[]};\ntype CategoricalValue = { category: string, extract: string, score: number };\n\n/**\n * Parameters for Categorical Slot constructor.\n */\ninterface CategoricalSlotArgs {\n    /**\n     * The name of the slot.\n     */\n    name: string;\n\n    /**\n     * An object with the name of the category as a key and an array of synonyms that belong to\n     * the category as a value.\n     */\n    categories: Categories;\n\n    /**\n     * The list of actions that can be taken by the model only when the slot is defined.\n     */\n    dependantActions?: string[];\n\n    /**\n     * The list of actions that can be taken by the model only when the slot is undefined.\n     */\n    invDependantActions?: string[];\n\n    /**\n     * The minimum similarity to get selected as a value. (based on Leveinshtein Distance)\n     */\n    threshold?: number;\n}\n\n/**\n * A slot that stores a categorical value extracted using fuzzy string matching.\n */\nexport class CategoricalSlot extends Slot<CategoricalValue> {\n    readonly id: string;\n    readonly size: number;\n\n    private categoryNames: string[];\n    private categories: Categories;\n\n    private threshold: number;\n\n    constructor({\n        name,\n        categories,\n        dependantActions = [],\n        invDependantActions = [],\n        threshold = 0.75\n    }: CategoricalSlotArgs) {\n        super(dependantActions, invDependantActions);\n\n        this.categoryNames = Object.keys(categories);\n        this.categories = categories;\n        this.threshold = threshold;\n\n        this.id = `${name}#Categorical`;\n        this.size = 2 * this.categoryNames.length;\n    }\n\n    async init(actions: any[]) {\n        await super.init(actions);\n        this.resetDialog();\n    }\n\n    private oneHotValue(value: CategoricalValue): tf.Tensor1D {\n        const categoryNames = Object.keys(this.categories);\n\n        return <tf.Tensor1D> tf.oneHot(\n            categoryNames.indexOf(value.category),\n            categoryNames.length\n        );\n    }\n\n    async handleQuery(query: string): Promise<tf.Tensor1D> {\n        const previousValue = this.getValue();\n        let bestValue: CategoricalValue = { category: undefined, extract: undefined, score: 0 };\n\n        // For each category...\n        Object.entries(this.categories).forEach(([category, keywords]) => {\n            // Find the best match of the category.\n            const match = keywords\n                .map((keyword) => fuzzyMatch(query.toLowerCase(), keyword.toLowerCase()))\n\n                .filter((m) => m.score >= this.threshold)\n\n                .reduce(\n                    (hm, m) => (hm.score > m.score ? hm : m),\n                    { extract: undefined, score: 0 }\n                );\n\n            // The best match is preferably a match of a different category with the highest score.\n            if (match.extract !== undefined) {\n                const currentUneqPrevious = category !== previousValue.category;\n                const bestEqPrevious = bestValue.category === previousValue.category;\n                const betterScore = match.score > bestValue.score;\n\n                if (bestValue.category === undefined\n                    || (currentUneqPrevious && betterScore)\n                    || (bestEqPrevious && currentUneqPrevious)\n                    || (bestEqPrevious && betterScore)\n                ) {\n                    bestValue = { category, ...match };\n                }\n            }\n        });\n\n        const features = tf.tidy(() => (\n            tf.concat([\n                this.oneHotValue(bestValue),\n                this.oneHotValue(this.getValue())\n            ])\n        ));\n\n        if (bestValue.category !== undefined) {\n            this.setValue(bestValue);\n        }\n\n        return features;\n    }\n\n    getValue(): CategoricalValue {\n        if (super.getValue() === undefined) {\n            return { category: undefined, extract: undefined, score: 0 };\n        }\n\n        return super.getValue();\n    }\n}\n","import { HCN } from '../models';\nimport { Slot } from '../slots';\n\n/**\n * Parameters for NLUFormatter.\n */\ninterface NLUFormatterArgs {\n    model: HCN;\n    slots?: Slot<any>[];\n    LUSAction?: string;\n}\n\n/**\n * An NLU digests containing the input query, the list of bot action to take,\n * the overall confidence of the turn (product of action's confidences) and slots values.\n */\ninterface NLUDigest {\n    /**\n     * The raw input query.\n     */\n    query: string;\n\n    /**\n     * An array of actions names.\n     */\n    actions: string[];\n\n    /**\n     * The overall confidence of the turn.\n     */\n    turnConfidence: number;\n\n    /**\n     * The value of each slot.\n     */\n    slots: {[slot: string]: any};\n}\n\n/**\n * An utility class using HCN methods and Slots to offer an higher level API\n * looking like NLU librairies.\n */\nexport class NLUFormatter {\n    private model: HCN;\n    private slots: Slot<any>[];\n    private LUSAction: string;\n\n    constructor({\n        model,\n        slots = [],\n        LUSAction = 'LUS'\n    }: NLUFormatterArgs) {\n        this.model = model;\n        this.slots = slots;\n        this.LUSAction = LUSAction;\n    }\n\n    /**\n     * Turn a query into a NLU digest.\n     */\n    async ask(query: string): Promise<NLUDigest> {\n        const digest: NLUDigest = {\n            query,\n            actions: [],\n            turnConfidence: 1,\n            slots: {}\n        };\n\n        let { action, confidence } = await this.model.predict(query);\n\n        while (action !== this.LUSAction) {\n            digest.actions.push(action);\n            digest.turnConfidence *= confidence;\n\n            // eslint-disable-next-line no-await-in-loop\n            ({ action, confidence } = await this.model.predict(''));\n        }\n\n        this.slots.forEach((slot) => {\n            digest.slots[slot.id] = slot.getValue();\n        });\n\n        return digest;\n    }\n\n    /**\n     * Reset the model state.\n     */\n    resetDialog() {\n        this.model.resetDialog();\n    }\n}\n","import { Stories } from '../utils';\n\n/**\n * Split a set stories into random train and test subsets.\n *\n * @param stories Some stories.\n * @param testSize The proportion of stories to put in the test subset.\n */\nexport function trainTestSplit(stories: Stories, testSize: number):\n    {train: Stories, test: Stories} {\n    const trainEntries = Object.entries(stories);\n    const testEntries = [];\n\n    for (let i = 0; i / trainEntries.length < testSize; i += 1) {\n        testEntries.push(...trainEntries.splice(\n            Math.floor(Math.random() * trainEntries.length), 1\n        ));\n    }\n\n    return {\n        train: Object.fromEntries(trainEntries),\n        test: Object.fromEntries(testEntries)\n    };\n}\n","import * as tf from '@tensorflow/tfjs';\nimport { levenshteinDistance, Trie } from '../utils';\n\n/**\n * Parameters for KeyedVectors.\n */\ninterface KeyedVectorsArgs {\n    loaderFunction(): Promise<string>;\n    size: number;\n    tokenization?: 'word' | 'byte_pair';\n    cased?: boolean;\n    maxDistance?: number;\n    unknownKey?: string;\n}\n\n/**\n * A reusable class storing words embeddings for functions and class that needs it.\n */\nexport class KeyedVectors {\n    private vectors: {[key: string]: number[]};\n\n    private loaderFunction: () => Promise<string>;\n\n    readonly size: number;\n    private tokenization: 'word' | 'byte_pair';\n    private cased: boolean;\n    private trie: Trie;\n\n    private maxDistance: number;\n    private unknownKey: string;\n\n    /**\n     * Build a KeyedVector.\n     */\n    constructor({\n        loaderFunction,\n        size,\n        tokenization = 'word',\n        cased = false,\n        maxDistance = 0.5,\n        unknownKey = undefined\n    }: KeyedVectorsArgs) {\n        if (!['word', 'byte_pair'].includes(tokenization)) {\n            throw new Error('KeyedVector tokenization setting must be \"word\" or \"byte_pair\"');\n        }\n\n        this.loaderFunction = loaderFunction;\n\n        this.size = size;\n        this.tokenization = tokenization;\n        this.cased = cased;\n\n        this.maxDistance = maxDistance;\n        this.unknownKey = unknownKey;\n    }\n\n    /**\n     * Return every keys stored as an array.\n     */\n    keys(): string[] {\n        return Object.keys(this.vectors);\n    }\n\n    /**\n     * Load the word embeddings.\n     */\n    async load() {\n        this.vectors = JSON.parse(await this.loaderFunction());\n\n        if (this.tokenization === 'byte_pair') {\n            this.trie = new Trie();\n            this.keys().forEach((key) => this.trie.add(key));\n        }\n    }\n\n    /**\n     * Check if the word embeddings were loaded.\n     */\n    isLoaded(): boolean {\n        return this.vectors !== undefined;\n    }\n\n    /**\n     * Return the vector associated with a key.\n     * If the key is not part of the vocabulary, it will use a similar key according to\n     * the leveinshtein distance.\n     * If no similar keys are below `maxDistance`, it will return the unknown key vector or\n     * undefined.\n     */\n    get(key: string): tf.Tensor1D {\n        // If the token in in the vocabulary, just use its embedding.\n        if (this.keys().includes(key)) {\n            return tf.tensor1d(this.vectors[key]);\n        }\n\n        // If the token is out of vocabulary, use the most similarly spelled token instead.\n        let bestKey: string;\n        let lowestDistance: number = Infinity;\n\n        this.keys().forEach((knownKey) => {\n            const distance = levenshteinDistance(knownKey, key);\n\n            if (distance < lowestDistance) {\n                bestKey = knownKey;\n                lowestDistance = distance;\n            }\n        });\n\n        if (lowestDistance <= this.maxDistance) {\n            return tf.tensor(this.vectors[bestKey]);\n        }\n\n        // If no tokens are enough similar, return the unknownKey vector or undefined.\n        if (this.unknownKey !== undefined) {\n            return tf.tensor(this.vectors[this.unknownKey]);\n        }\n\n        return undefined;\n    }\n\n    /**\n     * Tokenize a string at each non-word character.\n     *\n     * @param text  A non tokenized text string.\n     */\n    // eslint-disable-next-line class-methods-use-this\n    private wordTokenize(text: string): string[] {\n        return text.split(/\\W/g).filter((token) => token.length > 0);\n    }\n\n    /**\n     * Tokenize a string based on the vocabulary.\n     *\n     * @param text A non tokenized text string.\n     */\n    private bytePairTokenize(text: string): string[] {\n        const pretext = ` ${text}`.split(' ').join('â–');\n\n        return this.trie.split(pretext, this.unknownKey, ['â–']);\n    }\n\n    /**\n     * Tokenize a string based on the settings.\n     *\n     * @param text A raw text string.\n     */\n    tokenize(text: string): string[] {\n        if (this.cased) {\n            // eslint-disable-next-line no-param-reassign\n            text = text.toLowerCase();\n        }\n\n        switch (this.tokenization) {\n        case 'word':\n            return this.wordTokenize(text);\n\n        case 'byte_pair':\n            return this.bytePairTokenize(text);\n\n        default:\n            throw new Error('KeyedVector tokenization setting must be \"word\" or \"byte_pair\"');\n        }\n    }\n}\n"],"names":["Featurizer","this","init","actions","handleQuery","query","getOptimizableFeatures","data","undefined","tf","handleAction","action","getActionMask","map","resetDialog","load","parameters","levenshteinDistance","s1","s2","d","Array","from","length","fill","i","j","Math","min","max","fuzzyMatch","text","substring","bestMatch","extract","score","aMatch","hashcode","input","hash","charCodeAt","initializeVariable","shape","scalar","initializer","heNormal","zeros","randomNormal","Error","randomTensor","apply","asScalar","variable","LSTM","inputSize","hiddenSize","outputSize","dropout","lstmKernel","lstmBias","lstmForgetBias","lstmInitH","lstmInitC","denseWeights","denseBias","initLSTM","clone","c","h","predict","x","mask","temperature","_this","nc","nh","y","matMul","add","squeeze","div","softmax","mul","weights","_this2","_this4","array","TrieNode","key","parent","childs","ending","addChild","child","setEnding","Trie","root","word","actualNode","split","unknownKey","ignoreTokens","splittedText","pushUnknown","includes","push","node","character","maskLUS","maskPreviousAction","LUSAction","_this3","size","embeddings","_this5","userTalked","indexOf","previousAction","indexes","toLowerCase","asType","sum","use","encoder","encodeQuery","emptyEncoding","embed","squeezedEmbed","vectors","isLoaded","tokenize","token","get","filter","v","embeddingsMatrix","mean","bind","pact","_settle","update","shouldContinue","result","StateStep","featurizers","optimizer","adam","lstmTemperature","lstmDropout","Promise","all","featurizer","reduce","acc","lstm","forEach","lstmC","lstmH","features","idx","_this6","fitStory","story","_this8","minimize","predictions","inputs","statePred","masks","targetsMatrix","targets","predictionsMatrix","lossScalar","categoricalCrossentropy","argMax","loss","arraySync","isFailing","categoricalAccuracy","stateIdx","state","_push","train","stories","nEpochs","onEpochEnd","epochMetrics","_this10","storiesEntries","Object","entries","epoch","confusionMatrix","allTargets","allPredictions","truePredictions","failingSamples","accuracy","recall","precision","allLosses","a","b","storyIdx","storyTitle","storyData","_this12","prediction","actionIdx","confidence","_this14","metrics","averageConfidence","confidences","json","JSON","parse","id","_this16","stringify","Slot","dependantActions","invDependantActions","isDefined","value","isDependant","isInvDependant","getValue","setValue","name","categories","threshold","categoryNames","keys","oneHotValue","category","previousValue","bestValue","match","keyword","m","hm","currentUneqPrevious","bestEqPrevious","betterScore","_Slot","source","walker","commonmark","smart","event","next","section","status","slot","sentence","extractedValues","storyName","currentState","stateStep","empty","parsedSource","endStory","pushSlot","entering","type","literal","destination","info","level","start","end","newStep","testSize","trainEntries","testEntries","splice","floor","random","fromEntries","test","slots","model","ask","digest","turnConfidence","loaderFunction","tokenization","cased","maxDistance","trie","bestKey","lowestDistance","Infinity","knownKey","distance","wordTokenize","bytePairTokenize","pretext","join"],"mappings":"gZASaA,aAAb,aAeaC,UAAe,EAf5B,2BAuBUC,cAAKC,cACPF,KAAKE,QAAUA,oBAxBvB,sCAqCUC,qBAAYC,+BAelBC,uBAAA,SAAuBC,GACnB,YAAaC,IAATD,EACOE,EAAS,CAAC,IAGAF,KAOzBG,aAAA,SAAaC,OAQbC,cAAA,WACI,YAAYT,QAAQU,IAAI,yBAO5BC,YAAA,eAMAC,KAAA,SAAKC,yBAOD,uBAAO,iUClGCC,EAAoBC,EAAYC,GAM5C,IALA,IAAMC,EAAIC,MAAMC,KACZD,MAAMH,EAAGK,OAAS,GAClB,sBAAUF,MAAMF,EAAGI,OAAS,GAAGC,KAAK,KAG/BC,EAAI,EAAGA,GAAKP,EAAGK,OAAQE,GAAK,EACjCL,EAAEK,GAAG,GAAKA,EAGd,IAAK,IAAIC,EAAI,EAAGA,GAAKP,EAAGI,OAAQG,GAAK,EACjCN,EAAE,GAAGM,GAAKA,EAGd,IAAK,IAAIA,EAAI,EAAGA,EAAIP,EAAGI,OAAQG,GAAK,EAChC,IAAK,IAAID,EAAI,EAAGA,EAAIP,EAAGK,OAAQE,GAAK,EAGhCL,EAAEK,EAAI,GAAGC,EAAI,GAAKC,KAAKC,IACnBR,EAAEK,GAAGC,EAAI,GAAK,EACdN,EAAEK,EAAI,GAAGC,GAAK,EACdN,EAAEK,GAAGC,IALiBR,EAAGO,KAAON,EAAGO,GAAM,EAAI,IAUzD,OAAON,EAAEF,EAAGK,QAAQJ,EAAGI,QAAUI,KAAKE,IAAIX,EAAGK,OAAQJ,EAAGI,OAAQ,YC1BpDO,EAAWC,EAAcC,GAGrC,IAFA,IAAIC,EAAmB,CAAEC,aAAS1B,EAAW2B,MAAO,GAE3CV,EAAI,EAAGA,EAAIM,EAAKR,OAAQE,GAAK,EAAG,CACrC,IAAMS,EAAUH,EAAKC,UAAUP,EAAGA,EAAIO,EAAUT,QAE1Ca,EAAS,CACXF,QAAAA,EACAC,MAAO,EAAIlB,EAAoBiB,EAASF,IAG5C,GAAqB,IAAjBI,EAAOD,MACP,OAAOC,EAGPA,EAAOD,MAAQF,EAAUE,QACzBF,EAAYG,GAIpB,OAAOH,WClBKI,EAASC,GAGrB,IAFA,IAAIC,EAAO,EAEFd,EAAI,EAAGA,EAAIa,EAAMf,OAAQE,GAAK,EAGnCc,GAASA,GAAQ,GAAKA,EAFVD,EAAME,WAAWf,GAG7Bc,GAAQ,EAGZ,OAAOA,WCXKE,EAAmBC,EAAiBC,EAChDzC,GACA,gBAFgDyC,IAAAA,GAAkB,YAClEzC,IAAAA,EAA8B,MACvBO,EAAQ,WACX,IAAImC,EAEJ,OAAQ1C,GACR,IAAK,KACD0C,EAAcnC,EAAgBoC,SAAS,IACvC,MAEJ,IAAK,QACDD,EAAcnC,EAAgBqC,QAC9B,MAEJ,IAAK,SACDF,EAAcnC,EAAgBsC,aAAa,IAC3C,MAEJ,QACI,UAAUC,8EACkE9C,QAIhF,IAAI+C,EAAeL,EAAYM,MAAMR,GAGrC,OAFIC,IAAQM,EAAeA,EAAaE,YAEjCF,EAAaG,iBCxBfC,aAqBT,WAAYC,EAAmBC,EAAoBC,EAAoBC,YAAAA,IAAAA,EAAkB,IACrFxD,KAAKyD,WAAajB,EAAmB,CAACa,EAAYC,EAAyB,EAAbA,IAC9DtD,KAAK0D,SAAWlB,EAAmB,CAAc,EAAbc,IAAiB,EAAO,SAC5DtD,KAAK2D,eAAiBnB,EAAmB,CAAC,IAAI,EAAM,SACpDxC,KAAK4D,UAAYpB,EAAmB,CAAC,EAAGc,IACxCtD,KAAK6D,UAAYrB,EAAmB,CAAC,EAAGc,IAExCtD,KAAK8D,aAAetB,EAAmB,CAACc,EAAYC,IACpDvD,KAAK+D,UAAYvB,EAAmB,CAACe,IAAa,EAAO,SAEzDvD,KAAKwD,QAAUA,EA/BvB,2BAuCIQ,SAAA,SAASC,GACL,gBADKA,IAAAA,GAAiB,GACf,CACHC,EAAkBD,EAAQjE,KAAK6D,UAAUI,QAAUjE,KAAK6D,UACxDM,EAAkBF,EAAQjE,KAAK4D,UAAUK,QAAUjE,KAAK4D,cAWhEQ,QAAA,SAAQC,EAAgBH,EAAgBC,EAAgBG,EACpDC,cACA,gBADAA,IAAAA,EAAsB,GACf/D,EAAQ,iBAEMA,EACDgE,EAAKb,eACHa,EAAKf,WACLe,EAAKd,SACLlD,EAAS,CAAC6D,IACxBF,EAAGD,GALAO,OAAIC,OASPC,EAAkBnE,EACTkE,EAAIF,EAAKhB,SACjBoB,OAAOJ,EAAKV,cACZe,IAAIL,EAAKT,WACTe,UACAC,IAAIR,GACJS,UACAC,UAAIX,EAAAA,EAAQ,GAKjB,MAAO,CAAEK,EAFTA,EAAIA,EAAEI,IAAIvE,EAAOmE,IAELF,GAAAA,EAAIC,GAAAA,QAOxB5D,KAAA,SAAKoE,cACD1E,EAAQ,WAEJ2E,EAAK1B,WAAajD,EAAU0E,EAAQzB,YAAYN,WAChDgC,EAAKzB,SAAWlD,EAAU0E,EAAQxB,UAAUP,WAC5CgC,EAAKxB,eAAiBnD,EAAU0E,EAAQvB,gBAAgBR,WACxDgC,EAAKvB,UAAYpD,EAAU0E,EAAQtB,WAAWT,WAC9CgC,EAAKtB,UAAYrD,EAAU0E,EAAQrB,WAAWV,WAC9CgC,EAAKrB,aAAetD,EAAU0E,EAAQpB,cAAcX,WACpDgC,EAAKpB,UAAYvD,EAAU0E,EAAQnB,WAAWZ,4CAS5BnD,4BAAAoF,EAAK3B,WAAW4B,iDAClBD,EAAK1B,SAAS2B,iDACRD,EAAKzB,eAAe0B,iDACzBD,EAAKxB,UAAUyB,iDACfD,EAAKvB,UAAUwB,iDACZD,EAAKtB,aAAauB,iDACrBD,EAAKrB,UAAUsB,0BAGpC,MAVgB,CACZ5B,aACAC,WACAC,iBACAC,YACAC,YACAC,eACAC,2BA7GZ,yCCAauB,aAMT,WAAYC,EAAaC,GACrBxF,KAAKuF,IAAMA,EACXvF,KAAKwF,OAASA,EAEdxF,KAAKyF,OAAS,GACdzF,KAAK0F,QAAS,EAXtB,2BAcIC,SAAA,SAASC,GACL5F,KAAKyF,OAAOG,EAAML,KAAOK,KAG7BC,UAAA,WACI7F,KAAK0F,QAAS,QAOTI,aAGT,aACI9F,KAAK+F,KAAO,IAAIT,EAAS,GAAI,MAJrC,2BAUIT,IAAA,SAAImB,GAGA,IAFA,IAAIC,EAAajG,KAAK+F,KAEbvE,EAAI,EAAGA,EAAIwE,EAAK1E,OAAQE,GAAK,OACCjB,IAA/B0F,EAAWR,OAAOO,EAAKxE,KACvByE,EAAWN,SAAS,IAAIL,EAASU,EAAKxE,GAAIyE,IAG9CA,EAAaA,EAAWR,OAAOO,EAAKxE,IAEhCA,IAAMwE,EAAK1E,OAAS,GACpB2E,EAAWJ,eAYvBK,MAAA,SAAMpE,EAAcqE,EAAgCC,YAAhCD,IAAAA,OAAqB5F,YAAW6F,IAAAA,EAAyB,IACzE,IAAMC,EAAe,GAErB,SAASC,EAAYN,GACbK,EAAaA,EAAa/E,OAAS,KAAO6E,GACtCC,EAAaG,SAASP,IAC1BK,EAAaG,KAAKL,GAO1B,IAHA,IAAIM,EAAOzG,KAAK+F,KACZC,EAAO,GAEFxE,EAAI,EAAGA,EAAIM,EAAKR,OAAQE,GAAK,EAAG,CACrC,IAAMkF,EAAY5E,EAAKN,QAEQjB,IAA3BkG,EAAKhB,OAAOiB,IACZV,GAAQU,EACRD,EAAOA,EAAKhB,OAAOiB,KAEfD,EAAKf,OAAQW,EAAaG,KAAKR,GAC9BM,EAAYN,QAEmBzF,IAAhCP,KAAK+F,KAAKN,OAAOiB,IACjBV,EAAOU,EACPD,EAAOzG,KAAK+F,KAAKN,OAAOiB,KAExBJ,EAAYN,GACZA,EAAO,GACPS,EAAOzG,KAAK+F,OAQxB,OAHIU,EAAKf,OAAQW,EAAaG,KAAKR,GAC9BM,EAAYN,GAEVK,wKCvDX,iCAI0B,CAAEM,SAAS,EAAMC,oBAAoB,EAAMC,UAAW,aAH5EF,QAAAA,oBACAC,mBAAAA,oBACAC,UAAAA,aAAY,eAEZrC,yBAjBU,oBAkBVA,EAAKmC,QAAUA,EACfnC,EAAKoC,mBAAqBA,EAC1BpC,EAAKqC,UAAYA,EAEjBrC,EAAK3D,uBAvBb,2BA0BUZ,cAAKC,qDACKD,YAAKC,oBAEjB4G,EAAKC,KAAO7G,EAAQoB,OACpBwF,EAAKE,WAAaxE,EAAmB,CAACsE,EAAKC,KAAMD,EAAKC,SA9B9D,sCAiCU5G,qBAAYC,aAEVJ,KADJ,uBAAOQ,EAAQ,WAIX,OAHAyG,EAAKC,WAAuB,KAAV9G,EAGGI,EACjB,CAACyG,EAAK/G,QAAQiH,QAAQF,EAAKG,iBAC3BH,EAAK/G,QAAQoB,WAxC7B,sCA6CIjB,uBAAA,SAAuBC,GACnB,OAAqBA,EAAKsE,OAAO5E,KAAKgH,YAAYlC,aAGtDrE,aAAA,SAAaC,GAETV,KAAKoH,eAAiB1G,IAAWV,KAAK6G,UAAYnG,EAASV,KAAKoH,kBAGpEzG,cAAA,WACI,IAAM2D,cAAa3D,yBAYnB,OATIX,KAAK2G,SAAW3G,KAAKkH,aACrB5C,EAAKtE,KAAKE,QAAQiH,QAAQnH,KAAK6G,aAAc,GAI7C7G,KAAK4G,oBAAsB5G,KAAKE,QAAQqG,SAASvG,KAAKoH,kBACtD9C,EAAKtE,KAAKE,QAAQiH,QAAQnH,KAAKoH,kBAAmB,GAG/C9C,KAGXzD,YAAA,WACIb,KAAKkH,YAAa,EAClBlH,KAAKoH,oBAAiB7G,KAG1BO,KAAA,SAAKC,GACDf,KAAKgH,WAAaxG,EAAQ,kBAAMA,EAAUO,EAAWiG,YAAY7D,6DAK9BnD,KAAKgH,WAAW3B,0BADnD,MAAO,CACH2B,gBAjFZ,uCAAsCjH,mBCnBlC,WAAYgH,gBACRvC,yBAPU,eAQVA,EAAKuC,KAAOA,8BAGV5G,qBAAYC,aAI0BJ,KAHxC,uBAAOQ,EAAQ,WACX,IAAM6G,EAAUjH,EAAMkH,cACjBpB,MAAM,OACNtF,IAAI,SAACoF,UAAS5D,EAAS4D,GAAQc,EAAKC,OAEzC,OAAqBvG,EAAU6G,EAASP,EAAKC,MAAMQ,OAAO,WAAWC,IAAI,MAlBrF,uCAAyBzH,mBCHzB,8DACkB,6BAKLyE,OAAO,aANpB,2BAQUvE,cAAKC,qDACKD,YAAKC,2CACIuH,6BAArBX,EAAKY,0BAGsBZ,EAAKa,YAAY,sBAA5Cb,EAAKc,sBAbb,sCAmBkBD,qBAAYvH,8BACFJ,KAAK0H,QAAQG,MAAM,CAACzH,mBAAlCyH,GACN,IAAMC,EAA8BD,EAAM/C,UAG1C,OAFAtE,EAAWqH,GAEJC,IAxBf,sCA2BU3H,qBAAYC,OAEd,uBAAKA,EACMJ,KAGC2H,YAAYvH,GAHbJ,KAAK4H,cAAc3D,SA9BtC,uCAAyBlE,6BCcrB,WAAYgI,gBACRvD,yBATU,iBAUVA,EAAKuC,KAAO,EAAIgB,EAAQhB,KACxBvC,EAAKuD,QAAUA,WAZvB,2BAeU9H,cAAKC,qDACKD,YAAKC,qCAEjB,IAAK4G,EAAKiB,QAAQC,kCAAkBlB,EAAKiB,QAAQjH,yEAlBzD,sCAqBUX,qBAAYC,aAEKJ,KADnB,uBAAqBQ,EAAQ,WACzB,IACMwG,EADSC,EAAKc,QAAQE,SAAS7H,GAEhCQ,IAAI,SAACsH,YAAeH,QAAQI,IAAID,KAChCE,OAAO,SAACC,eAAY9H,IAAN8H,IAGnB,GAA0B,IAAtBrB,EAAW1F,OACX,OAAOd,EAAS,CAACyG,EAAKF,OAG1B,IAAMuB,EAAmB9H,EAASwG,GAElC,OAAOxG,EAAU,CAAC8H,EAAiBC,KAAK,GAAID,EAAiB1G,IAAI,QAnC7E,uCAAmC7B,IC2I5B,sDAaH,kBAHkByI,KACV,qEAOuB,8CASFC,aAhL1B,8GAwFJ,4GAqCKjE,IACHkE,2HA0VsBC,8CAUpBC,SACGC,8CAUmB,8iBCvexBC,mCDuGD,kBACI5I,IAAAA,QACA6I,IAAAA,gBACAzF,WAAAA,aAAa,SACb0F,UAAAA,aAAYxI,EAASyI,KAAK,WAC1B1E,YAAAA,aAAc,QACdf,QAAAA,aAAU,IAEVxD,KAAKE,QAAUA,EACfF,KAAK+I,YAAcA,EACnB/I,KAAKgJ,UAAYA,EAEjBhJ,KAAKsD,WAAaA,EAClBtD,KAAKuD,WAAarD,EAAQoB,OAE1BtB,KAAKkJ,gBAAkB3E,EACvBvE,KAAKmJ,YAAc3F,EApC3B,2BA0CUvD,0BAGED,4BADEoJ,QAAQC,IACVlE,EAAK4D,YAAYnI,IAAI,SAAC0I,UAAeA,EAAWrJ,KAAKkF,EAAKjF,6BAI9DiF,EAAK9B,UAAY8B,EAAK4D,YACjBnI,IAAI,SAAC0I,UAAeA,EAAWvC,OAC/BwC,OAAO,SAACC,EAAKzC,UAASyC,EAAMzC,GAAM,GAEvC5B,EAAKsE,KAAO,IAAIrG,EAAK+B,EAAK9B,UAAW8B,EAAK7B,WAAY6B,EAAK5B,WAAY4B,EAAKgE,aAE5EhE,EAAKtE,gBAvDb,sCA6DIA,YAAA,WACIb,KAAK+I,YAAYW,QAAQ,SAACJ,UAAeA,EAAWzI,sBAChBb,KAAKyJ,KAAKzF,WAAxChE,KAAK2J,QAARzF,EAAkBlE,KAAK4J,QAARzF,KAMRhE,qBAAYC,OACtB,OAAOgJ,QAAQC,IACXrJ,KAAK+I,YAAYnI,IAAI,SAAC0I,UAAeA,EAAWnJ,YAAYC,MAvExE,sCA8EYC,uBAAA,SAAuBwJ,cAC3B,OAAOrJ,EAAQ,WACX,IAAMwG,EAAaC,EAAK8B,YAAYnI,IAChC,SAAC0I,EAAYQ,UAAQR,EAAWjJ,uBAAuBwJ,EAASC,MAMpE,OAFA9C,EAAWR,KAAKhG,EAAS,CAAC,KAELA,EAAUwG,QAO/BvG,aAAA,SAAaC,GACjBV,KAAK+I,YAAYnI,IAAI,SAAC0I,UAAeA,EAAW7I,aAAaC,QAMzDC,cAAA,sBACJ,OAAOH,EAAQ,kBAAMuJ,EAAKhB,YAErBnI,IAAI,SAAC0I,UAA6B9I,EAC/B8I,EAAW3I,qBACXJ,EAAW,aAGdgJ,OAAO,SAACC,EAAKlF,UAAS9D,EAAOgJ,EAAKlF,IAAO9D,EAAQ,CAACuJ,EAAK7J,QAAQoB,eAM1D0I,kBAASC,wBA6BnB,IAAI3J,EA8CJ,OA5CA4J,EAAKlB,UAAUmB,SAAS,iBACLD,EAAKT,KAAKzF,UAAS,GAA5BE,IAAAA,EAAGC,IAAAA,EAGHiG,EAAcC,EAAOzJ,IAAI,SAACiJ,EAAUC,GACtC,IAAMQ,EAAYJ,EAAKT,KAAKrF,QACV8F,EAAK7J,uBAAuBwJ,GAC5B3F,EACAC,EACAoG,EAAMT,IAMxB,OAHA5F,EAAIoG,EAAU7F,GACdN,EAAImG,EAAU5F,GAEP4F,EAAU3F,IAGf6F,EAAgBhK,EAASiK,GACzBC,EAAoBlK,EAAS4J,GAG7BO,EAAyBnK,EAAWoK,wBACtCJ,EAAeE,GACjBnC,OAcF,OAXAjI,EAAO,CACHmK,QAASjK,EAAQgK,EAAcK,OAAO,IACtCT,YAAa5J,EAAQkK,EAAkBG,OAAO,IAC9CC,KAAeH,EAAWI,YAC1BC,UAAWxK,EACNyK,oBAAoBT,EAAeE,GACnCnC,OACAwC,YAAc,MAIhBJ,IAIXnK,EAAW,CAAC6J,EAAQI,IAEbnK,KA1EPN,KAAAkK,EAAKrJ,cAGL,IAAMwJ,EAAkB,GAClBE,EAAuB,GACvBE,EAAyB,GAGtBS,EAAW,wBAAGA,EAAWjB,EAAM3I,4BAAQ4J,GAAY,eACxD,IAAMC,EAAQlB,EAAMiB,KAIpBb,EAAO7D,4BAAW0D,EAAK/J,YAAYgL,EAAM/K,yBAAzCgL,OAAAf,KAEAE,EAAM/D,KAAK0D,EAAKvJ,iBAEhB8J,EAAQjE,KACUhG,EACV0J,EAAKhK,QAAQiH,QAAQgE,EAAMzK,QAC3BwJ,EAAK3G,aAIb2G,EAAKzJ,aAAa0K,EAAMzK,4DA5IpC,sCAsMU2K,sBAAQC,IAAAA,YAASC,QAAAA,aAAU,SAAIC,WAAAA,kBAAajL,YAE1CkL,eAmEJ,OADAC,EAAK7K,cACE4K,KApDyBzL,KAhB1B2L,EAAiBC,OAAOC,QAAQP,GAI7BQ,EAAQ,wBAAGA,EAAQP,uBAASO,GAAS,4BAwB1C,IAAMC,EAAkBvL,EAAQ,kBAAMA,EAAQuL,gBAC1CvL,EAAUwL,GACVxL,EAAUyL,GACVP,EAAKnI,cAGH2I,EAAkB1L,EAAQ,kBAAMuL,EACjC9G,IAAIzE,QAAAA,EAAUuL,EAAgBtJ,QAC9B+E,IAAI,KAETiE,EAAe,CACXK,MAAAA,EACAK,eAAAA,EAEAC,SAAmB5L,EAAQ,kBACvB0L,EAAgB1E,MAAMzC,IAAIgH,EAAgBvE,OAAOuD,cAGrDsB,OAAiB7L,EAAQ,kBACrB0L,EAAgBnH,IAAIgH,EAAgBvE,IAAI,IAAIe,OAAOwC,cAGvDuB,UAAoB9L,EAAQ,kBACxB0L,EAAgBnH,IAAIgH,EAAgBvE,IAAI,IAAIe,OAAOwC,cAGvDD,KAAMyB,EAAUhD,OAAO,SAACiD,EAAGC,UAAMD,EAAIC,IAAKF,EAAUjL,QAIxDd,EAAWwL,GACXxL,EAAWyL,GACXzL,EAAW,CAAC0L,EAAiBH,SAEVxL,IAAfiL,GACAA,EAAWC,GA1Df,IAAMO,EAA4B,GAC5BC,EAAgC,GAChCM,EAAsB,GACtBJ,EAA2B,GAGxBO,EAAW,wBAAGA,EAAWf,EAAerK,4BAAQoL,GAAY,qBACrCf,EAAee,GAApCC,8BAIiBjB,EAAK1B,8BAAvB4C,GAENZ,EAAWxF,KAAKoG,EAAUnC,SAC1BwB,EAAezF,KAAKoG,EAAUxC,aAC9BmC,EAAU/F,KAAKoG,EAAU9B,MAErB8B,EAAU5B,WACVmB,EAAe3F,KAAKmG,wFA9NxC,sCAoRUvI,iBAAQhE,aAGVJ,KAAA6M,EAAKpD,KAAKjG,QAAU,QAEHqJ,EAAKxM,8CAA6BwM,EAAK1M,YAAYC,qBAApE,IAAMyJ,cACAU,EAAQsC,EAAKlM,gBAEbmM,EAAaD,EAAKpD,KAAKrF,QACzByF,EAAUgD,EAAKlD,MAAOkD,EAAKjD,MAAOW,EAAOsC,EAAK3D,iBAIlD1I,EAAW,CAACqM,EAAKlD,MAAOkD,EAAKjD,QAC7BiD,EAAKlD,MAAQmD,EAAWrI,GAAGR,QAC3B4I,EAAKjD,MAAQkD,EAAWpI,GAAGT,QAE3B,IAAM8I,EAAqBvM,EAAQ,kBAAMsM,EAAWnI,EAAEkG,SAASE,cACzDiC,EAAsBxM,EAAQ,kBAAMsM,EAAWnI,EAAEoG,YAAYgC,KAWnE,OARAvM,EAAW,CAACqJ,EAAUU,IACtB/J,EAAWsM,GAGXD,EAAKpD,KAAKjG,QAAUqJ,EAAK1D,YAEzB0D,EAAKpM,aAAaoM,EAAK3M,QAAQ6M,IAExB,CAAErM,OAAQmM,EAAK3M,QAAQ6M,GAAYC,WAAAA,KAjTlD,sCA0TU9K,eAAMoJ,wBA8BR,IAAMS,EAAkBvL,EAAQ,kBAAMA,EAAQuL,gBAC1CvL,EAAUiK,GAAUjK,EAAU4J,GAAc6C,EAAK1J,cAG/C2I,EAAkB1L,EAAQ,kBAAMuL,EACjC9G,IAAIzE,QAAAA,EAAUuL,EAAgBtJ,QAC9B+E,IAAI,KAEH0F,EAAmB,CACrBf,eAAAA,EAEAC,SAAmB5L,EAAQ,kBACvB0L,EAAgB1E,MAAMzC,IAAIgH,EAAgBvE,OAAOuD,cAGrDsB,OAAiB7L,EAAQ,kBACrB0L,EAAgBnH,IAAIgH,EAAgBvE,IAAI,IAAIe,OAAOwC,cAGvDuB,UAAoB9L,EAAQ,kBACxB0L,EAAgBnH,IAAIgH,EAAgBvE,IAAI,IAAIe,OAAOwC,cAGvDoC,kBAAmBC,EAAY7D,OAAO,SAACiD,EAAGC,UAAMD,EAAIC,IAAKW,EAAY9L,QAMzE,OAHAd,EAAW,CAAC0L,EAAiBH,IAE7BkB,EAAKpM,cACEqM,KAhDHlN,KAVE2L,EAAiBC,OAAOC,QAAQP,GAEhCb,EAAoB,GACpBL,EAAwB,GACxBgD,EAAwB,GACxBjB,EAA2B,GAGxBO,EAAW,wBAAGA,EAAWf,EAAerK,4BAAQoL,GAAY,qBACrCf,EAAee,GAApCC,OAAY1C,OACnBgD,EAAKpM,cAEA,IAAIqK,EAAW,wBAAGA,EAAWjB,EAAM3I,4BAAQ4J,GAAY,eACxD,IAAMC,EAAQlB,EAAMiB,GADuC,uBAItB+B,EAAK7I,QAAQ+G,EAAM/K,6BAAhDM,IAAAA,OAAQsM,IAAAA,WAEhBvC,EAAQjE,KAAKyG,EAAK/M,QAAQiH,QAAQgE,EAAMzK,SACxC0J,EAAY5D,KAAKyG,EAAK/M,QAAQiH,QAAQzG,IACtC0M,EAAY5G,KAAKwG,GAEbtM,IAAWyK,EAAMzK,QAAWyL,EAAe5F,SAASoG,IACpDR,EAAe3F,KAAKmG,kGAlVxC,sCA2XI7L,KAAA,SAAKuM,GACD,IAAMtM,EAAauM,KAAKC,MAAMF,GAE9BrN,KAAK+I,YAAYW,QAAQ,SAACJ,GACtBA,EAAWxI,KAAKC,EAAWuI,EAAWkE,OAG1CxN,KAAKyJ,KAAK3I,KAAKC,EAAW0I,MAE1BzJ,KAAKa,6CAO4Bb,4BAAAyN,EAAKhE,6CAStC,OAAO6D,KAAKI,UAAU3M,GATtB,IAAMA,EAAa,CAAE0I,QAEZK,EAAM,wBAAGA,EAAM2D,EAAK1E,YAAYzH,4BAAQwI,GAAO,eACpD,IAAMR,EAAamE,EAAK1E,YAAYe,GADmB,uBAIrBR,6BAAlCvI,EAAWuI,EAAWkE,2CAjZlC,0CErFaG,cAsBT,WAAYC,EAA4BC,gBACpCrJ,sBACKoJ,iBAAmBA,EACxBpJ,EAAKqJ,oBAAsBA,WAzBnC,2BA4BIlN,cAAA,sBACI,YAAYT,QAAQU,IAAI,SAACF,GACrB,IAAMoN,OAA2BvN,IAAf4E,EAAK4I,MACjBC,EAAc7I,EAAKyI,iBAAiBrH,SAAS7F,GAC7CuN,EAAiB9I,EAAK0I,oBAAoBtH,SAAS7F,GAEzD,OAASoN,KAAeE,GAAeC,IAC/BH,IAAcG,OAI9BpN,YAAA,WACIb,KAAK+N,WAAQxN,KAMjB2N,SAAA,WACI,YAAYH,SAMhBI,SAAA,SAASJ,GACL/N,KAAK+N,MAAQA,MAtDYhO,wDC4C7B,oBACIqO,IAAAA,KACAC,IAAAA,eACAT,qBACAC,wBACAS,UAAAA,aAAY,aAEZ9J,yBAJmB,gBACG,aAKjB+J,cAAgB3C,OAAO4C,KAAKH,GACjC7J,EAAK6J,WAAaA,EAClB7J,EAAK8J,UAAYA,EAEjB9J,EAAKgJ,GAAQY,iBACb5J,EAAKuC,KAAO,EAAIvC,EAAK+J,cAAcjN,gBAvB3C,2BA0BUrB,cAAKC,qDACKD,YAAKC,oBACjB4G,EAAKjG,gBA5Bb,sCA+BY4N,YAAA,SAAYV,GAChB,IAAMQ,EAAgB3C,OAAO4C,KAAKxO,KAAKqO,YAEvC,OAAqB7N,EACjB+N,EAAcpH,QAAQ4G,EAAMW,UAC5BH,EAAcjN,WAIhBnB,qBAAYC,aACQJ,KAAhB2O,EAAgB1H,EAAKiH,WACvBU,EAA8B,CAAEF,cAAUnO,EAAW0B,aAAS1B,EAAW2B,MAAO,GAGpF0J,OAAOC,QAAQ5E,EAAKoH,YAAY3E,QAAQ,gBAAEgF,OAEhCG,OACDjO,IAAI,SAACkO,UAAYjN,EAAWzB,EAAMkH,cAAewH,EAAQxH,iBAEzDc,OAAO,SAAC2G,UAAMA,EAAE7M,OAAS+E,EAAKqH,YAE9B/E,OACG,SAACyF,EAAID,UAAOC,EAAG9M,MAAQ6M,EAAE7M,MAAQ8M,EAAKD,GACtC,CAAE9M,aAAS1B,EAAW2B,MAAO,IAIrC,QAAsB3B,IAAlBsO,EAAM5M,QAAuB,CAC7B,IAAMgN,EAAsBP,IAAaC,EAAcD,SACjDQ,EAAiBN,EAAUF,WAAaC,EAAcD,SACtDS,EAAcN,EAAM3M,MAAQ0M,EAAU1M,YAEjB3B,IAAvBqO,EAAUF,UACNO,GAAuBE,GACvBD,GAAkBD,GAClBC,GAAkBC,KAEtBP,KAAcF,SAAAA,GAAaG,OAKvC,IAAMhF,EAAWrJ,EAAQ,kBACrBA,EAAU,CACNyG,EAAKwH,YAAYG,GACjB3H,EAAKwH,YAAYxH,EAAKiH,gBAQ9B,YAJ2B3N,IAAvBqO,EAAUF,UACVzH,EAAKkH,SAASS,mBAGX/E,GApFf,sCAuFIqE,SAAA,WACI,YAAyB3N,IAArB6O,YAAMlB,oBACC,CAAEQ,cAAUnO,EAAW0B,aAAS1B,EAAW2B,MAAO,eAGhDgM,wBA5FgBP,kNFjCrC,SAAK7E,GACDA,qBAAOA,mBAAMA,uBAAQA,qBADzB,CAAKA,IAAAA,0FGuCW9I,YAKH,qBAGT,oGAgBc,0BAIL6I,EAAQ,IAAckF,MAGtBlF,8EApCb,4CH1B6BwG,GACzB,IAGMC,EAHiB,IAAIC,EAAkB,CAAEC,OAAO,IAChBjC,MAAM8B,GAEdC,SAC1BG,EAAQH,EAAOI,OAEbvE,EAAQ,CAEVwE,aAASpP,EACTqP,YAAQrP,EAERsP,UAAMtP,EACNuP,SAAU,GACVC,gBAAiB,GAEjBC,eAAWzP,EACX0J,MAAO,GACPgG,kBAAc1P,EACd2P,UAAWpH,EAAUqH,OAGnBC,EAA8B,CAAE9E,QAAS,GAAIyE,gBAAiB,IAEpE,SAASM,SACmB9P,IAApB4K,EAAM6E,YAEN7E,EAAMlB,MAAMzD,KAAK2E,EAAM8E,cAEvB9E,EAAMlB,MAAMzD,KAAK,CAAEpG,MAAO,GAAIM,OAAQ,QAGtC0P,EAAa9E,QAAQH,EAAM6E,WAAa7E,EAAMlB,MAG9CkB,EAAM6E,eAAYzP,EAClB4K,EAAMlB,MAAQ,GACdkB,EAAM8E,kBAAe1P,EACrB4K,EAAM+E,UAAYpH,EAAUqH,OAIpC,SAASG,EAASR,cACmCvP,IAA7C6P,EAAaL,gBAAgB5E,EAAM0E,QACnCO,EAAaL,gBAAgB5E,EAAM0E,MAAQ,OAI/CO,EAAaL,gBAAgB5E,EAAM0E,OAAMrJ,aAElC2E,EAAM4E,gBAAgBnP,IAAI,SAACmP,aAAuBD,SAAAA,GAAaC,MAGtE5E,EAAM4E,gBAAkB,GACxB5E,EAAM2E,SAAW,GAGrB,KAAiB,OAAVL,GAAgB,KACXc,EAAmBd,EAAnBc,SAAU9J,EAASgJ,EAAThJ,KAEd+J,EAKA/J,EALA+J,KACAC,EAIAhK,EAJAgK,QACAC,EAGAjK,EAHAiK,YACAC,EAEAlK,EAFAkK,KACAC,EACAnK,EADAmK,MAOJ,GAAIL,GAAqB,YAATC,GAAgC,IAAVI,EAClCzF,EAAMyE,OAAS,cACfS,YAKgB,SAATG,GAAoC,gBAAjBrF,EAAMyE,OAChCzE,EAAMwE,QAAUc,EAChBtF,EAAMyE,OAAYa,sBAMO,gBAAlBtF,EAAMwE,QAQTY,GAAqB,YAATC,GAAgC,IAAVI,EAClCzF,EAAMyE,OAAS,iBAKC,SAATY,GAAoC,mBAAjBrF,EAAMyE,QAC1Ba,KAAWL,EAAaL,kBAC1BK,EAAaL,gBAAgBU,GAAW,IAG5CtF,EAAM0E,KAAOY,EACbtF,EAAMyE,OAAS,iBAORW,GAAqB,SAATC,GAAoC,kBAAjBrF,EAAMyE,OAC5CzE,EAAMyE,OAAS,kBAKC,SAATY,GAAoC,oBAAjBrF,EAAMyE,OAChCzE,EAAM2E,UAAYW,EAOF,SAATD,GAAoC,oBAAjBrF,EAAMyE,QAChCzE,EAAM4E,gBAAgBvJ,KAAK,CACvBvE,QAASwO,EACTI,MAAO1F,EAAM2E,SAASxO,OACtBwP,IAAK3F,EAAM2E,SAASxO,OAASmP,EAAQnP,OAAS,IAGlD6J,EAAM2E,UAAYW,GAKVF,GAAqB,SAATC,GAAoC,oBAAjBrF,EAAMyE,SAC7CU,EAASnF,EAAM2E,UACf3E,EAAMyE,OAAS,yBAQM,kBAAlBzE,EAAMwE,QAQb,GAAIY,GAAqB,YAATC,GAAgC,IAAVI,EAClCzF,EAAMyE,OAAS,oBAEfS,YAKgB,SAATG,GAAoC,sBAAjBrF,EAAMyE,OAChCzE,EAAM6E,UAAYS,EAClBtF,EAAMyE,OAAS,2BAMfW,GACG,CAAC,cAAe,OAAQ,cAAchK,SAASiK,IAC9B,qBAAjBrF,EAAMyE,OAA+B,CAExC,IAAImB,SAEJ,OAAQP,GACR,IAAK,cACDO,EAAUjI,EAAU1I,MACpB,MAEJ,IAAK,OACD2Q,EAAUjI,EAAUpI,OACpB,MAEJ,IAAK,aACDqQ,EAAUjI,EAAUxI,KAuBxB,OAbIyQ,GAAW5F,EAAM+E,iBAEU3P,IAAvB4K,EAAM8E,eACN9E,EAAMlB,MAAMzD,KAAK2E,EAAM8E,cAEnBc,IAAYjI,EAAU1I,OAAuC,QAA9B+K,EAAM8E,aAAavP,QAClDyK,EAAMlB,MAAMzD,KAAa,CAAEpG,MAAO,GAAIM,OAAQ,SAItDyK,EAAM8E,aAAe,CAAE7P,MAAO,GAAIM,OAAQ,QAGtCqQ,GACR,KAAKjI,EAAU1I,MACX+K,EAAMyE,OAAS,oBACf,MAEJ,KAAK9G,EAAUpI,OACXyK,EAAMyE,OAAS,qBACf,MAEJ,KAAK9G,EAAUxI,KACE,SAATqQ,IACAxF,EAAM8E,aAAa3P,KAAOgN,KAAKC,MAAMkD,IAO7CtF,EAAM+E,UAAYa,MAKF,SAATP,GAAoC,sBAAjBrF,EAAMyE,OAChCzE,EAAM8E,aAAa7P,OAASqQ,EAKrBF,GAAqB,SAATC,GAAoC,sBAAjBrF,EAAMyE,QAC5CzE,EAAM0E,KAAOa,EACbvF,EAAMyE,OAAS,oBAKC,SAATY,GAAoC,qBAAjBrF,EAAMyE,QAChCzE,EAAM4E,gBAAgBvJ,KAAK,CACvBvE,QAASwO,EACTI,MAAO1F,EAAM8E,aAAa7P,MAAMkB,OAChCwP,IAAK3F,EAAM8E,aAAa7P,MAAMkB,OAASmP,EAAQnP,OAAS,IAG5D6J,EAAM8E,aAAa7P,OAASqQ,EAC5BtF,EAAMyE,OAAS,qBAKPW,GAAqB,gBAATC,GAA2C,sBAAjBrF,EAAMyE,OAQpC,SAATY,GAAoC,uBAAjBrF,EAAMyE,SAChCzE,EAAM8E,aAAavP,OAAS+P,EAC5BtF,EAAMyE,OAAS,qBATXzE,EAAM4E,gBAAgBzO,OAAS,GAAGgP,EAASnF,EAAM8E,aAAa7P,OAElE+K,EAAMyE,OAAS,oBAWvBH,EAAQH,EAAOI,OAKnB,OAFAW,IAEOD,2BIhSoB9E,EAAkB0F,GAK7C,IAHA,IAAMC,EAAerF,OAAOC,QAAQP,GAC9B4F,EAAc,GAEX1P,EAAI,EAAGA,EAAIyP,EAAa3P,OAAS0P,EAAUxP,GAAK,EACrD0P,EAAY1K,WAAZ0K,EAAoBD,EAAaE,OAC7BzP,KAAK0P,MAAM1P,KAAK2P,SAAWJ,EAAa3P,QAAS,IAIzD,MAAO,CACH+J,MAAOO,OAAO0F,YAAYL,GAC1BM,KAAM3F,OAAO0F,YAAYJ,6BD0B7B,sBAEIM,MAAAA,aAAQ,SACR3K,UAAAA,aAAY,QAEZ7G,KAAKyR,QAJLA,MAKAzR,KAAKwR,MAAQA,EACbxR,KAAK6G,UAAYA,EAZzB,2BAkBU6K,aAAItR,aAQ6BJ,KAP7B2R,EAAoB,CACtBvR,MAAAA,EACAF,QAAS,GACT0R,eAAgB,EAChBJ,MAAO,2BAGwBrM,EAAKsM,MAAMrN,QAAQhE,yBAAhDM,IAAAA,OAAQsM,IAAAA,wBAcd,OAJA7H,EAAKqM,MAAM9H,QAAQ,SAACmG,GAChB8B,EAAOH,MAAM3B,EAAKrC,IAAMqC,EAAK3B,aAG1ByD,ukBAZAjR,IAAWyE,EAAK0B,wBAAW,OAC9B8K,EAAOzR,QAAQsG,KAAK9F,GACpBiR,EAAOC,gBAAkB5E,kBAGO7H,EAAKsM,MAAMrN,QAAQ,sBAAhD1D,IAAAA,OAAQsM,IAAAA,gDAjCvB,sCA8CInM,YAAA,WACIb,KAAKyR,MAAM5Q,4CEvDf,kBACIgR,IAAAA,eACA9K,IAAAA,SACA+K,aAAAA,aAAe,aACfC,MAAAA,oBACAC,YAAAA,aAAc,SACd7L,WAAAA,kBAAa5F,IAEb,IAAK,CAAC,OAAQ,aAAagG,SAASuL,GAChC,UAAU/O,MAAM,kEAGpB/C,KAAK6R,eAAiBA,EAEtB7R,KAAK+G,KAAOA,EACZ/G,KAAK8R,aAAeA,EACpB9R,KAAK+R,MAAQA,EAEb/R,KAAKgS,YAAcA,EACnBhS,KAAKmG,WAAaA,EAnC1B,2BAyCIqI,KAAA,WACI,OAAO5C,OAAO4C,KAAKxO,KAAK+H,YAMtBjH,0BACFd,4BAAgCmF,EAAK0M,mCAArC1M,EAAK4C,QAAUuF,KAAKC,SAEM,cAAtBpI,EAAK2M,eACL3M,EAAK8M,KAAO,IAAInM,EAChBX,EAAKqJ,OAAO9E,QAAQ,SAACnE,YAAa0M,KAAKpN,IAAIU,QArDvD,sCA4DIyC,SAAA,WACI,YAAwBzH,SAAZwH,WAUhBI,IAAA,SAAI5C,GAEA,GAAIvF,KAAKwO,OAAOjI,SAAShB,GACrB,OAAO/E,EAAYR,KAAK+H,QAAQxC,IAIpC,IAAI2M,EACAC,EAAyBC,SAW7B,OATApS,KAAKwO,OAAO9E,QAAQ,SAAC2I,GACjB,IAAMC,EAAWtR,EAAoBqR,EAAU9M,GAE3C+M,EAAWH,IACXD,EAAUG,EACVF,EAAiBG,KAIrBH,GAAkBnS,KAAKgS,YAChBxR,EAAUR,KAAK+H,QAAQmK,SAIV3R,IAApBP,KAAKmG,WACE3F,EAAUR,KAAK+H,QAAQ/H,KAAKmG,kBADvC,KAaIoM,aAAA,SAAazQ,GACjB,OAAOA,EAAKoE,MAAM,OAAOkC,OAAO,SAACF,UAAUA,EAAM5G,OAAS,OAQtDkR,iBAAA,SAAiB1Q,GACrB,IAAM2Q,OAAc3Q,GAAOoE,MAAM,KAAKwM,KAAK,KAE3C,YAAYT,KAAK/L,MAAMuM,EAASzS,KAAKmG,WAAY,CAAC,SAQtD8B,SAAA,SAASnG,GAML,OALI9B,KAAK+R,QAELjQ,EAAOA,EAAKwF,eAGRtH,KAAK8R,cACb,IAAK,OACD,YAAYS,aAAazQ,GAE7B,IAAK,YACD,YAAY0Q,iBAAiB1Q,GAEjC,QACI,UAAUiB,MAAM"}