{"version":3,"file":"wisty.modern.js","sources":["../src/featurizers/featurizer.ts","../src/utils/levenshtein_distance.ts","../src/utils/fuzzy_match.ts","../src/utils/hashcode.ts","../src/utils/initialize_variable.ts","../src/utils/lstm.ts","../src/featurizers/action_featurizer.ts","../src/featurizers/bow.ts","../src/featurizers/use.ts","../src/featurizers/word_embedding.ts","../node_modules/babel-plugin-transform-async-to-promises/helpers.js","../src/models/hcn.ts","../src/slots/categorical_slot.ts","../src/tools/parse_stories.ts","../src/tools/train_test_split.ts"],"sourcesContent":["import * as tf from '@tensorflow/tfjs';\n\ntype JSONSerializable = {[key: string]: any};\n\n/**\n * A stateful featurizer that turns queries into numerical representations.\n */\nexport abstract class Featurizer {\n    /**\n     * An ID used by models for exportations.\n     */\n    readonly id: string;\n\n    /**\n     * The list of every action the model can take.\n     */\n    protected actions: any[];\n\n    /**\n     * The size of the vector returned by the featurizer.\n     */\n    readonly size: number;\n\n    /**\n     * Initialize the model, can be asynchronous async code.\n     * This method is executed by the model during it's initialization,\n     * it will also set the actions attribute.\n     */\n    async init(actions: any[]) {\n        this.actions = actions;\n    }\n\n    /**\n     * Featurizes and handle a text query.\n     *\n     * This method can directly return a 1D tensor to provide features to the model.\n     * Alternatively, it can returns data of any type if the Featurizer implement a custom\n     * getOptimizableFeatures method to handle those data.\n     * @async\n     */\n    abstract handleQuery(query: string): Promise<any>;\n\n    /**\n     * Turn the data returned by handleQuery into an embedding vector.\n     * This function is used to expose featurizer variables to the model optimizer for training.\n     *\n     * Reimplementing this method is not necessary if your featurizer is not meant to be optimizable\n     * through gradient descent.\n     * In this case, just return the feature vector directly using the handleQuery method.\n     *\n     * It's important to keep this function stateless, it should only depend of its tensor argument\n     * and of featurizer's variables.\n     */\n    // eslint-disable-next-line class-methods-use-this\n    getOptimizableFeatures(data: any): tf.Tensor1D {\n        return <tf.Tensor1D> data;\n    }\n\n    /**\n     * Let the featurizer know what action the model has taken.\n     */\n    // eslint-disable-next-line no-unused-vars, class-methods-use-this\n    handleAction(action: any): void {}\n\n    /**\n     * Produce an action mask according to featurizer state.\n     * (Generally, this method is reimplemented in stateful featurizers)\n     *\n     * @returns An array of boolean mapping every actions availability.\n     */\n    getActionMask(): boolean[] {\n        return this.actions.map(() => true);\n    }\n\n    /**\n     * Resets the state of the featurizer (if the stateful feature is used).\n     */\n    // eslint-disable-next-line class-methods-use-this\n    resetDialog(): void {}\n\n    /**\n     * Load parameters extracted from a JSON-like document.\n     */\n    // eslint-disable-next-line no-unused-vars, class-methods-use-this\n    load(parameters: JSONSerializable) {}\n\n    /**\n     * Export the featurizer's internal parameters to be serialized along the model.\n     */\n    // eslint-disable-next-line class-methods-use-this\n    async export(): Promise<JSONSerializable> {\n        return {};\n    }\n}\n","/**\n * Compute the Levenshtein distance between two strings using the Wagner-Fisher algorithm.\n * (as described at https://en.wikipedia.org/wiki/Wagner%E2%80%93Fischer_algorithm)\n */\nexport function levenshteinDistance(s1: string, s2: string): number {\n    const d = Array.from(\n        Array(s1.length + 1),\n        () => new Array(s2.length + 1).fill(0)\n    );\n\n    for (let i = 1; i <= s1.length; i += 1) {\n        d[i][0] = i;\n    }\n\n    for (let j = 1; j <= s2.length; j += 1) {\n        d[0][j] = j;\n    }\n\n    for (let j = 0; j < s2.length; j += 1) {\n        for (let i = 0; i < s1.length; i += 1) {\n            const substitutionCost = (s1[i] !== s2[j]) ? 1 : 0;\n\n            d[i + 1][j + 1] = Math.min(\n                d[i][j + 1] + 1,\n                d[i + 1][j] + 1,\n                d[i][j] + substitutionCost\n            );\n        }\n    }\n\n    return d[s1.length][s2.length] / Math.max(s1.length, s2.length, 1);\n}\n","import { levenshteinDistance } from './levenshtein_distance';\n\ntype Match = { extract: string, score: number };\n\nexport function fuzzyMatch(text: string, substring: string): Match {\n    let bestMatch: Match = { extract: undefined, score: 0 };\n\n    for (let i = 0; i < text.length; i += 1) {\n        const extract = text.substring(i, i + substring.length);\n\n        const aMatch = {\n            extract,\n            score: 1 - levenshteinDistance(extract, substring)\n        };\n\n        if (aMatch.score === 1) {\n            return aMatch;\n        }\n\n        if (aMatch.score > bestMatch.score) {\n            bestMatch = aMatch;\n        }\n    }\n\n    return bestMatch;\n}\n","/* eslint-disable no-bitwise */\n\n/**\n * Hash a string.\n * Based on https://stackoverflow.com/a/7616484\n */\nexport function hashcode(input: string) {\n    let hash = 0;\n\n    for (let i = 0; i < input.length; i += 1) {\n        const chr = input.charCodeAt(i);\n\n        hash = ((hash << 5) - hash) + chr;\n        hash |= 0; // Convert to 32bit integer\n    }\n\n    return hash;\n}\n","import * as tf from '@tensorflow/tfjs';\n\n/**\n * Initialize a variable of a given shape.\n */\nexport function initializeVariable(shape: number[], scalar: boolean = false,\n    init: 'he'|'zeros'|'normal' = 'he'): tf.Variable {\n    return tf.tidy(() => {\n        let initializer;\n\n        switch (init) {\n        case 'he':\n            initializer = tf.initializers.heNormal({});\n            break;\n\n        case 'zeros':\n            initializer = tf.initializers.zeros();\n            break;\n\n        case 'normal':\n            initializer = tf.initializers.randomNormal({});\n            break;\n\n        default:\n            throw new Error(\n                `Expected parameter init to take value 'he', 'zeros' or 'normal' not '${init}'.`\n            );\n        }\n\n        let randomTensor = initializer.apply(shape);\n        if (scalar) randomTensor = randomTensor.asScalar();\n\n        return randomTensor.variable();\n    });\n}\n","import * as tf from '@tensorflow/tfjs';\nimport { initializeVariable } from './initialize_variable';\n\ntype LSTMPrediction = {y: tf.Tensor1D, nc: tf.Tensor2D, nh: tf.Tensor2D};\n\n/**\n * An LSTM cell with a dense layer on its top.\n */\nexport class LSTM {\n    // LSTM parameters :\n    private lstmKernel: tf.Tensor;\n    private lstmBias: tf.Tensor;\n    private lstmForgetBias: tf.Tensor;\n    private lstmInitH: tf.Tensor;\n    private lstmInitC: tf.Tensor;\n\n    // Dense layer parameters :\n    private denseWeights: tf.Tensor;\n    private denseBias: tf.Tensor;\n\n    // Let dropout be public to allow to change its value when training/inference.\n    public dropout: number;\n\n    /**\n     * @param inputSize The dimension of the input data.\n     * @param hiddenSize The dimension of the output of the LSTM, passed to the dense layer.\n     * @param outputSize The dimension of the output data.\n     * @param dropout The dropout rate between the LSTM cell and the dense layer.\n     */\n    constructor(inputSize: number, hiddenSize: number, outputSize: number, dropout: number = 0.2) {\n        this.lstmKernel = initializeVariable([inputSize + hiddenSize, hiddenSize * 4]);\n        this.lstmBias = initializeVariable([hiddenSize * 4], false, 'zeros');\n        this.lstmForgetBias = initializeVariable([1], true, 'zeros'); // (scalar)\n        this.lstmInitH = initializeVariable([1, hiddenSize]);\n        this.lstmInitC = initializeVariable([1, hiddenSize]);\n\n        this.denseWeights = initializeVariable([hiddenSize, outputSize]);\n        this.denseBias = initializeVariable([outputSize], false, 'zeros');\n\n        this.dropout = dropout;\n    }\n\n    /**\n     * Gives the initial state values of the LSTM (c and h).\n     *\n     * @param clone If it is necessary to clone states variable or no.\n     */\n    initLSTM(clone: boolean = true): {c: tf.Tensor2D, h: tf.Tensor2D} {\n        return {\n            c: <tf.Tensor2D> (clone ? this.lstmInitC.clone() : this.lstmInitC),\n            h: <tf.Tensor2D> (clone ? this.lstmInitH.clone() : this.lstmInitH)\n        };\n    }\n\n    /**\n     * Make a prediction given an input and state values (c and h).\n     * @param x A vector of shape [inputSize].\n     * @param c LSTM's state value.\n     * @param h LSTM's last output value.\n     * @param mask A vector of ones and zeros of shape [outputSize].\n     */\n    predict(x: tf.Tensor1D, c: tf.Tensor2D, h: tf.Tensor2D, mask?: tf.Tensor1D,\n        temperature: number = 1): LSTMPrediction {\n        return tf.tidy(() => {\n            // Execute the LSTM cell.\n            const [nc, nh] = tf.basicLSTMCell(\n                <tf.Scalar> this.lstmForgetBias,\n                <tf.Tensor2D> this.lstmKernel,\n                <tf.Tensor1D> this.lstmBias,\n                <tf.Tensor2D> tf.stack([x]),\n                h, c\n            );\n\n            // Execute the dense layer on top of the LSTM cell.\n            let y = <tf.Tensor1D> tf\n                .dropout(nh, this.dropout)\n                .matMul(this.denseWeights)\n                .add(this.denseBias)\n                .squeeze()\n                .div(temperature)\n                .softmax()\n                .mul(mask ?? 1);\n\n            // Apply normalization after the mask to get probabilities.\n            y = y.div(tf.sum(y));\n\n            return { y, nc, nh };\n        });\n    }\n\n    /**\n     * Update the given model parameters.\n     */\n    load(weights: {[key: string]: any}) {\n        tf.tidy(() => {\n            // Convert every parameter to a tf variable tensor.\n            this.lstmKernel = tf.tensor(weights.lstmKernel).variable();\n            this.lstmBias = tf.tensor(weights.lstmBias).variable();\n            this.lstmForgetBias = tf.tensor(weights.lstmForgetBias).variable();\n            this.lstmInitH = tf.tensor(weights.lstmInitH).variable();\n            this.lstmInitC = tf.tensor(weights.lstmInitC).variable();\n            this.denseWeights = tf.tensor(weights.denseWeights).variable();\n            this.denseBias = tf.tensor(weights.denseBias).variable();\n        });\n    }\n\n    /**\n     * Return all the LSTM model parameters.\n     */\n    async export(): Promise<{[key: string]: any}> {\n        const exports = {\n            lstmKernel: await this.lstmKernel.array(),\n            lstmBias: await this.lstmBias.array(),\n            lstmForgetBias: await this.lstmForgetBias.array(),\n            lstmInitH: await this.lstmInitH.array(),\n            lstmInitC: await this.lstmInitC.array(),\n            denseWeights: await this.denseWeights.array(),\n            denseBias: await this.denseBias.array()\n        };\n\n        return exports;\n    }\n}\n","import * as tf from '@tensorflow/tfjs';\nimport { Featurizer } from './featurizer';\nimport { initializeVariable } from '../utils';\n\n/**\n * Parameters for ActionFeaturizer constructor.\n */\ninterface ActionFeaturizerArgs {\n    /**\n     * Enable the masking of LUS when the user has just talked.\n     * Enabled by default.\n     */\n    maskLUS?: boolean;\n\n    /**\n     * Enable the masking of the previous action.\n     * Enabled by default.\n     */\n    maskPreviousAction?: boolean;\n\n    /**\n     * The action the bot takes to let the user talk.\n     * Default to 'LUS' (acronym for Let User Speak)\n     */\n    LUSAction?: string;\n}\n\n/**\n * Rule-based featurizer improving model robustness.\n *\n * - Featurize the previous action the model has taken.\n * - Mask the LUS action when the user has just talked.\n *   (Force the model to reply at least once)\n * - Mask the previous action.\n *   (Prevent looping : the model can't take two times in a row the same action)\n */\nexport class ActionFeaturizer extends Featurizer {\n    readonly id = 'Action Featurizer';\n    size: number;\n\n    private LUSAction: any;\n    private maskLUS: boolean;\n    private maskPreviousAction: boolean;\n\n    private userTalked: boolean;\n    private previousAction: any;\n\n    private embeddings: tf.Tensor;\n\n    constructor({\n        maskLUS = true,\n        maskPreviousAction = true,\n        LUSAction = 'LUS'\n    }: ActionFeaturizerArgs = { maskLUS: true, maskPreviousAction: true, LUSAction: 'LUS' }) {\n        super();\n        this.maskLUS = maskLUS;\n        this.maskPreviousAction = maskPreviousAction;\n        this.LUSAction = LUSAction;\n\n        this.resetDialog();\n    }\n\n    async init(actions: any[]) {\n        await super.init(actions);\n\n        this.size = actions.length;\n        this.embeddings = initializeVariable([this.size, this.size]);\n    }\n\n    async handleQuery(query: string): Promise<tf.Tensor2D> {\n        return tf.tidy(() => {\n            this.userTalked = query !== '';\n\n            // One-hot encode the previous action.\n            return <tf.Tensor2D> tf.oneHot(\n                [this.actions.indexOf(this.previousAction)],\n                this.actions.length\n            );\n        });\n    }\n\n    getOptimizableFeatures(data: tf.Tensor2D): tf.Tensor1D {\n        return <tf.Tensor1D> data.matMul(this.embeddings).squeeze();\n    }\n\n    handleAction(action: any) {\n        // Store the new action if it's not the LUS action.\n        this.previousAction = action !== this.LUSAction ? action : this.previousAction;\n    }\n\n    getActionMask(): boolean[] {\n        const mask = super.getActionMask();\n\n        // Mask LUS when the user talk and the option is enabled.\n        if (this.maskLUS && this.userTalked) {\n            mask[this.actions.indexOf(this.LUSAction)] = false;\n        }\n\n        // Mask the previous action when the option is enabled and if applicable.\n        if (this.maskPreviousAction && this.actions.includes(this.previousAction)) {\n            mask[this.actions.indexOf(this.previousAction)] = false;\n        }\n\n        return mask;\n    }\n\n    resetDialog() {\n        this.userTalked = false;\n        this.previousAction = undefined;\n    }\n\n    load(parameters: {embeddings: number[][]}) {\n        this.embeddings = tf.tidy(() => tf.tensor(parameters.embeddings).variable());\n    }\n\n    async export(): Promise<{embeddings: number[][]}> {\n        return {\n            embeddings: <number[][]> await this.embeddings.array()\n        };\n    }\n}\n","import * as tf from '@tensorflow/tfjs';\nimport { Featurizer } from './featurizer';\nimport { hashcode } from '../utils';\n\n/**\n * Featurizes queries as bag of words.\n * The algorithm use the hashing trick to avoid having to store a vocabulary in the memory.\n */\nexport class BOW extends Featurizer {\n    readonly id = 'Bag-of-Words';\n    readonly size: number;\n\n    constructor(size: number) {\n        super();\n        this.size = size;\n    }\n\n    /**\n     * @return A tensor of shape [size].\n     */\n    async handleQuery(query: string): Promise<tf.Tensor1D> {\n        return tf.tidy(() => {\n            const indexes = query.toLowerCase()\n                .split(/\\W/g)\n                .map((word) => hashcode(word) % this.size);\n\n            return <tf.Tensor1D> tf.oneHot(indexes, this.size).asType('float32').sum(0);\n        });\n    }\n}\n","import * as tf from '@tensorflow/tfjs';\nimport * as use from '@tensorflow-models/universal-sentence-encoder';\nimport { Featurizer } from './featurizer';\n\n/**\n * Featurizes queries using the Universal Sentence Encoder model.\n */\nexport class USE extends Featurizer {\n    readonly id = 'Universal Sentence Encoder';\n\n    private encoder: use.UniversalSentenceEncoder;\n    private emptyEncoding: tf.Tensor1D;\n\n    readonly size = 512;\n\n    /**\n     * Initializes the Universal Sentence Encoder model.\n     */\n    async init(actions: any[]) {\n        await super.init(actions);\n        this.encoder = await use.load();\n\n        // Cache the empty string embed (for optimization purpose).\n        this.emptyEncoding = await this.encodeQuery('');\n    }\n\n    /**\n     * Encodes a query using the model.\n     */\n    private async encodeQuery(query: string): Promise<tf.Tensor1D> {\n        const embed = await this.encoder.embed([query]);\n        const squeezedEmbed = <tf.Tensor1D> embed.squeeze();\n        tf.dispose(embed);\n\n        return squeezedEmbed;\n    }\n\n    /**\n     * @return A tensor of shape [512].\n     */\n    async handleQuery(query: string): Promise<tf.Tensor1D> {\n        // When the query is empty, return the cached empty query encoding.\n        if (!query) {\n            return this.emptyEncoding.clone();\n        }\n\n        return this.encodeQuery(query);\n    }\n}\n","import * as tf from '@tensorflow/tfjs';\nimport { Featurizer } from './featurizer';\nimport { levenshteinDistance } from '../utils';\n\n/**\n * Featurize queries by pooling words embedding using SWEM-concat(*).\n *\n * (*): Dinghan Shen, Guoyin Wang, Wenlin Wang, Martin Renqiang Min, Qinliang Su, Yizhe Zhang,\n *      Chunyuan Li, Ricardo Henao, Lawrence Carin- 2018.\n *      Baseline Needs More Love: On Simple Word-Embedding-Based Models and\n *      Associated Pooling Mechanisms.\n */\nexport class WordEmbedding extends Featurizer {\n    readonly id = 'Word Embedding';\n    readonly size: number;\n\n    private loaderFunction: () => Promise<string>;\n    private vectors: {[word: string]: number[]};\n\n    /**\n     * @param loaderFunction A function that loads the json string containing the embedding.\n     * @param size The dimension of the word embedding\n     */\n    constructor(loaderFunction: () => Promise<string>, size: number) {\n        super();\n        this.size = 2 * size;\n        this.loaderFunction = loaderFunction;\n    }\n\n    async init(actions: any[]) {\n        await super.init(actions);\n        this.vectors = JSON.parse(await this.loaderFunction());\n    }\n\n    async handleQuery(query: string): Promise<tf.Tensor1D> {\n        return <tf.Tensor1D> tf.tidy(() => {\n            const tokens = query.toLowerCase() // Word embeddings are uncased.\n                .split(/\\W/g) // Tokenize at each non-word character.\n                .filter((token) => token.length > 0);\n\n            const embeddings: tf.Tensor1D[] = [];\n\n            tokens.forEach((token) => {\n                // If the token in in the vocabulary, just use its embedding.\n                if (Object.keys(this.vectors).includes(token)) {\n                    embeddings.push(tf.tensor(this.vectors[token]));\n\n                // If the token is out of vocabulary, use the most similarly spelled token instead.\n                } else {\n                    let bestToken: string;\n                    let lowestDistance: number = Infinity;\n\n                    Object.keys(this.vectors).forEach((vocabToken) => {\n                        const distance = levenshteinDistance(vocabToken, token);\n\n                        if (distance < lowestDistance) {\n                            bestToken = vocabToken;\n                            lowestDistance = distance;\n                        }\n                    });\n\n                    if (lowestDistance < 0.5) {\n                        embeddings.push(tf.tensor(this.vectors[bestToken]));\n                    }\n                }\n            });\n\n            // When there is no embeddable tokens, return a zeros vector.\n            if (embeddings.length === 0) {\n                return tf.zeros([this.size]);\n            }\n\n            const embeddingsMatrix = tf.stack(embeddings);\n\n            return tf.concat([embeddingsMatrix.mean(0), embeddingsMatrix.max(0)]);\n        });\n    }\n}\n","// A type of promise-like that resolves synchronously and supports only one observer\nexport const _Pact = /*#__PURE__*/(function() {\n\tfunction _Pact() {}\n\t_Pact.prototype.then = function(onFulfilled, onRejected) {\n\t\tconst result = new _Pact();\n\t\tconst state = this.s;\n\t\tif (state) {\n\t\t\tconst callback = state & 1 ? onFulfilled : onRejected;\n\t\t\tif (callback) {\n\t\t\t\ttry {\n\t\t\t\t\t_settle(result, 1, callback(this.v));\n\t\t\t\t} catch (e) {\n\t\t\t\t\t_settle(result, 2, e);\n\t\t\t\t}\n\t\t\t\treturn result;\n\t\t\t} else {\n\t\t\t\treturn this;\n\t\t\t}\n\t\t}\n\t\tthis.o = function(_this) {\n\t\t\ttry {\n\t\t\t\tconst value = _this.v;\n\t\t\t\tif (_this.s & 1) {\n\t\t\t\t\t_settle(result, 1, onFulfilled ? onFulfilled(value) : value);\n\t\t\t\t} else if (onRejected) {\n\t\t\t\t\t_settle(result, 1, onRejected(value));\n\t\t\t\t} else {\n\t\t\t\t\t_settle(result, 2, value);\n\t\t\t\t}\n\t\t\t} catch (e) {\n\t\t\t\t_settle(result, 2, e);\n\t\t\t}\n\t\t};\n\t\treturn result;\n\t}\n\treturn _Pact;\n})();\n\n// Settles a pact synchronously\nexport function _settle(pact, state, value) {\n\tif (!pact.s) {\n\t\tif (value instanceof _Pact) {\n\t\t\tif (value.s) {\n\t\t\t\tif (state & 1) {\n\t\t\t\t\tstate = value.s;\n\t\t\t\t}\n\t\t\t\tvalue = value.v;\n\t\t\t} else {\n\t\t\t\tvalue.o = _settle.bind(null, pact, state);\n\t\t\t\treturn;\n\t\t\t}\n\t\t}\n\t\tif (value && value.then) {\n\t\t\tvalue.then(_settle.bind(null, pact, state), _settle.bind(null, pact, 2));\n\t\t\treturn;\n\t\t}\n\t\tpact.s = state;\n\t\tpact.v = value;\n\t\tconst observer = pact.o;\n\t\tif (observer) {\n\t\t\tobserver(pact);\n\t\t}\n\t}\n}\n\nexport function _isSettledPact(thenable) {\n\treturn thenable instanceof _Pact && thenable.s & 1;\n}\n\n// Converts argument to a function that always returns a Promise\nexport function _async(f) {\n\treturn function() {\n\t\tfor (var args = [], i = 0; i < arguments.length; i++) {\n\t\t\targs[i] = arguments[i];\n\t\t}\n\t\ttry {\n\t\t\treturn Promise.resolve(f.apply(this, args));\n\t\t} catch(e) {\n\t\t\treturn Promise.reject(e);\n\t\t}\n\t}\n}\n\n// Awaits on a value that may or may not be a Promise (equivalent to the await keyword in ES2015, with continuations passed explicitly)\nexport function _await(value, then, direct) {\n\tif (direct) {\n\t\treturn then ? then(value) : value;\n\t}\n\tif (!value || !value.then) {\n\t\tvalue = Promise.resolve(value);\n\t}\n\treturn then ? value.then(then) : value;\n}\n\n// Awaits on a value that may or may not be a Promise, then ignores it\nexport function _awaitIgnored(value, direct) {\n\tif (!direct) {\n\t\treturn value && value.then ? value.then(_empty) : Promise.resolve();\n\t}\n}\n\n// Proceeds after a value has resolved, or proceeds immediately if the value is not thenable\nexport function _continue(value, then) {\n\treturn value && value.then ? value.then(then) : then(value);\n}\n\n// Proceeds after a value has resolved, or proceeds immediately if the value is not thenable\nexport function _continueIgnored(value) {\n\tif (value && value.then) {\n\t\treturn value.then(_empty);\n\t}\n}\n\n// Asynchronously iterate through an object that has a length property, passing the index as the first argument to the callback (even as the length property changes)\nexport function _forTo(array, body, check) {\n\tvar i = -1, pact, reject;\n\tfunction _cycle(result) {\n\t\ttry {\n\t\t\twhile (++i < array.length && (!check || !check())) {\n\t\t\t\tresult = body(i);\n\t\t\t\tif (result && result.then) {\n\t\t\t\t\tif (_isSettledPact(result)) {\n\t\t\t\t\t\tresult = result.v;\n\t\t\t\t\t} else {\n\t\t\t\t\t\tresult.then(_cycle, reject || (reject = _settle.bind(null, pact = new _Pact(), 2)));\n\t\t\t\t\t\treturn;\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t\tif (pact) {\n\t\t\t\t_settle(pact, 1, result);\n\t\t\t} else {\n\t\t\t\tpact = result;\n\t\t\t}\n\t\t} catch (e) {\n\t\t\t_settle(pact || (pact = new _Pact()), 2, e);\n\t\t}\n\t}\n\t_cycle();\n\treturn pact;\n}\n\n// Asynchronously iterate through an object's properties (including properties inherited from the prototype)\n// Uses a snapshot of the object's properties\nexport function _forIn(target, body, check) {\n\tvar keys = [];\n\tfor (var key in target) {\n\t\tkeys.push(key);\n\t}\n\treturn _forTo(keys, function(i) { return body(keys[i]); }, check);\n}\n\n// Asynchronously iterate through an object's own properties (excluding properties inherited from the prototype)\n// Uses a snapshot of the object's properties\nexport function _forOwn(target, body, check) {\n\tvar keys = [];\n\tfor (var key in target) {\n\t\tif (Object.prototype.hasOwnProperty.call(target, key)) {\n\t\t\tkeys.push(key);\n\t\t}\n\t}\n\treturn _forTo(keys, function(i) { return body(keys[i]); }, check);\n}\n\nexport const _iteratorSymbol = /*#__PURE__*/ typeof Symbol !== \"undefined\" ? (Symbol.iterator || (Symbol.iterator = Symbol(\"Symbol.iterator\"))) : \"@@iterator\";\n\n// Asynchronously iterate through an object's values\n// Uses for...of if the runtime supports it, otherwise iterates until length on a copy\nexport function _forOf(target, body, check) {\n\tif (typeof target[_iteratorSymbol] === \"function\") {\n\t\tvar iterator = target[_iteratorSymbol](), step, pact, reject;\n\t\tfunction _cycle(result) {\n\t\t\ttry {\n\t\t\t\twhile (!(step = iterator.next()).done && (!check || !check())) {\n\t\t\t\t\tresult = body(step.value);\n\t\t\t\t\tif (result && result.then) {\n\t\t\t\t\t\tif (_isSettledPact(result)) {\n\t\t\t\t\t\t\tresult = result.v;\n\t\t\t\t\t\t} else {\n\t\t\t\t\t\t\tresult.then(_cycle, reject || (reject = _settle.bind(null, pact = new _Pact(), 2)));\n\t\t\t\t\t\t\treturn;\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tif (pact) {\n\t\t\t\t\t_settle(pact, 1, result);\n\t\t\t\t} else {\n\t\t\t\t\tpact = result;\n\t\t\t\t}\n\t\t\t} catch (e) {\n\t\t\t\t_settle(pact || (pact = new _Pact()), 2, e);\n\t\t\t}\n\t\t}\n\t\t_cycle();\n\t\tif (iterator.return) {\n\t\t\tvar _fixup = function(value) {\n\t\t\t\ttry {\n\t\t\t\t\tif (!step.done) {\n\t\t\t\t\t\titerator.return();\n\t\t\t\t\t}\n\t\t\t\t} catch(e) {\n\t\t\t\t}\n\t\t\t\treturn value;\n\t\t\t}\n\t\t\tif (pact && pact.then) {\n\t\t\t\treturn pact.then(_fixup, function(e) {\n\t\t\t\t\tthrow _fixup(e);\n\t\t\t\t});\n\t\t\t}\n\t\t\t_fixup();\n\t\t}\n\t\treturn pact;\n\t}\n\t// No support for Symbol.iterator\n\tif (!(\"length\" in target)) {\n\t\tthrow new TypeError(\"Object is not iterable\");\n\t}\n\t// Handle live collections properly\n\tvar values = [];\n\tfor (var i = 0; i < target.length; i++) {\n\t\tvalues.push(target[i]);\n\t}\n\treturn _forTo(values, function(i) { return body(values[i]); }, check);\n}\n\nexport const _asyncIteratorSymbol = /*#__PURE__*/ typeof Symbol !== \"undefined\" ? (Symbol.asyncIterator || (Symbol.asyncIterator = Symbol(\"Symbol.asyncIterator\"))) : \"@@asyncIterator\";\n\n// Asynchronously iterate on a value using it's async iterator if present, or its synchronous iterator if missing\nexport function _forAwaitOf(target, body, check) {\n\tif (typeof target[_asyncIteratorSymbol] === \"function\") {\n\t\tvar pact = new _Pact();\n\t\tvar iterator = target[_asyncIteratorSymbol]();\n\t\titerator.next().then(_resumeAfterNext).then(void 0, _reject);\n\t\treturn pact;\n\t\tfunction _resumeAfterBody(result) {\n\t\t\tif (check && check()) {\n\t\t\t\treturn _settle(pact, 1, iterator.return ? iterator.return().then(function() { return result; }) : result);\n\t\t\t}\n\t\t\titerator.next().then(_resumeAfterNext).then(void 0, _reject);\n\t\t}\n\t\tfunction _resumeAfterNext(step) {\n\t\t\tif (step.done) {\n\t\t\t\t_settle(pact, 1);\n\t\t\t} else {\n\t\t\t\tPromise.resolve(body(step.value)).then(_resumeAfterBody).then(void 0, _reject);\n\t\t\t}\n\t\t}\n\t\tfunction _reject(error) {\n\t\t\t_settle(pact, 2, iterator.return ? iterator.return().then(function() { return error; }) : error);\n\t\t}\n\t}\n\treturn Promise.resolve(_forOf(target, function(value) { return Promise.resolve(value).then(body); }, check));\n}\n\n// Asynchronously implement a generic for loop\nexport function _for(test, update, body) {\n\tvar stage;\n\tfor (;;) {\n\t\tvar shouldContinue = test();\n\t\tif (_isSettledPact(shouldContinue)) {\n\t\t\tshouldContinue = shouldContinue.v;\n\t\t}\n\t\tif (!shouldContinue) {\n\t\t\treturn result;\n\t\t}\n\t\tif (shouldContinue.then) {\n\t\t\tstage = 0;\n\t\t\tbreak;\n\t\t}\n\t\tvar result = body();\n\t\tif (result && result.then) {\n\t\t\tif (_isSettledPact(result)) {\n\t\t\t\tresult = result.s;\n\t\t\t} else {\n\t\t\t\tstage = 1;\n\t\t\t\tbreak;\n\t\t\t}\n\t\t}\n\t\tif (update) {\n\t\t\tvar updateValue = update();\n\t\t\tif (updateValue && updateValue.then && !_isSettledPact(updateValue)) {\n\t\t\t\tstage = 2;\n\t\t\t\tbreak;\n\t\t\t}\n\t\t}\n\t}\n\tvar pact = new _Pact();\n\tvar reject = _settle.bind(null, pact, 2);\n\t(stage === 0 ? shouldContinue.then(_resumeAfterTest) : stage === 1 ? result.then(_resumeAfterBody) : updateValue.then(_resumeAfterUpdate)).then(void 0, reject);\n\treturn pact;\n\tfunction _resumeAfterBody(value) {\n\t\tresult = value;\n\t\tdo {\n\t\t\tif (update) {\n\t\t\t\tupdateValue = update();\n\t\t\t\tif (updateValue && updateValue.then && !_isSettledPact(updateValue)) {\n\t\t\t\t\tupdateValue.then(_resumeAfterUpdate).then(void 0, reject);\n\t\t\t\t\treturn;\n\t\t\t\t}\n\t\t\t}\n\t\t\tshouldContinue = test();\n\t\t\tif (!shouldContinue || (_isSettledPact(shouldContinue) && !shouldContinue.v)) {\n\t\t\t\t_settle(pact, 1, result);\n\t\t\t\treturn;\n\t\t\t}\n\t\t\tif (shouldContinue.then) {\n\t\t\t\tshouldContinue.then(_resumeAfterTest).then(void 0, reject);\n\t\t\t\treturn;\n\t\t\t}\n\t\t\tresult = body();\n\t\t\tif (_isSettledPact(result)) {\n\t\t\t\tresult = result.v;\n\t\t\t}\n\t\t} while (!result || !result.then);\n\t\tresult.then(_resumeAfterBody).then(void 0, reject);\n\t}\n\tfunction _resumeAfterTest(shouldContinue) {\n\t\tif (shouldContinue) {\n\t\t\tresult = body();\n\t\t\tif (result && result.then) {\n\t\t\t\tresult.then(_resumeAfterBody).then(void 0, reject);\n\t\t\t} else {\n\t\t\t\t_resumeAfterBody(result);\n\t\t\t}\n\t\t} else {\n\t\t\t_settle(pact, 1, result);\n\t\t}\n\t}\n\tfunction _resumeAfterUpdate() {\n\t\tif (shouldContinue = test()) {\n\t\t\tif (shouldContinue.then) {\n\t\t\t\tshouldContinue.then(_resumeAfterTest).then(void 0, reject);\n\t\t\t} else {\n\t\t\t\t_resumeAfterTest(shouldContinue);\n\t\t\t}\n\t\t} else {\n\t\t\t_settle(pact, 1, result);\n\t\t}\n\t}\n}\n\n// Asynchronously implement a do ... while loop\nexport function _do(body, test) {\n\tvar awaitBody;\n\tdo {\n\t\tvar result = body();\n\t\tif (result && result.then) {\n\t\t\tif (_isSettledPact(result)) {\n\t\t\t\tresult = result.v;\n\t\t\t} else {\n\t\t\t\tawaitBody = true;\n\t\t\t\tbreak;\n\t\t\t}\n\t\t}\n\t\tvar shouldContinue = test();\n\t\tif (_isSettledPact(shouldContinue)) {\n\t\t\tshouldContinue = shouldContinue.v;\n\t\t}\n\t\tif (!shouldContinue) {\n\t\t\treturn result;\n\t\t}\n\t} while (!shouldContinue.then);\n\tconst pact = new _Pact();\n\tconst reject = _settle.bind(null, pact, 2);\n\t(awaitBody ? result.then(_resumeAfterBody) : shouldContinue.then(_resumeAfterTest)).then(void 0, reject);\n\treturn pact;\n\tfunction _resumeAfterBody(value) {\n\t\tresult = value;\n\t\tfor (;;) {\n\t\t\tshouldContinue = test();\n\t\t\tif (_isSettledPact(shouldContinue)) {\n\t\t\t\tshouldContinue = shouldContinue.v;\n\t\t\t}\n\t\t\tif (!shouldContinue) {\n\t\t\t\tbreak;\n\t\t\t}\n\t\t\tif (shouldContinue.then) {\n\t\t\t\tshouldContinue.then(_resumeAfterTest).then(void 0, reject);\n\t\t\t\treturn;\n\t\t\t}\n\t\t\tresult = body();\n\t\t\tif (result && result.then) {\n\t\t\t\tif (_isSettledPact(result)) {\n\t\t\t\t\tresult = result.v;\n\t\t\t\t} else {\n\t\t\t\t\tresult.then(_resumeAfterBody).then(void 0, reject);\n\t\t\t\t\treturn;\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t\t_settle(pact, 1, result);\n\t}\n\tfunction _resumeAfterTest(shouldContinue) {\n\t\tif (shouldContinue) {\n\t\t\tdo {\n\t\t\t\tresult = body();\n\t\t\t\tif (result && result.then) {\n\t\t\t\t\tif (_isSettledPact(result)) {\n\t\t\t\t\t\tresult = result.v;\n\t\t\t\t\t} else {\n\t\t\t\t\t\tresult.then(_resumeAfterBody).then(void 0, reject);\n\t\t\t\t\t\treturn;\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tshouldContinue = test();\n\t\t\t\tif (_isSettledPact(shouldContinue)) {\n\t\t\t\t\tshouldContinue = shouldContinue.v;\n\t\t\t\t}\n\t\t\t\tif (!shouldContinue) {\n\t\t\t\t\t_settle(pact, 1, result);\n\t\t\t\t\treturn;\n\t\t\t\t}\n\t\t\t} while (!shouldContinue.then);\n\t\t\tshouldContinue.then(_resumeAfterTest).then(void 0, reject);\n\t\t} else {\n\t\t\t_settle(pact, 1, result);\n\t\t}\n\t}\n}\n\n// Asynchronously implement a switch statement\nexport function _switch(discriminant, cases) {\n\tvar dispatchIndex = -1;\n\tvar awaitBody;\n\touter: {\n\t\tfor (var i = 0; i < cases.length; i++) {\n\t\t\tvar test = cases[i][0];\n\t\t\tif (test) {\n\t\t\t\tvar testValue = test();\n\t\t\t\tif (testValue && testValue.then) {\n\t\t\t\t\tbreak outer;\n\t\t\t\t}\n\t\t\t\tif (testValue === discriminant) {\n\t\t\t\t\tdispatchIndex = i;\n\t\t\t\t\tbreak;\n\t\t\t\t}\n\t\t\t} else {\n\t\t\t\t// Found the default case, set it as the pending dispatch case\n\t\t\t\tdispatchIndex = i;\n\t\t\t}\n\t\t}\n\t\tif (dispatchIndex !== -1) {\n\t\t\tdo {\n\t\t\t\tvar body = cases[dispatchIndex][1];\n\t\t\t\twhile (!body) {\n\t\t\t\t\tdispatchIndex++;\n\t\t\t\t\tbody = cases[dispatchIndex][1];\n\t\t\t\t}\n\t\t\t\tvar result = body();\n\t\t\t\tif (result && result.then) {\n\t\t\t\t\tawaitBody = true;\n\t\t\t\t\tbreak outer;\n\t\t\t\t}\n\t\t\t\tvar fallthroughCheck = cases[dispatchIndex][2];\n\t\t\t\tdispatchIndex++;\n\t\t\t} while (fallthroughCheck && !fallthroughCheck());\n\t\t\treturn result;\n\t\t}\n\t}\n\tconst pact = new _Pact();\n\tconst reject = _settle.bind(null, pact, 2);\n\t(awaitBody ? result.then(_resumeAfterBody) : testValue.then(_resumeAfterTest)).then(void 0, reject);\n\treturn pact;\n\tfunction _resumeAfterTest(value) {\n\t\tfor (;;) {\n\t\t\tif (value === discriminant) {\n\t\t\t\tdispatchIndex = i;\n\t\t\t\tbreak;\n\t\t\t}\n\t\t\tif (++i === cases.length) {\n\t\t\t\tif (dispatchIndex !== -1) {\n\t\t\t\t\tbreak;\n\t\t\t\t} else {\n\t\t\t\t\t_settle(pact, 1, result);\n\t\t\t\t\treturn;\n\t\t\t\t}\n\t\t\t}\n\t\t\ttest = cases[i][0];\n\t\t\tif (test) {\n\t\t\t\tvalue = test();\n\t\t\t\tif (value && value.then) {\n\t\t\t\t\tvalue.then(_resumeAfterTest).then(void 0, reject);\n\t\t\t\t\treturn;\n\t\t\t\t}\n\t\t\t} else {\n\t\t\t\tdispatchIndex = i;\n\t\t\t}\n\t\t}\n\t\tdo {\n\t\t\tvar body = cases[dispatchIndex][1];\n\t\t\twhile (!body) {\n\t\t\t\tdispatchIndex++;\n\t\t\t\tbody = cases[dispatchIndex][1];\n\t\t\t}\n\t\t\tvar result = body();\n\t\t\tif (result && result.then) {\n\t\t\t\tresult.then(_resumeAfterBody).then(void 0, reject);\n\t\t\t\treturn;\n\t\t\t}\n\t\t\tvar fallthroughCheck = cases[dispatchIndex][2];\n\t\t\tdispatchIndex++;\n\t\t} while (fallthroughCheck && !fallthroughCheck());\n\t\t_settle(pact, 1, result);\n\t}\n\tfunction _resumeAfterBody(result) {\n\t\tfor (;;) {\n\t\t\tvar fallthroughCheck = cases[dispatchIndex][2];\n\t\t\tif (!fallthroughCheck || fallthroughCheck()) {\n\t\t\t\tbreak;\n\t\t\t}\n\t\t\tdispatchIndex++;\n\t\t\tvar body = cases[dispatchIndex][1];\n\t\t\twhile (!body) {\n\t\t\t\tdispatchIndex++;\n\t\t\t\tbody = cases[dispatchIndex][1];\n\t\t\t}\n\t\t\tresult = body();\n\t\t\tif (result && result.then) {\n\t\t\t\tresult.then(_resumeAfterBody).then(void 0, reject);\n\t\t\t\treturn;\n\t\t\t}\n\t\t}\n\t\t_settle(pact, 1, result);\n\t}\n}\n\n// Asynchronously call a function and pass the result to explicitly passed continuations\nexport function _call(body, then, direct) {\n\tif (direct) {\n\t\treturn then ? then(body()) : body();\n\t}\n\ttry {\n\t\tvar result = Promise.resolve(body());\n\t\treturn then ? result.then(then) : result;\n\t} catch (e) {\n\t\treturn Promise.reject(e);\n\t}\n}\n\n// Asynchronously call a function and swallow the result\nexport function _callIgnored(body, direct) {\n\treturn _call(body, _empty, direct);\n}\n\n// Asynchronously call a function and pass the result to explicitly passed continuations\nexport function _invoke(body, then) {\n\tvar result = body();\n\tif (result && result.then) {\n\t\treturn result.then(then);\n\t}\n\treturn then(result);\n}\n\n// Asynchronously call a function and swallow the result\nexport function _invokeIgnored(body) {\n\tvar result = body();\n\tif (result && result.then) {\n\t\treturn result.then(_empty);\n\t}\n}\n\n// Asynchronously call a function and send errors to recovery continuation\nexport function _catch(body, recover) {\n\ttry {\n\t\tvar result = body();\n\t} catch(e) {\n\t\treturn recover(e);\n\t}\n\tif (result && result.then) {\n\t\treturn result.then(void 0, recover);\n\t}\n\treturn result;\n}\n\n// Asynchronously await a promise and pass the result to a finally continuation\nexport function _finallyRethrows(body, finalizer) {\n\ttry {\n\t\tvar result = body();\n\t} catch (e) {\n\t\treturn finalizer(true, e);\n\t}\n\tif (result && result.then) {\n\t\treturn result.then(finalizer.bind(null, false), finalizer.bind(null, true));\n\t}\n\treturn finalizer(false, result);\n}\n\n// Asynchronously await a promise and invoke a finally continuation that always overrides the result\nexport function _finally(body, finalizer) {\n\ttry {\n\t\tvar result = body();\n\t} catch (e) {\n\t\treturn finalizer();\n\t}\n\tif (result && result.then) {\n\t\treturn result.then(finalizer, finalizer);\n\t}\n\treturn finalizer();\n}\n\n// Rethrow or return a value from a finally continuation\nexport function _rethrow(thrown, value) {\n\tif (thrown)\n\t\tthrow value;\n\treturn value;\n}\n\n// Empty function to implement break and other control flow that ignores asynchronous results\nexport function _empty() {\n}\n\n// Sentinel value for early returns in generators \nexport const _earlyReturn = /*#__PURE__*/ {};\n\n// Asynchronously call a function and send errors to recovery continuation, skipping early returns\nexport function _catchInGenerator(body, recover) {\n\treturn _catch(body, function(e) {\n\t\tif (e === _earlyReturn) {\n\t\t\tthrow e;\n\t\t}\n\t\treturn recover(e);\n\t});\n}\n\n// Asynchronous generator class; accepts the entrypoint of the generator, to which it passes itself when the generator should start\nexport const _AsyncGenerator = /*#__PURE__*/(function() {\n\tfunction _AsyncGenerator(entry) {\n\t\tthis._entry = entry;\n\t\tthis._pact = null;\n\t\tthis._resolve = null;\n\t\tthis._return = null;\n\t\tthis._promise = null;\n\t}\n\n\tfunction _wrapReturnedValue(value) {\n\t\treturn { value: value, done: true };\n\t}\n\tfunction _wrapYieldedValue(value) {\n\t\treturn { value: value, done: false };\n\t}\n\n\t_AsyncGenerator.prototype._yield = function(value) {\n\t\t// Yield the value to the pending next call\n\t\tthis._resolve(value && value.then ? value.then(_wrapYieldedValue) : _wrapYieldedValue(value));\n\t\t// Return a pact for an upcoming next/return/throw call\n\t\treturn this._pact = new _Pact();\n\t};\n\t_AsyncGenerator.prototype.next = function(value) {\n\t\t// Advance the generator, starting it if it has yet to be started\n\t\tconst _this = this;\n\t\treturn _this._promise = new Promise(function (resolve) {\n\t\t\tconst _pact = _this._pact;\n\t\t\tif (_pact === null) {\n\t\t\t\tconst _entry = _this._entry;\n\t\t\t\tif (_entry === null) {\n\t\t\t\t\t// Generator is started, but not awaiting a yield expression\n\t\t\t\t\t// Abandon the next call!\n\t\t\t\t\treturn resolve(_this._promise);\n\t\t\t\t}\n\t\t\t\t// Start the generator\n\t\t\t\t_this._entry = null;\n\t\t\t\t_this._resolve = resolve;\n\t\t\t\tfunction returnValue(value) {\n\t\t\t\t\t_this._resolve(value && value.then ? value.then(_wrapReturnedValue) : _wrapReturnedValue(value));\n\t\t\t\t\t_this._pact = null;\n\t\t\t\t\t_this._resolve = null;\n\t\t\t\t}\n\t\t\t\tvar result = _entry(_this);\n\t\t\t\tif (result && result.then) {\n\t\t\t\t\tresult.then(returnValue, function(error) {\n\t\t\t\t\t\tif (error === _earlyReturn) {\n\t\t\t\t\t\t\treturnValue(_this._return);\n\t\t\t\t\t\t} else {\n\t\t\t\t\t\t\tconst pact = new _Pact();\n\t\t\t\t\t\t\t_this._resolve(pact);\n\t\t\t\t\t\t\t_this._pact = null;\n\t\t\t\t\t\t\t_this._resolve = null;\n\t\t\t\t\t\t\t_resolve(pact, 2, error);\n\t\t\t\t\t\t}\n\t\t\t\t\t});\n\t\t\t\t} else {\n\t\t\t\t\treturnValue(result);\n\t\t\t\t}\n\t\t\t} else {\n\t\t\t\t// Generator is started and a yield expression is pending, settle it\n\t\t\t\t_this._pact = null;\n\t\t\t\t_this._resolve = resolve;\n\t\t\t\t_settle(_pact, 1, value);\n\t\t\t}\n\t\t});\n\t};\n\t_AsyncGenerator.prototype.return = function(value) {\n\t\t// Early return from the generator if started, otherwise abandons the generator\n\t\tconst _this = this;\n\t\treturn _this._promise = new Promise(function (resolve) {\n\t\t\tconst _pact = _this._pact;\n\t\t\tif (_pact === null) {\n\t\t\t\tif (_this._entry === null) {\n\t\t\t\t\t// Generator is started, but not awaiting a yield expression\n\t\t\t\t\t// Abandon the return call!\n\t\t\t\t\treturn resolve(_this._promise);\n\t\t\t\t}\n\t\t\t\t// Generator is not started, abandon it and return the specified value\n\t\t\t\t_this._entry = null;\n\t\t\t\treturn resolve(value && value.then ? value.then(_wrapReturnedValue) : _wrapReturnedValue(value));\n\t\t\t}\n\t\t\t// Settle the yield expression with a rejected \"early return\" value\n\t\t\t_this._return = value;\n\t\t\t_this._resolve = resolve;\n\t\t\t_this._pact = null;\n\t\t\t_settle(_pact, 2, _earlyReturn);\n\t\t});\n\t};\n\t_AsyncGenerator.prototype.throw = function(error) {\n\t\t// Inject an exception into the pending yield expression\n\t\tconst _this = this;\n\t\treturn _this._promise = new Promise(function (resolve, reject) {\n\t\t\tconst _pact = _this._pact;\n\t\t\tif (_pact === null) {\n\t\t\t\tif (_this._entry === null) {\n\t\t\t\t\t// Generator is started, but not awaiting a yield expression\n\t\t\t\t\t// Abandon the throw call!\n\t\t\t\t\treturn resolve(_this._promise);\n\t\t\t\t}\n\t\t\t\t// Generator is not started, abandon it and return a rejected Promise containing the error\n\t\t\t\t_this._entry = null;\n\t\t\t\treturn reject(error);\n\t\t\t}\n\t\t\t// Settle the yield expression with the value as a rejection\n\t\t\t_this._resolve = resolve;\n\t\t\t_this._pact = null;\n\t\t\t_settle(_pact, 2, error);\n\t\t});\n\t};\n\n\t_AsyncGenerator.prototype[_asyncIteratorSymbol] = function() {\n\t\treturn this;\n\t};\n\t\n\treturn _AsyncGenerator;\n})();\n","import * as tf from '@tensorflow/tfjs';\nimport { Featurizer } from '../featurizers';\nimport { LSTM, Story, Metrics } from '../utils';\n\ninterface SampleData {\n    targets: tf.Tensor1D,\n    predictions: tf.Tensor1D,\n    loss: number,\n    isFailing: boolean\n}\n\ntype TrainingCallback = (metrics: Metrics) => void;\n\n/**\n * Parameters for HCN constructor.\n */\ninterface HCNConstructorArgs {\n    /**\n     * The list of actions the model can take.\n     * (keeping the order the same is important for pretrained models)\n     */\n    actions: string[];\n\n    /**\n     * The list of featurizers the model uses.\n     * (keeping the order the same is important for pretrained models)\n     */\n    featurizers: Featurizer[];\n\n    /**\n     * The output size of the LSTM cell.\n     * Default is set to 32 units.\n     */\n    hiddenSize?: number;\n\n    /**\n     * The optimization algorithm used for training.\n     * By default, Adam with a learning rate of 0.01 is used.\n     */\n    optimizer?: tf.Optimizer;\n\n    /**\n     * The percentage of units to dropout between the LSTM cell layer and the dense.\n     * Useful for regularizing the model. It's disabled by default (value = 0).\n     */\n    dropout?: number;\n}\n\n/**\n * Parameters for HCN train method.\n */\ninterface HCNTrainArgs {\n    /**\n     * Training stories to learn from.\n     */\n    stories: Story[];\n\n    /**\n     * Number of times the model will be passed the whole set of training stories during training.\n     * Default is set to 12 epochs.\n     */\n    nEpochs?: number;\n\n    /**\n     * After each epoch, this callback function will be executed with the metrics collected\n     * during the epoch.\n     */\n    onEpochEnd?: TrainingCallback;\n}\n\n/**\n * An implementation of Hybrid Code Networks(*) dialog manager.\n *\n * (*): Williams, Asadi, Zweig - 2017.\n *      Hybrid Code Networks: practical and efﬁcient end-to-end dialog control with supervised\n *      and reinforcement learning.\n */\nexport class HCN {\n    private actions: string[];\n    private featurizers: Featurizer[];\n    private optimizer: tf.Optimizer;\n\n    private inputSize: number;\n    private hiddenSize: number;\n    private outputSize: number;\n\n    private lstm: LSTM;\n    private lstmH: tf.Tensor2D;\n    private lstmC: tf.Tensor2D;\n    private lstmDropout: number;\n\n    /**\n     * Defines the model.\n     * To fully initialize the model, run the async init() method.\n     */\n    constructor({\n        actions,\n        featurizers,\n        hiddenSize = 32,\n        optimizer = tf.train.adam(0.01),\n        dropout = 0\n    }: HCNConstructorArgs) {\n        this.actions = actions;\n        this.featurizers = featurizers;\n        this.optimizer = optimizer;\n\n        this.hiddenSize = hiddenSize;\n        this.outputSize = actions.length;\n\n        this.lstmDropout = dropout;\n    }\n\n    /**\n     * Initialize the model and its featurizers.\n     */\n    async init() {\n        // Initialize asynchronously all featurizers.\n        await Promise.all(\n            this.featurizers.map((featurizer) => featurizer.init(this.actions))\n        );\n\n        // The model input size is the sum of the sizes of features vectors.\n        this.inputSize = this.featurizers\n            .map((featurizer) => featurizer.size)\n            .reduce((acc, size) => acc + size, 1);\n\n        this.lstm = new LSTM(this.inputSize, this.hiddenSize, this.outputSize, this.lstmDropout);\n\n        this.resetDialog();\n    }\n\n    /**\n     * Resets the state of the model and its featurizers.\n     */\n    resetDialog() {\n        this.featurizers.forEach((featurizer) => featurizer.resetDialog());\n        ({ c: this.lstmC, h: this.lstmH } = this.lstm.initLSTM());\n    }\n\n    /**\n     * Get the data returned from every featurizer's handleQuery method.\n     */\n    private async handleQuery(query: string): Promise<any[]> {\n        return Promise.all(\n            this.featurizers.map((featurizer) => featurizer.handleQuery(query))\n        );\n    }\n\n    /**\n     * Get the embedding vector resulted from every featurizers.\n     */\n    private getOptimizableFeatures(features: tf.Tensor[]): tf.Tensor1D {\n        return tf.tidy(() => {\n            const embeddings = this.featurizers.map(\n                (featurizer, idx) => featurizer.getOptimizableFeatures(features[idx])\n            );\n\n            // Add a zero to make tf.concat work consistently even with only one featurizer.\n            embeddings.push(tf.zeros([1]));\n\n            return <tf.Tensor1D> tf.concat(embeddings);\n        });\n    }\n\n    /**\n     * Inform every featurizers of the taken action.\n     */\n    private handleAction(action: string) {\n        this.featurizers.map((featurizer) => featurizer.handleAction(action));\n    }\n\n    /**\n     * Get the final action mask resulted from every featurizers.\n     */\n    private getActionMask(): tf.Tensor1D {\n        return tf.tidy(() => this.featurizers\n            // Get action mask and convert them to tensors.\n            .map((featurizer) => <tf.Tensor1D> tf.tensor(\n                featurizer.getActionMask(),\n                undefined, 'float32'\n            ))\n            // Compute the product of every masks.\n            .reduce((acc, mask) => tf.mul(acc, mask), tf.ones([this.actions.length])));\n    }\n\n    /**\n     * Trains the model on a single training story.\n     */\n    private async fitStory(story: Story): Promise<SampleData> {\n        this.resetDialog();\n\n        // 1. Prepare the input data.\n        const inputs: any[][] = [];\n        const masks: tf.Tensor1D[] = [];\n        const targets: tf.Tensor1D[] = [];\n\n        // For each story's state...\n        for (let stateIdx = 0; stateIdx < story.length; stateIdx += 1) {\n            const state = story[stateIdx];\n\n            // The query must be featurized before moving to the next state.\n            // eslint-disable-next-line no-await-in-loop\n            inputs.push(await this.handleQuery(state.query));\n\n            masks.push(this.getActionMask());\n\n            targets.push(\n                <tf.Tensor1D> tf.oneHot(\n                    this.actions.indexOf(state.action),\n                    this.outputSize\n                )\n            );\n\n            this.handleAction(state.action);\n        }\n\n        // 2. Fit the sequence.\n        let data: SampleData;\n\n        this.optimizer.minimize(() => {\n            let { c, h } = this.lstm.initLSTM(false);\n\n            // Make a prediction for each step of the input sequence.\n            const predictions = inputs.map((features, idx) => {\n                const statePred = this.lstm.predict(\n                    <tf.Tensor1D> this.getOptimizableFeatures(features),\n                    <tf.Tensor2D> c,\n                    <tf.Tensor2D> h,\n                    <tf.Tensor1D> masks[idx]\n                );\n\n                c = statePred.nc;\n                h = statePred.nh;\n\n                return statePred.y;\n            });\n\n            const targetsMatrix = tf.stack(targets);\n            const predictionsMatrix = tf.stack(predictions);\n\n            // Compare the predicted sequence with the target.\n            const lossScalar = <tf.Scalar> tf.metrics.categoricalCrossentropy(\n                targetsMatrix, predictionsMatrix\n            ).mean();\n\n            // Store the necessary data to build metrics.\n            data = {\n                targets: tf.keep(targetsMatrix.argMax(1)),\n                predictions: tf.keep(predictionsMatrix.argMax(1)),\n                loss: <number> lossScalar.arraySync(),\n                isFailing: tf.metrics\n                    .categoricalAccuracy(targetsMatrix, predictionsMatrix)\n                    .mean()\n                    .arraySync() < 0.999\n            };\n\n            // Return the loss to the optimizer to update the model.\n            return lossScalar;\n        });\n\n        // BUG: two tensors leak in the memory at each loop :/\n        tf.dispose([inputs, targets]);\n\n        return data;\n    }\n\n\n    /**\n     * Trains the model using the training stories.\n     *\n     * @returns Metrics collected from the last epoch (that correspond to the trained model).\n     */\n    async train({ stories, nEpochs = 12, onEpochEnd = undefined }: HCNTrainArgs): Promise<Metrics> {\n        let epochMetrics: Metrics;\n\n        // For each epoch...\n        for (let epoch = 0; epoch < nEpochs; epoch += 1) {\n            const allTargets: tf.Tensor1D[] = [];\n            const allPredictions: tf.Tensor1D[] = [];\n            const allLosses: number[] = [];\n            const failingSamples: number[] = [];\n\n            // For each training story...\n            for (let storyIdx = 0; storyIdx < stories.length; storyIdx += 1) {\n                // (Each story must be fitted sequentially)\n                // eslint-disable-next-line no-await-in-loop\n                const storyData = await this.fitStory(stories[storyIdx]);\n\n                allTargets.push(storyData.targets);\n                allPredictions.push(storyData.predictions);\n                allLosses.push(storyData.loss);\n\n                if (storyData.isFailing) {\n                    failingSamples.push(storyIdx);\n                }\n            }\n\n            // Build the metrics.\n            const confusionMatrix = tf.tidy(() => tf.math.confusionMatrix(\n                tf.concat(allTargets),\n                tf.concat(allPredictions),\n                this.outputSize\n            ));\n\n            const truePredictions = tf.tidy(() => confusionMatrix\n                .mul(tf.eye(...confusionMatrix.shape))\n                .sum(0));\n\n            epochMetrics = {\n                epoch,\n                failingSamples,\n\n                accuracy: <number> tf.tidy(() => (\n                    truePredictions.sum().div(confusionMatrix.sum()).arraySync()\n                )),\n\n                recall: <number> tf.tidy(() => (\n                    truePredictions.div(confusionMatrix.sum(1)).mean().arraySync()\n                )),\n\n                precision: <number> tf.tidy(() => (\n                    truePredictions.div(confusionMatrix.sum(0)).mean().arraySync()\n                )),\n\n                loss: allLosses.reduce((a, b) => a + b) / allLosses.length\n            };\n\n            // Clear the tensors.\n            tf.dispose(allTargets);\n            tf.dispose(allPredictions);\n            tf.dispose([truePredictions, confusionMatrix]);\n\n            if (onEpochEnd !== undefined) {\n                onEpochEnd(epochMetrics);\n            }\n        }\n\n        this.resetDialog();\n        return epochMetrics;\n    }\n\n    /**\n     * Predict an action resulting from the given query.\n     *\n     * @param query The given query from the user.\n     * @param temperature Temperature of the model softmax, used to calibrate confidence estimation.\n     * @returns The predicted action from the model and its confidence.\n     */\n    async predict(query: string, temperature: number = 1):\n        Promise<{action: string, confidence: number}> {\n        // At inference, dropout is disabled\n        this.lstm.dropout = 0;\n\n        const features = this.getOptimizableFeatures(await this.handleQuery(query));\n        const masks = this.getActionMask();\n\n        const prediction = this.lstm.predict(features, this.lstmC, this.lstmH, masks, temperature);\n\n        // Update lstm internal state\n        tf.dispose([this.lstmC, this.lstmH]);\n        this.lstmC = prediction.nc.clone();\n        this.lstmH = prediction.nh.clone();\n\n        const actionIdx = <number> tf.tidy(() => prediction.y.argMax().arraySync());\n        const confidence = <number> tf.tidy(() => prediction.y.arraySync()[actionIdx]);\n\n        // Clear the memory\n        tf.dispose([features, masks]);\n        tf.dispose(prediction);\n\n        // Retablish dropout (just in case)\n        this.lstm.dropout = this.lstmDropout;\n\n        this.handleAction(this.actions[actionIdx]);\n\n        return { action: this.actions[actionIdx], confidence };\n    }\n\n    /**\n     * Evaluate the model using stories.\n     * @param stories Validation stories to evaluate the model.\n     * @param temperature Temperature of the model softmax, used to calibrate confidence estimation.\n     * @returns Validation metrics based on the results from the stories.\n     */\n    async score(stories: Story[], temperature: number = 1): Promise<Metrics> {\n        const targets: number[] = [];\n        const predictions: number[] = [];\n        const confidences: number[] = [];\n        const failingSamples: number[] = [];\n\n        // For each stories and states, make predictions.\n        for (let storyIdx = 0; storyIdx < stories.length; storyIdx += 1) {\n            this.resetDialog();\n\n            for (let stateIdx = 0; stateIdx < stories[storyIdx].length; stateIdx += 1) {\n                const state = stories[storyIdx][stateIdx];\n\n                // eslint-disable-next-line no-await-in-loop\n                const { action, confidence } = await this.predict(state.query, temperature);\n\n                targets.push(this.actions.indexOf(state.action));\n                predictions.push(this.actions.indexOf(action));\n                confidences.push(confidence);\n\n                if (action !== state.action && !failingSamples.includes(storyIdx)) {\n                    failingSamples.push(storyIdx);\n                }\n            }\n        }\n\n        // Build a confusion matrix out of the prediction and build the metrics.\n        const confusionMatrix = tf.tidy(() => tf.math.confusionMatrix(\n            tf.tensor(targets), tf.tensor(predictions), this.outputSize\n        ));\n\n        const truePredictions = tf.tidy(() => confusionMatrix\n            .mul(tf.eye(...confusionMatrix.shape))\n            .sum(0));\n\n        const metrics: Metrics = {\n            failingSamples,\n\n            accuracy: <number> tf.tidy(() => (\n                truePredictions.sum().div(confusionMatrix.sum()).arraySync()\n            )),\n\n            recall: <number> tf.tidy(() => (\n                truePredictions.div(confusionMatrix.sum(1)).mean().arraySync()\n            )),\n\n            precision: <number> tf.tidy(() => (\n                truePredictions.div(confusionMatrix.sum(0)).mean().arraySync()\n            )),\n\n            averageConfidence: confidences.reduce((a, b) => a + b) / confidences.length\n        };\n\n        tf.dispose([truePredictions, confusionMatrix]);\n\n        this.resetDialog();\n        return metrics;\n    }\n\n    /**\n     * Load the models parameters from a JSON formatted string.\n     */\n    load(json: string) {\n        const parameters = JSON.parse(json);\n\n        this.featurizers.forEach((featurizer) => {\n            featurizer.load(parameters[featurizer.id]);\n        });\n\n        this.lstm.load(parameters.lstm);\n\n        this.resetDialog();\n    }\n\n    /**\n     * Export the models parameters in a JSON format.\n     */\n    async export(): Promise<string> {\n        const parameters = { lstm: await this.lstm.export() };\n\n        for (let idx = 0; idx < this.featurizers.length; idx += 1) {\n            const featurizer = this.featurizers[idx];\n\n            // eslint-disable-next-line no-await-in-loop\n            parameters[featurizer.id] = await featurizer.export();\n        }\n\n        return JSON.stringify(parameters);\n    }\n}\n","import * as tf from '@tensorflow/tfjs';\nimport { Featurizer } from '../featurizers';\nimport { fuzzyMatch, hashcode } from '../utils';\n\ntype Categories = {[category: string]: string[]};\ntype Value = { category: string, extract: string, score: number };\n\nexport class CategoricalSlot extends Featurizer {\n    readonly id: string;\n    readonly size: number;\n\n    private categoryNames: string[];\n    private categories: Categories;\n\n    private dependantActions: any[];\n    private inverselyDependantActions: any[];\n\n    private threshold: number;\n    private value: Value;\n\n    constructor(categories: Categories, dependantActions: any[] = [],\n        inverselyDependantActions: any[] = [], threshold: number = 0.75) {\n        super();\n\n        this.categoryNames = Object.keys(categories);\n        this.categories = categories;\n\n        this.id = `Categorical Slot (${hashcode(JSON.stringify(this.categoryNames))})`;\n\n        this.dependantActions = dependantActions;\n        this.inverselyDependantActions = inverselyDependantActions;\n\n        this.threshold = threshold;\n\n        this.size = 2 * this.categoryNames.length;\n    }\n\n    async init(actions: any[]) {\n        await super.init(actions);\n        this.resetDialog();\n    }\n\n    private featurizeValue(value: Value): tf.Tensor1D {\n        const categoryNames = Object.keys(this.categories);\n\n        return <tf.Tensor1D> tf.oneHot(\n            categoryNames.indexOf(value.category),\n            categoryNames.length\n        );\n    }\n\n    async handleQuery(query: string): Promise<tf.Tensor1D> {\n        let bestValue: Value = { category: undefined, extract: undefined, score: 0 };\n\n        Object.entries(this.categories).forEach(([category, keywords]) => {\n            // Find the best match of one category.\n            const match = keywords\n                .map((keyword) => fuzzyMatch(query.toLowerCase(), keyword.toLowerCase()))\n                .filter((m) => m.score >= this.threshold)\n                .reduce(\n                    (hm, m) => (hm.score > m.score ? hm : m),\n                    { extract: undefined, score: 0 }\n                );\n\n            // If this match is the best of every categories.\n            if (match.score > bestValue.score) {\n                bestValue = { category, ...match };\n            }\n        });\n\n        const features = tf.tidy(() => (\n            tf.concat([\n                this.featurizeValue(bestValue),\n                this.featurizeValue(this.value)\n            ])\n        ));\n\n        if (bestValue.category !== undefined) {\n            this.value = bestValue;\n        }\n\n        return features;\n    }\n\n    getActionMask(): boolean[] {\n        return this.actions.map((action) => {\n            const u = this.value.extract === undefined;\n            const d = this.dependantActions.includes(action);\n            const i = this.inverselyDependantActions.includes(action);\n\n            return (u && (i || !d)) || (!u && !i);\n        });\n    }\n\n    resetDialog() {\n        this.value = { category: undefined, extract: undefined, score: 0 };\n    }\n\n    getValue(): Value {\n        return this.value;\n    }\n}\n","import { Story, State } from '../utils';\n\n/**\n * Parse a source string formatted according the Wisty Training Story syntax.\n * Usually, this source string is extracted using fetch or from a file.\n */\nexport function parseStories(source: string): Story[] {\n    const stories: Story[] = [];\n    let story: Story = [];\n    let inputAnswered = true;\n\n    source.split('\\n').forEach((line) => {\n        const newStory = /^## *([^#].*)?$/gm.exec(line);\n        const newInput = /^> *(.*)$/gm.exec(line);\n        const newAction = /^- *(\\w*)$/gm.exec(line);\n\n        /*\n            New story\n            ## Story name\n        */\n        if (newStory != null && story.length > 0) {\n            story.push(<State> { query: '', action: 'LUS' });\n            stories.push(story); // Push previous story.\n            story = [];\n\n        /*\n            New user input\n            > user input\n        */\n        } else if (newInput != null) {\n            // Add a LUS action to mark the end of the previous turn.\n            if (story.length > 0) story.push(<State> { query: '', action: 'LUS' });\n\n            story.push(<State> { query: newInput[1], action: undefined });\n            inputAnswered = false;\n\n        /*\n            New bot action\n            (> user input)\n            (- action_name)\n            - action_name\n        */\n        } else if (newAction != null && inputAnswered) {\n            story.push(<State> { query: '', action: newAction[1] });\n\n        /*\n            New bot action (first answer)\n            (> user input)\n            - action_name\n        */\n        } else if (newAction != null && !inputAnswered) {\n            // eslint-disable-next-line prefer-destructuring\n            story[story.length - 1].action = newAction[1];\n            inputAnswered = true;\n        }\n    });\n\n    // Finalize the last story\n    if (story.length > 0) {\n        story.push(<State> { query: '', action: 'LUS' });\n        stories.push(story);\n    }\n\n    return stories;\n}\n","import { Story } from '../utils';\n\n/**\n * Split a list of stories into random train and test subsets.\n *\n * @param stories A list of stories.\n * @param testSize The proportion of stories to put in the test subset.\n */\nexport function trainTestSplit(stories: Story[], testSize: number):\n    {train: Story[], test: Story[]} {\n    const test: Story[] = [];\n\n    for (let i = 0; i / stories.length < testSize; i += 1) {\n        test.push(...stories.splice(\n            Math.floor(Math.random() * stories.length), 1\n        ));\n    }\n\n    return { train: stories, test };\n}\n"],"names":["Featurizer","init","actions","this","getOptimizableFeatures","data","handleAction","action","getActionMask","map","resetDialog","load","parameters","levenshteinDistance","s1","s2","d","Array","from","length","fill","i","j","Math","min","max","fuzzyMatch","text","substring","bestMatch","extract","undefined","score","aMatch","hashcode","input","hash","charCodeAt","initializeVariable","shape","scalar","tf","initializer","heNormal","zeros","randomNormal","Error","randomTensor","apply","asScalar","variable","LSTM","inputSize","hiddenSize","outputSize","dropout","lstmKernel","lstmBias","lstmForgetBias","lstmInitH","lstmInitC","denseWeights","denseBias","initLSTM","clone","c","h","predict","x","mask","temperature","_this","nc","nh","y","matMul","add","squeeze","div","softmax","mul","weights","_this2","_this4","array","maskLUS","maskPreviousAction","LUSAction","_this3","size","embeddings","handleQuery","query","_this5","userTalked","indexOf","previousAction","includes","indexes","toLowerCase","split","word","asType","sum","use","encoder","encodeQuery","emptyEncoding","embed","squeezedEmbed","loaderFunction","vectors","JSON","parse","tokens","filter","token","forEach","Object","keys","push","bestToken","lowestDistance","Infinity","vocabToken","distance","embeddingsMatrix","mean","_Pact","prototype","then","onFulfilled","onRejected","result","state","s","callback","_settle","v","e","o","value","pact","bind","observer","_isSettledPact","thenable","_for","test","update","body","stage","shouldContinue","updateValue","reject","_resumeAfterTest","_resumeAfterBody","_resumeAfterUpdate","Symbol","iterator","asyncIterator","featurizers","optimizer","adam","lstmDropout","Promise","all","featurizer","reduce","acc","lstm","lstmC","lstmH","features","idx","_this6","fitStory","story","_this8","minimize","predictions","inputs","statePred","masks","targetsMatrix","targets","predictionsMatrix","lossScalar","categoricalCrossentropy","argMax","loss","arraySync","isFailing","categoricalAccuracy","stateIdx","_push","train","stories","nEpochs","onEpochEnd","epochMetrics","_this10","epoch","confusionMatrix","allTargets","allPredictions","truePredictions","failingSamples","accuracy","recall","precision","allLosses","a","b","storyIdx","storyData","_this12","prediction","actionIdx","confidence","_this14","metrics","averageConfidence","confidences","json","id","_this16","stringify","categories","dependantActions","inverselyDependantActions","threshold","categoryNames","featurizeValue","category","bestValue","entries","match","keyword","m","hm","u","getValue","source","inputAnswered","line","newStory","exec","newInput","newAction","testSize","splice","floor","random"],"mappings":"8VAOsBA,sDAqBZC,cAAKC,cACPC,KAAKD,QAAUA,oBAtBvB,sCA+CIE,uBAAA,SAAuBC,GACnB,OAAqBA,KAOzBC,aAAA,SAAaC,OAQbC,cAAA,WACI,YAAYN,QAAQO,IAAI,yBAO5BC,YAAA,eAMAC,KAAA,SAAKC,yBAOD,uBAAO,iUCvFCC,EAAoBC,EAAYC,GAM5C,IALA,IAAMC,EAAIC,MAAMC,KACZD,MAAMH,EAAGK,OAAS,GAClB,sBAAUF,MAAMF,EAAGI,OAAS,GAAGC,KAAK,KAG/BC,EAAI,EAAGA,GAAKP,EAAGK,OAAQE,GAAK,EACjCL,EAAEK,GAAG,GAAKA,EAGd,IAAK,IAAIC,EAAI,EAAGA,GAAKP,EAAGI,OAAQG,GAAK,EACjCN,EAAE,GAAGM,GAAKA,EAGd,IAAK,IAAIA,EAAI,EAAGA,EAAIP,EAAGI,OAAQG,GAAK,EAChC,IAAK,IAAID,EAAI,EAAGA,EAAIP,EAAGK,OAAQE,GAAK,EAGhCL,EAAEK,EAAI,GAAGC,EAAI,GAAKC,KAAKC,IACnBR,EAAEK,GAAGC,EAAI,GAAK,EACdN,EAAEK,EAAI,GAAGC,GAAK,EACdN,EAAEK,GAAGC,IALiBR,EAAGO,KAAON,EAAGO,GAAM,EAAI,IAUzD,OAAON,EAAEF,EAAGK,QAAQJ,EAAGI,QAAUI,KAAKE,IAAIX,EAAGK,OAAQJ,EAAGI,OAAQ,YC1BpDO,EAAWC,EAAcC,GAGrC,IAFA,IAAIC,EAAmB,CAAEC,aAASC,EAAWC,MAAO,GAE3CX,EAAI,EAAGA,EAAIM,EAAKR,OAAQE,GAAK,EAAG,CACrC,IAAMS,EAAUH,EAAKC,UAAUP,EAAGA,EAAIO,EAAUT,QAE1Cc,EAAS,CACXH,QAAAA,EACAE,MAAO,EAAInB,EAAoBiB,EAASF,IAG5C,GAAqB,IAAjBK,EAAOD,MACP,OAAOC,EAGPA,EAAOD,MAAQH,EAAUG,QACzBH,EAAYI,GAIpB,OAAOJ,WClBKK,EAASC,GAGrB,IAFA,IAAIC,EAAO,EAEFf,EAAI,EAAGA,EAAIc,EAAMhB,OAAQE,GAAK,EAGnCe,GAASA,GAAQ,GAAKA,EAFVD,EAAME,WAAWhB,GAG7Be,GAAQ,EAGZ,OAAOA,WCXKE,EAAmBC,EAAiBC,EAChDvC,GACA,gBAFgDuC,IAAAA,GAAkB,YAClEvC,IAAAA,EAA8B,MACvBwC,EAAQ,WACX,IAAIC,EAEJ,OAAQzC,GACR,IAAK,KACDyC,EAAcD,EAAgBE,SAAS,IACvC,MAEJ,IAAK,QACDD,EAAcD,EAAgBG,QAC9B,MAEJ,IAAK,SACDF,EAAcD,EAAgBI,aAAa,IAC3C,MAEJ,QACI,UAAUC,8EACkE7C,QAIhF,IAAI8C,EAAeL,EAAYM,MAAMT,GAGrC,OAFIC,IAAQO,EAAeA,EAAaE,YAEjCF,EAAaG,iBCxBfC,aAqBT,WAAYC,EAAmBC,EAAoBC,EAAoBC,YAAAA,IAAAA,EAAkB,IACrFpD,KAAKqD,WAAalB,EAAmB,CAACc,EAAYC,EAAyB,EAAbA,IAC9DlD,KAAKsD,SAAWnB,EAAmB,CAAc,EAAbe,IAAiB,EAAO,SAC5DlD,KAAKuD,eAAiBpB,EAAmB,CAAC,IAAI,EAAM,SACpDnC,KAAKwD,UAAYrB,EAAmB,CAAC,EAAGe,IACxClD,KAAKyD,UAAYtB,EAAmB,CAAC,EAAGe,IAExClD,KAAK0D,aAAevB,EAAmB,CAACe,EAAYC,IACpDnD,KAAK2D,UAAYxB,EAAmB,CAACgB,IAAa,EAAO,SAEzDnD,KAAKoD,QAAUA,EA/BvB,2BAuCIQ,SAAA,SAASC,GACL,gBADKA,IAAAA,GAAiB,GACf,CACHC,EAAkBD,EAAQ7D,KAAKyD,UAAUI,QAAU7D,KAAKyD,UACxDM,EAAkBF,EAAQ7D,KAAKwD,UAAUK,QAAU7D,KAAKwD,cAWhEQ,QAAA,SAAQC,EAAgBH,EAAgBC,EAAgBG,EACpDC,cACA,gBADAA,IAAAA,EAAsB,GACf7B,EAAQ,iBAEMA,EACD8B,EAAKb,eACHa,EAAKf,WACLe,EAAKd,SACLhB,EAAS,CAAC2B,IACxBF,EAAGD,GALAO,OAAIC,OASPC,EAAkBjC,EACTgC,EAAIF,EAAKhB,SACjBoB,OAAOJ,EAAKV,cACZe,IAAIL,EAAKT,WACTe,UACAC,IAAIR,GACJS,UACAC,UAAIX,EAAAA,EAAQ,GAKjB,MAAO,CAAEK,EAFTA,EAAIA,EAAEI,IAAIrC,EAAOiC,IAELF,GAAAA,EAAIC,GAAAA,QAOxB9D,KAAA,SAAKsE,cACDxC,EAAQ,WAEJyC,EAAK1B,WAAaf,EAAUwC,EAAQzB,YAAYN,WAChDgC,EAAKzB,SAAWhB,EAAUwC,EAAQxB,UAAUP,WAC5CgC,EAAKxB,eAAiBjB,EAAUwC,EAAQvB,gBAAgBR,WACxDgC,EAAKvB,UAAYlB,EAAUwC,EAAQtB,WAAWT,WAC9CgC,EAAKtB,UAAYnB,EAAUwC,EAAQrB,WAAWV,WAC9CgC,EAAKrB,aAAepB,EAAUwC,EAAQpB,cAAcX,WACpDgC,EAAKpB,UAAYrB,EAAUwC,EAAQnB,WAAWZ,4CAS5B/C,4BAAAgF,EAAK3B,WAAW4B,iDAClBD,EAAK1B,SAAS2B,iDACRD,EAAKzB,eAAe0B,iDACzBD,EAAKxB,UAAUyB,iDACfD,EAAKvB,UAAUwB,iDACZD,EAAKtB,aAAauB,iDACrBD,EAAKrB,UAAUsB,0BAGpC,MAVgB,CACZ5B,aACAC,WACAC,iBACAC,YACAC,YACAC,eACAC,2BA7GZ,kMCyCI,iCAI0B,CAAEuB,SAAS,EAAMC,oBAAoB,EAAMC,UAAW,aAH5EF,QAAAA,oBACAC,mBAAAA,oBACAC,UAAAA,aAAY,eAEZhB,yBAjBU,oBAkBVA,EAAKc,QAAUA,EACfd,EAAKe,mBAAqBA,EAC1Bf,EAAKgB,UAAYA,EAEjBhB,EAAK7D,uBAvBb,2BA0BUT,cAAKC,qDACKD,YAAKC,oBAEjBsF,EAAKC,KAAOvF,EAAQiB,OACpBqE,EAAKE,WAAapD,EAAmB,CAACkD,EAAKC,KAAMD,EAAKC,SA9B9D,sCAiCUE,qBAAYC,aAEVzF,KADJ,uBAAOsC,EAAQ,WAIX,OAHAoD,EAAKC,WAAuB,KAAVF,EAGGnD,EACjB,CAACoD,EAAK3F,QAAQ6F,QAAQF,EAAKG,iBAC3BH,EAAK3F,QAAQiB,WAxC7B,sCA6CIf,uBAAA,SAAuBC,GACnB,OAAqBA,EAAKsE,OAAOxE,KAAKuF,YAAYb,aAGtDvE,aAAA,SAAaC,GAETJ,KAAK6F,eAAiBzF,IAAWJ,KAAKoF,UAAYhF,EAASJ,KAAK6F,kBAGpExF,cAAA,WACI,IAAM6D,cAAa7D,yBAYnB,OATIL,KAAKkF,SAAWlF,KAAK2F,aACrBzB,EAAKlE,KAAKD,QAAQ6F,QAAQ5F,KAAKoF,aAAc,GAI7CpF,KAAKmF,oBAAsBnF,KAAKD,QAAQ+F,SAAS9F,KAAK6F,kBACtD3B,EAAKlE,KAAKD,QAAQ6F,QAAQ5F,KAAK6F,kBAAmB,GAG/C3B,KAGX3D,YAAA,WACIP,KAAK2F,YAAa,EAClB3F,KAAK6F,oBAAiBjE,KAG1BpB,KAAA,SAAKC,GACDT,KAAKuF,WAAajD,EAAQ,kBAAMA,EAAU7B,EAAW8E,YAAYxC,6DAK9B/C,KAAKuF,WAAWN,0BADnD,MAAO,CACHM,gBAjFZ,uCAAsC1F,mBCxBlC,WAAYyF,gBACRlB,yBAJU,eAKVA,EAAKkB,KAAOA,8BAMVE,qBAAYC,aAI0BzF,KAHxC,uBAAOsC,EAAQ,WACX,IAAMyD,EAAUN,EAAMO,cACjBC,MAAM,OACN3F,IAAI,SAAC4F,UAASnE,EAASmE,GAAQb,EAAKC,OAEzC,OAAqBhD,EAAUyD,EAASV,EAAKC,MAAMa,OAAO,WAAWC,IAAI,MAlBrF,uCAAyBvG,mBCDzB,8DACkB,6BAKLuE,OAAO,aANpB,2BAWUtE,cAAKC,qDACKD,YAAKC,2CACIsG,6BAArBhB,EAAKiB,0BAGsBjB,EAAKkB,YAAY,sBAA5ClB,EAAKmB,sBAhBb,sCAsBkBD,qBAAYd,8BACFzF,KAAKsG,QAAQG,MAAM,CAAChB,mBAAlCgB,GACN,IAAMC,EAA8BD,EAAM/B,UAG1C,OAFApC,EAAWmE,GAEJC,IA3Bf,sCAiCUlB,qBAAYC,OAEd,uBAAKA,EACMzF,KAGCuG,YAAYd,GAHbzF,KAAKwG,cAAc3C,SApCtC,uCAAyBhE,6BCgBrB,WAAY8G,EAAuCrB,gBAC/ClB,yBAXU,iBAYVA,EAAKkB,KAAO,EAAIA,EAChBlB,EAAKuC,eAAiBA,WAd9B,2BAiBU7G,cAAKC,qDACKD,YAAKC,2CACesF,EAAKsB,mCAArCtB,EAAKuB,QAAUC,KAAKC,aAnB5B,sCAsBUtB,qBAAYC,aAUUzF,KATxB,uBAAqBsC,EAAQ,WACzB,IAAMyE,EAAStB,EAAMO,cAChBC,MAAM,OACNe,OAAO,SAACC,UAAUA,EAAMjG,OAAS,IAEhCuE,EAA4B,GA4BlC,GA1BAwB,EAAOG,QAAQ,SAACD,GAEZ,GAAIE,OAAOC,KAAK1B,EAAKkB,SAASd,SAASmB,GACnC1B,EAAW8B,KAAK/E,EAAUoD,EAAKkB,QAAQK,SAGpC,CACH,IAAIK,EACAC,EAAyBC,SAE7BL,OAAOC,KAAK1B,EAAKkB,SAASM,QAAQ,SAACO,GAC/B,IAAMC,EAAWhH,EAAoB+G,EAAYR,GAE7CS,EAAWH,IACXD,EAAYG,EACZF,EAAiBG,KAIrBH,EAAiB,IACjBhC,EAAW8B,KAAK/E,EAAUoD,EAAKkB,QAAQU,QAMzB,IAAtB/B,EAAWvE,OACX,OAAOsB,EAAS,CAACoD,EAAKJ,OAG1B,IAAMqC,EAAmBrF,EAASiD,GAElC,OAAOjD,EAAU,CAACqF,EAAiBC,KAAK,GAAID,EAAiBrG,IAAI,QA9D7E,uCAAmCzB,ICX5B,MAAMgI,EAAqB,WACjC,SAASA,KAiCT,OAhCAA,EAAMC,UAAUC,KAAO,SAASC,EAAaC,GAC5C,MAAMC,EAAS,IAAIL,EACbM,EAAQnI,KAAKoI,EACnB,GAAID,EAAO,CACV,MAAME,EAAmB,EAARF,EAAYH,EAAcC,EAC3C,GAAII,EAAU,CACb,IACCC,EAAQJ,EAAQ,EAAGG,EAASrI,KAAKuI,IAChC,MAAOC,GACRF,EAAQJ,EAAQ,EAAGM,GAEpB,OAAON,EAEP,OAAOlI,KAiBT,OAdAA,KAAKyI,EAAI,SAASrE,GACjB,IACC,MAAMsE,EAAQtE,EAAMmE,EACN,EAAVnE,EAAMgE,EACTE,EAAQJ,EAAQ,EAAGF,EAAcA,EAAYU,GAASA,GAC5CT,EACVK,EAAQJ,EAAQ,EAAGD,EAAWS,IAE9BJ,EAAQJ,EAAQ,EAAGQ,GAEnB,MAAOF,GACRF,EAAQJ,EAAQ,EAAGM,KAGdN,GAEDL,EAlC0B,GAsClC,SAAgBS,EAAQK,EAAMR,EAAOO,GACpC,IAAKC,EAAKP,EAAG,CACZ,GAAIM,aAAiBb,EAAO,CAC3B,IAAIa,EAAMN,EAOT,YADAM,EAAMD,EAAIH,EAAQM,KAAK,KAAMD,EAAMR,IALvB,EAARA,IACHA,EAAQO,EAAMN,GAEfM,EAAQA,EAAMH,EAMhB,GAAIG,GAASA,EAAMX,KAElB,YADAW,EAAMX,KAAKO,EAAQM,KAAK,KAAMD,EAAMR,GAAQG,EAAQM,KAAK,KAAMD,EAAM,IAGtEA,EAAKP,EAAID,EACTQ,EAAKJ,EAAIG,EACT,MAAMG,EAAWF,EAAKF,EAClBI,GACHA,EAASF,IAKL,SAASG,EAAeC,GAC9B,OAAOA,aAAoBlB,GAAsB,EAAbkB,EAASX,EA6L9C,SAAgBY,EAAKC,EAAMC,EAAQC,GAElC,IADA,IAAIC,IACK,CACR,IAAIC,EAAiBJ,IAIrB,GAHIH,EAAeO,KAClBA,EAAiBA,EAAed,IAE5Bc,EACJ,OAAOnB,EAER,GAAImB,EAAetB,KAAM,CACxBqB,EAAQ,EACR,MAED,IAAIlB,EAASiB,IACb,GAAIjB,GAAUA,EAAOH,KAAM,CAC1B,IAAIe,EAAeZ,GAEZ,CACNkB,EAAQ,EACR,MAHAlB,EAASA,EAAOE,EAMlB,GAAIc,EAAQ,CACX,IAAII,EAAcJ,IAClB,GAAII,GAAeA,EAAYvB,OAASe,EAAeQ,GAAc,CACpEF,EAAQ,EACR,QAIH,IAAIT,EAAO,IAAId,EACX0B,EAASjB,EAAQM,KAAK,KAAMD,EAAM,GAEtC,OADW,IAAVS,EAAcC,EAAetB,KAAKyB,GAA8B,IAAVJ,EAAclB,EAAOH,KAAK0B,GAAoBH,EAAYvB,KAAK2B,IAAqB3B,UAAK,EAAQwB,GACjJZ,EACP,SAASc,EAAiBf,GACzBR,EAASQ,EACT,EAAG,CACF,GAAIQ,IACHI,EAAcJ,MACKI,EAAYvB,OAASe,EAAeQ,GAEtD,YADAA,EAAYvB,KAAK2B,GAAoB3B,UAAK,EAAQwB,GAKpD,KADAF,EAAiBJ,MACOH,EAAeO,KAAoBA,EAAed,EAEzE,YADAD,EAAQK,EAAM,EAAGT,GAGlB,GAAImB,EAAetB,KAElB,YADAsB,EAAetB,KAAKyB,GAAkBzB,UAAK,EAAQwB,GAIhDT,EADJZ,EAASiB,OAERjB,EAASA,EAAOK,UAERL,IAAWA,EAAOH,MAC5BG,EAAOH,KAAK0B,GAAkB1B,UAAK,EAAQwB,GAE5C,SAASC,EAAiBH,GACrBA,GACHnB,EAASiB,MACKjB,EAAOH,KACpBG,EAAOH,KAAK0B,GAAkB1B,UAAK,EAAQwB,GAE3CE,EAAiBvB,GAGlBI,EAAQK,EAAM,EAAGT,GAGnB,SAASwB,KACJL,EAAiBJ,KAChBI,EAAetB,KAClBsB,EAAetB,KAAKyB,GAAkBzB,UAAK,EAAQwB,GAEnDC,EAAiBH,GAGlBf,EAAQK,EAAM,EAAGT,IA5K2C,oBAAXyB,SAA0BA,OAAOC,WAAaD,OAAOC,SAAWD,OAAO,qBA6DvD,oBAAXA,SAA0BA,OAAOE,gBAAkBF,OAAOE,cAAgBF,OAAO,+DClItI,kBACI5J,IAAAA,QACA+J,IAAAA,gBACA5G,WAAAA,aAAa,SACb6G,UAAAA,aAAYzH,EAAS0H,KAAK,WAC1B5G,QAAAA,aAAU,IAEVpD,KAAKD,QAAUA,EACfC,KAAK8J,YAAcA,EACnB9J,KAAK+J,UAAYA,EAEjB/J,KAAKkD,WAAaA,EAClBlD,KAAKmD,WAAapD,EAAQiB,OAE1BhB,KAAKiK,YAAc7G,EAhC3B,2BAsCUtD,0BAGEE,4BADEkK,QAAQC,IACVpF,EAAK+E,YAAYxJ,IAAI,SAAC8J,UAAeA,EAAWtK,KAAKiF,EAAKhF,6BAI9DgF,EAAK9B,UAAY8B,EAAK+E,YACjBxJ,IAAI,SAAC8J,UAAeA,EAAW9E,OAC/B+E,OAAO,SAACC,EAAKhF,UAASgF,EAAMhF,GAAM,GAEvCP,EAAKwF,KAAO,IAAIvH,EAAK+B,EAAK9B,UAAW8B,EAAK7B,WAAY6B,EAAK5B,WAAY4B,EAAKkF,aAE5ElF,EAAKxE,gBAnDb,sCAyDIA,YAAA,WACIP,KAAK8J,YAAY5C,QAAQ,SAACkD,UAAeA,EAAW7J,sBAChBP,KAAKuK,KAAK3G,WAAxC5D,KAAKwK,QAAR1G,EAAkB9D,KAAKyK,QAAR1G,KAMRyB,qBAAYC,OACtB,OAAOyE,QAAQC,IACXnK,KAAK8J,YAAYxJ,IAAI,SAAC8J,UAAeA,EAAW5E,YAAYC,MAnExE,sCA0EYxF,uBAAA,SAAuByK,cAC3B,OAAOpI,EAAQ,WACX,IAAMiD,EAAaG,EAAKoE,YAAYxJ,IAChC,SAAC8J,EAAYO,UAAQP,EAAWnK,uBAAuByK,EAASC,MAMpE,OAFApF,EAAW8B,KAAK/E,EAAS,CAAC,KAELA,EAAUiD,QAO/BpF,aAAA,SAAaC,GACjBJ,KAAK8J,YAAYxJ,IAAI,SAAC8J,UAAeA,EAAWjK,aAAaC,QAMzDC,cAAA,sBACJ,OAAOiC,EAAQ,kBAAMsI,EAAKd,YAErBxJ,IAAI,SAAC8J,UAA6B9H,EAC/B8H,EAAW/J,qBACXuB,EAAW,aAGdyI,OAAO,SAACC,EAAKpG,UAAS5B,EAAOgI,EAAKpG,IAAO5B,EAAQ,CAACsI,EAAK7K,QAAQiB,eAM1D6J,kBAASC,wBA6BnB,IAAI5K,EA8CJ,OA5CA6K,EAAKhB,UAAUiB,SAAS,iBACLD,EAAKR,KAAK3G,UAAS,GAA5BE,IAAAA,EAAGC,IAAAA,EAGHkH,EAAcC,EAAO5K,IAAI,SAACoK,EAAUC,GACtC,IAAMQ,EAAYJ,EAAKR,KAAKvG,QACV+G,EAAK9K,uBAAuByK,GAC5B5G,EACAC,EACAqH,EAAMT,IAMxB,OAHA7G,EAAIqH,EAAU9G,GACdN,EAAIoH,EAAU7G,GAEP6G,EAAU5G,IAGf8G,EAAgB/I,EAASgJ,GACzBC,EAAoBjJ,EAAS2I,GAG7BO,EAAyBlJ,EAAWmJ,wBACtCJ,EAAeE,GACjB3D,OAcF,OAXA1H,EAAO,CACHoL,QAAShJ,EAAQ+I,EAAcK,OAAO,IACtCT,YAAa3I,EAAQiJ,EAAkBG,OAAO,IAC9CC,KAAeH,EAAWI,YAC1BC,UAAWvJ,EACNwJ,oBAAoBT,EAAeE,GACnC3D,OACAgE,YAAc,MAIhBJ,IAIXlJ,EAAW,CAAC4I,EAAQI,IAEbpL,KA1EPF,KAAA+K,EAAKxK,cAGL,IAAM2K,EAAkB,GAClBE,EAAuB,GACvBE,EAAyB,GAGtBS,EAAW,wBAAGA,EAAWjB,EAAM9J,4BAAQ+K,GAAY,eACxD,IAAM5D,EAAQ2C,EAAMiB,KAIpBb,EAAO7D,4BAAW0D,EAAKvF,YAAY2C,EAAM1C,yBAAzCuG,OAAAd,KAEAE,EAAM/D,KAAK0D,EAAK1K,iBAEhBiL,EAAQjE,KACU/E,EACVyI,EAAKhL,QAAQ6F,QAAQuC,EAAM/H,QAC3B2K,EAAK5H,aAIb4H,EAAK5K,aAAagI,EAAM/H,4DAxIpC,sCAmMU6L,sBAAQC,IAAAA,YAASC,QAAAA,aAAU,SAAIC,WAAAA,kBAAaxK,YAC1CyK,eAiEJ,OADAC,EAAK/L,cACE8L,KApDyBrM,KAVvBuM,EAAQ,wBAAGA,EAAQJ,uBAASI,GAAS,4BAsB1C,IAAMC,EAAkBlK,EAAQ,kBAAMA,EAAQkK,gBAC1ClK,EAAUmK,GACVnK,EAAUoK,GACVJ,EAAKnJ,cAGHwJ,EAAkBrK,EAAQ,kBAAMkK,EACjC3H,IAAIvC,QAAAA,EAAUkK,EAAgBpK,QAC9BgE,IAAI,KAETiG,EAAe,CACXE,MAAAA,EACAK,eAAAA,EAEAC,SAAmBvK,EAAQ,kBACvBqK,EAAgBvG,MAAMzB,IAAI6H,EAAgBpG,OAAOwF,cAGrDkB,OAAiBxK,EAAQ,kBACrBqK,EAAgBhI,IAAI6H,EAAgBpG,IAAI,IAAIwB,OAAOgE,cAGvDmB,UAAoBzK,EAAQ,kBACxBqK,EAAgBhI,IAAI6H,EAAgBpG,IAAI,IAAIwB,OAAOgE,cAGvDD,KAAMqB,EAAU3C,OAAO,SAAC4C,EAAGC,UAAMD,EAAIC,IAAKF,EAAUhM,QAIxDsB,EAAWmK,GACXnK,EAAWoK,GACXpK,EAAW,CAACqK,EAAiBH,SAEV5K,IAAfwK,GACAA,EAAWC,GAxDf,IAAMI,EAA4B,GAC5BC,EAAgC,GAChCM,EAAsB,GACtBJ,EAA2B,GAGxBO,EAAW,wBAAGA,EAAWjB,EAAQlL,4BAAQmM,GAAY,sCAGlCb,EAAKzB,SAASqB,EAAQiB,mBAAxCC,GAENX,EAAWpF,KAAK+F,EAAU9B,SAC1BoB,EAAerF,KAAK+F,EAAUnC,aAC9B+B,EAAU3F,KAAK+F,EAAUzB,MAErByB,EAAUvB,WACVe,EAAevF,KAAK8F,wFAxNxC,sCA+QUnJ,iBAAQyB,EAAetB,YAAAA,IAAAA,EAAsB,aAG/CnE,KAAAqN,EAAK9C,KAAKnH,QAAU,QAEHiK,EAAKpN,8CAA6BoN,EAAK7H,YAAYC,qBAApE,IAAMiF,cACAU,EAAQiC,EAAKhN,gBAEbiN,EAAaD,EAAK9C,KAAKvG,QAAQ0G,EAAU2C,EAAK7C,MAAO6C,EAAK5C,MAAOW,EAAOjH,GAG9E7B,EAAW,CAAC+K,EAAK7C,MAAO6C,EAAK5C,QAC7B4C,EAAK7C,MAAQ8C,EAAWjJ,GAAGR,QAC3BwJ,EAAK5C,MAAQ6C,EAAWhJ,GAAGT,QAE3B,IAAM0J,EAAqBjL,EAAQ,kBAAMgL,EAAW/I,EAAEmH,SAASE,cACzD4B,EAAsBlL,EAAQ,kBAAMgL,EAAW/I,EAAEqH,YAAY2B,KAWnE,OARAjL,EAAW,CAACoI,EAAUU,IACtB9I,EAAWgL,GAGXD,EAAK9C,KAAKnH,QAAUiK,EAAKpD,YAEzBoD,EAAKlN,aAAakN,EAAKtN,QAAQwN,IAExB,CAAEnN,OAAQiN,EAAKtN,QAAQwN,GAAYC,WAAAA,KA1SlD,sCAmTU3L,eAAMqK,EAAkB/H,YAAAA,IAAAA,EAAsB,wBA2BhD,IAAMqI,EAAkBlK,EAAQ,kBAAMA,EAAQkK,gBAC1ClK,EAAUgJ,GAAUhJ,EAAU2I,GAAcwC,EAAKtK,cAG/CwJ,EAAkBrK,EAAQ,kBAAMkK,EACjC3H,IAAIvC,QAAAA,EAAUkK,EAAgBpK,QAC9BgE,IAAI,KAEHsH,EAAmB,CACrBd,eAAAA,EAEAC,SAAmBvK,EAAQ,kBACvBqK,EAAgBvG,MAAMzB,IAAI6H,EAAgBpG,OAAOwF,cAGrDkB,OAAiBxK,EAAQ,kBACrBqK,EAAgBhI,IAAI6H,EAAgBpG,IAAI,IAAIwB,OAAOgE,cAGvDmB,UAAoBzK,EAAQ,kBACxBqK,EAAgBhI,IAAI6H,EAAgBpG,IAAI,IAAIwB,OAAOgE,cAGvD+B,kBAAmBC,EAAYvD,OAAO,SAAC4C,EAAGC,UAAMD,EAAIC,IAAKU,EAAY5M,QAMzE,OAHAsB,EAAW,CAACqK,EAAiBH,IAE7BiB,EAAKlN,cACEmN,KAhDH1N,KAPEsL,EAAoB,GACpBL,EAAwB,GACxB2C,EAAwB,GACxBhB,EAA2B,GAGxBO,EAAW,wBAAGA,EAAWjB,EAAQlL,4BAAQmM,GAAY,eAC1DM,EAAKlN,cAEA,IAAIwL,EAAW,wBAAGA,EAAWG,EAAQiB,GAAUnM,4BAAQ+K,GAAY,eACpE,IAAM5D,EAAQ+D,EAAQiB,GAAUpB,GADuC,uBAIlC0B,EAAKzJ,QAAQmE,EAAM1C,MAAOtB,yBAAvD/D,IAAAA,OAAQoN,IAAAA,WAEhBlC,EAAQjE,KAAKoG,EAAK1N,QAAQ6F,QAAQuC,EAAM/H,SACxC6K,EAAY5D,KAAKoG,EAAK1N,QAAQ6F,QAAQxF,IACtCwN,EAAYvG,KAAKmG,GAEbpN,IAAW+H,EAAM/H,QAAWwM,EAAe9G,SAASqH,IACpDP,EAAevF,KAAK8F,kGAxUxC,sCAiXI3M,KAAA,SAAKqN,GACD,IAAMpN,EAAaoG,KAAKC,MAAM+G,GAE9B7N,KAAK8J,YAAY5C,QAAQ,SAACkD,GACtBA,EAAW5J,KAAKC,EAAW2J,EAAW0D,OAG1C9N,KAAKuK,KAAK/J,KAAKC,EAAW8J,MAE1BvK,KAAKO,6CAO4BP,4BAAA+N,EAAKxD,6CAStC,OAAO1D,KAAKmH,UAAUvN,GATtB,IAAMA,EAAa,CAAE8J,QAEZI,EAAM,wBAAGA,EAAMoD,EAAKjE,YAAY9I,4BAAQ2J,GAAO,eACpD,IAAMP,EAAa2D,EAAKjE,YAAYa,GADmB,uBAIrBP,6BAAlC3J,EAAW2J,EAAW0D,2CAvYlC,wFCzDI,WAAYG,EAAwBC,EAChCC,EAAuCC,yBADPF,IAAAA,EAA0B,aAC1DC,IAAAA,EAAmC,aAAIC,IAAAA,EAAoB,MAC3DhK,sBAEKiK,cAAgBlH,OAAOC,KAAK6G,GACjC7J,EAAK6J,WAAaA,EAElB7J,EAAK0J,wBAA0B/L,EAAS8E,KAAKmH,UAAU5J,EAAKiK,oBAE5DjK,EAAK8J,iBAAmBA,EACxB9J,EAAK+J,0BAA4BA,EAEjC/J,EAAKgK,UAAYA,EAEjBhK,EAAKkB,KAAO,EAAIlB,EAAKiK,cAAcrN,gBA3B3C,2BA8BUlB,cAAKC,qDACKD,YAAKC,oBACjBsF,EAAK9E,gBAhCb,sCAmCY+N,eAAA,SAAe5F,GACnB,IAAM2F,EAAgBlH,OAAOC,KAAKpH,KAAKiO,YAEvC,OAAqB3L,EACjB+L,EAAczI,QAAQ8C,EAAM6F,UAC5BF,EAAcrN,WAIhBwE,qBAAYC,aAGCzF,KAFXwO,EAAmB,CAAED,cAAU3M,EAAWD,aAASC,EAAWC,MAAO,GAEzEsF,OAAOsH,QAAQ/I,EAAKuI,YAAY/G,QAAQ,gBAAEqH,OAEhCG,OACDpO,IAAI,SAACqO,UAAYpN,EAAWkE,EAAMO,cAAe2I,EAAQ3I,iBACzDgB,OAAO,SAAC4H,UAAMA,EAAE/M,OAAS6D,EAAK0I,YAC9B/D,OACG,SAACwE,EAAID,UAAOC,EAAGhN,MAAQ+M,EAAE/M,MAAQgN,EAAKD,GACtC,CAAEjN,aAASC,EAAWC,MAAO,IAIjC6M,EAAM7M,MAAQ2M,EAAU3M,QACxB2M,KAAcD,SAAAA,GAAaG,MAInC,IAAMhE,EAAWpI,EAAQ,kBACrBA,EAAU,CACNoD,EAAK4I,eAAeE,GACpB9I,EAAK4I,eAAe5I,EAAKgD,WAQjC,YAJ2B9G,IAAvB4M,EAAUD,WACV7I,EAAKgD,MAAQ8F,mBAGV9D,GA1Ef,sCA6EIrK,cAAA,sBACI,YAAYN,QAAQO,IAAI,SAACF,GACrB,IAAM0O,OAA2BlN,IAAvBgJ,EAAKlC,MAAM/G,QACfd,EAAI+J,EAAKsD,iBAAiBpI,SAAS1F,GACnCc,EAAI0J,EAAKuD,0BAA0BrI,SAAS1F,GAElD,OAAQ0O,IAAM5N,IAAML,KAASiO,IAAM5N,OAI3CX,YAAA,WACIP,KAAK0I,MAAQ,CAAE6F,cAAU3M,EAAWD,aAASC,EAAWC,MAAO,MAGnEkN,SAAA,WACI,YAAYrG,UA5FiB7I,4CCDRmP,GACzB,IAAM9C,EAAmB,GACrBpB,EAAe,GACfmE,GAAgB,EAsDpB,OApDAD,EAAO/I,MAAM,MAAMiB,QAAQ,SAACgI,GACxB,IAAMC,EAAW,oBAAoBC,KAAKF,GACpCG,EAAW,cAAcD,KAAKF,GAC9BI,EAAY,eAAeF,KAAKF,GAMtB,MAAZC,GAAoBrE,EAAM9J,OAAS,GACnC8J,EAAMzD,KAAa,CAAE5B,MAAO,GAAIrF,OAAQ,QACxC8L,EAAQ7E,KAAKyD,GACbA,EAAQ,IAMW,MAAZuE,GAEHvE,EAAM9J,OAAS,GAAG8J,EAAMzD,KAAa,CAAE5B,MAAO,GAAIrF,OAAQ,QAE9D0K,EAAMzD,KAAa,CAAE5B,MAAO4J,EAAS,GAAIjP,YAAQwB,IACjDqN,GAAgB,GAQI,MAAbK,GAAqBL,EAC5BnE,EAAMzD,KAAa,CAAE5B,MAAO,GAAIrF,OAAQkP,EAAU,KAO9B,MAAbA,GAAsBL,IAE7BnE,EAAMA,EAAM9J,OAAS,GAAGZ,OAASkP,EAAU,GAC3CL,GAAgB,KAKpBnE,EAAM9J,OAAS,IACf8J,EAAMzD,KAAa,CAAE5B,MAAO,GAAIrF,OAAQ,QACxC8L,EAAQ7E,KAAKyD,IAGVoB,2BCvDoBA,EAAkBqD,GAI7C,IAFA,IAAMtG,EAAgB,GAEb/H,EAAI,EAAGA,EAAIgL,EAAQlL,OAASuO,EAAUrO,GAAK,EAChD+H,EAAK5B,WAAL4B,EAAaiD,EAAQsD,OACjBpO,KAAKqO,MAAMrO,KAAKsO,SAAWxD,EAAQlL,QAAS,IAIpD,MAAO,CAAEiL,MAAOC,EAASjD,KAAAA"}